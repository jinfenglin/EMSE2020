Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Loading pytorch/1.1.0
  Loading requirement: cuda/10.0 cudnn/7.4
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:__main__:model loaded
INFO:EMSE.BERTDataReader:Creating examples from dataset file at /afs/crc.nd.edu/user/j/jlin6/data/EMSE/arthas/test
update feature:   0%|          | 0/17 [00:00<?, ?it/s]update feature: 100%|██████████| 17/17 [00:00<00:00, 327.80it/s]
update feature:   0%|          | 0/17 [00:00<?, ?it/s]update feature: 100%|██████████| 17/17 [00:00<00:00, 367.95it/s]
update embedding:   0%|          | 0/17 [00:00<?, ?it/s]update embedding:   6%|▌         | 1/17 [00:00<00:15,  1.04it/s]update embedding:  12%|█▏        | 2/17 [00:01<00:13,  1.11it/s]update embedding:  18%|█▊        | 3/17 [00:02<00:12,  1.16it/s]update embedding:  24%|██▎       | 4/17 [00:03<00:10,  1.20it/s]update embedding:  29%|██▉       | 5/17 [00:04<00:10,  1.18it/s]update embedding:  35%|███▌      | 6/17 [00:04<00:09,  1.21it/s]update embedding:  41%|████      | 7/17 [00:05<00:08,  1.23it/s]update embedding:  47%|████▋     | 8/17 [00:06<00:07,  1.24it/s]update embedding:  53%|█████▎    | 9/17 [00:07<00:06,  1.22it/s]update embedding:  59%|█████▉    | 10/17 [00:08<00:05,  1.23it/s]update embedding:  65%|██████▍   | 11/17 [00:08<00:04,  1.24it/s]update embedding:  71%|███████   | 12/17 [00:09<00:04,  1.24it/s]update embedding:  76%|███████▋  | 13/17 [00:10<00:03,  1.25it/s]update embedding:  82%|████████▏ | 14/17 [00:11<00:02,  1.25it/s]update embedding:  88%|████████▊ | 15/17 [00:12<00:01,  1.27it/s]update embedding:  94%|█████████▍| 16/17 [00:12<00:00,  1.27it/s]update embedding: 100%|██████████| 17/17 [00:13<00:00,  1.30it/s]update embedding: 100%|██████████| 17/17 [00:13<00:00,  1.25it/s]
update embedding:   0%|          | 0/17 [00:00<?, ?it/s]update embedding:   6%|▌         | 1/17 [00:00<00:12,  1.28it/s]update embedding:  12%|█▏        | 2/17 [00:01<00:11,  1.30it/s]update embedding:  18%|█▊        | 3/17 [00:02<00:10,  1.31it/s]update embedding:  24%|██▎       | 4/17 [00:03<00:09,  1.32it/s]update embedding:  29%|██▉       | 5/17 [00:03<00:09,  1.32it/s]update embedding:  35%|███▌      | 6/17 [00:04<00:08,  1.32it/s]update embedding:  41%|████      | 7/17 [00:05<00:07,  1.33it/s]update embedding:  47%|████▋     | 8/17 [00:06<00:06,  1.33it/s]update embedding:  53%|█████▎    | 9/17 [00:06<00:06,  1.33it/s]update embedding:  59%|█████▉    | 10/17 [00:07<00:05,  1.33it/s]update embedding:  65%|██████▍   | 11/17 [00:08<00:04,  1.33it/s]update embedding:  71%|███████   | 12/17 [00:09<00:03,  1.31it/s]update embedding:  76%|███████▋  | 13/17 [00:09<00:03,  1.30it/s]update embedding:  82%|████████▏ | 14/17 [00:10<00:02,  1.30it/s]update embedding:  88%|████████▊ | 15/17 [00:11<00:01,  1.30it/s]update embedding:  94%|█████████▍| 16/17 [00:12<00:00,  1.30it/s]update embedding: 100%|██████████| 17/17 [00:12<00:00,  1.29it/s]update embedding: 100%|██████████| 17/17 [00:12<00:00,  1.31it/s]
retrival evaluation:   0%|          | 0/73 [00:00<?, ?it/s]retrival evaluation:  11%|█         | 8/73 [00:00<00:00, 72.84it/s]retrival evaluation:  23%|██▎       | 17/73 [00:00<00:00, 75.58it/s]retrival evaluation:  36%|███▌      | 26/73 [00:00<00:00, 77.39it/s]retrival evaluation:  48%|████▊     | 35/73 [00:00<00:00, 78.82it/s]retrival evaluation:  60%|██████    | 44/73 [00:00<00:00, 79.80it/s]retrival evaluation:  73%|███████▎  | 53/73 [00:00<00:00, 80.61it/s]retrival evaluation:  85%|████████▍ | 62/73 [00:00<00:00, 81.25it/s]retrival evaluation:  97%|█████████▋| 71/73 [00:00<00:00, 81.55it/s]retrival evaluation: 100%|██████████| 73/73 [00:00<00:00, 82.04it/s]

pk3=0, pk2=0,pk1=0 best_f1 = 0.132, bets_f2=0.26, MAP=0.207, MRR=0, AP=0.122, exe_time=27.603438138961792

INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:__main__:model loaded
INFO:EMSE.BERTDataReader:Creating examples from dataset file at /afs/crc.nd.edu/user/j/jlin6/data/EMSE/bk-cmdb/test
update feature:   0%|          | 0/119 [00:00<?, ?it/s]update feature:  13%|█▎        | 15/119 [00:00<00:00, 146.88it/s]update feature:  28%|██▊       | 33/119 [00:00<00:00, 155.31it/s]update feature:  58%|█████▊    | 69/119 [00:00<00:00, 186.84it/s]update feature:  77%|███████▋  | 92/119 [00:00<00:00, 197.95it/s]update feature: 100%|██████████| 119/119 [00:00<00:00, 259.09it/s]
update feature:   0%|          | 0/119 [00:00<?, ?it/s]update feature: 100%|██████████| 119/119 [00:00<00:00, 1731.49it/s]
update embedding:   0%|          | 0/119 [00:00<?, ?it/s]update embedding:   1%|          | 1/119 [00:00<01:51,  1.06it/s]update embedding:   2%|▏         | 2/119 [00:01<01:47,  1.08it/s]update embedding:   3%|▎         | 3/119 [00:02<01:45,  1.09it/s]update embedding:   3%|▎         | 4/119 [00:03<01:42,  1.12it/s]update embedding:   4%|▍         | 5/119 [00:04<01:40,  1.13it/s]update embedding:   5%|▌         | 6/119 [00:05<01:39,  1.14it/s]update embedding:   6%|▌         | 7/119 [00:06<01:36,  1.16it/s]update embedding:   7%|▋         | 8/119 [00:06<01:34,  1.18it/s]update embedding:   8%|▊         | 9/119 [00:07<01:32,  1.19it/s]update embedding:   8%|▊         | 10/119 [00:08<01:33,  1.17it/s]update embedding:   9%|▉         | 11/119 [00:09<01:30,  1.20it/s]update embedding:  10%|█         | 12/119 [00:10<01:28,  1.20it/s]update embedding:  11%|█         | 13/119 [00:11<01:26,  1.23it/s]update embedding:  12%|█▏        | 14/119 [00:11<01:25,  1.23it/s]update embedding:  13%|█▎        | 15/119 [00:12<01:22,  1.26it/s]update embedding:  13%|█▎        | 16/119 [00:13<01:20,  1.28it/s]update embedding:  14%|█▍        | 17/119 [00:14<01:19,  1.28it/s]update embedding:  15%|█▌        | 18/119 [00:14<01:18,  1.29it/s]update embedding:  16%|█▌        | 19/119 [00:15<01:17,  1.30it/s]update embedding:  17%|█▋        | 20/119 [00:16<01:16,  1.30it/s]update embedding:  18%|█▊        | 21/119 [00:17<01:16,  1.29it/s]update embedding:  18%|█▊        | 22/119 [00:17<01:14,  1.30it/s]update embedding:  19%|█▉        | 23/119 [00:18<01:13,  1.30it/s]update embedding:  20%|██        | 24/119 [00:19<01:12,  1.31it/s]update embedding:  21%|██        | 25/119 [00:20<01:11,  1.32it/s]update embedding:  22%|██▏       | 26/119 [00:20<01:10,  1.31it/s]update embedding:  23%|██▎       | 27/119 [00:21<01:10,  1.30it/s]update embedding:  24%|██▎       | 28/119 [00:22<01:10,  1.29it/s]update embedding:  24%|██▍       | 29/119 [00:23<01:09,  1.29it/s]update embedding:  25%|██▌       | 30/119 [00:24<01:09,  1.28it/s]update embedding:  26%|██▌       | 31/119 [00:24<01:09,  1.27it/s]update embedding:  27%|██▋       | 32/119 [00:25<01:09,  1.26it/s]update embedding:  28%|██▊       | 33/119 [00:26<01:08,  1.26it/s]update embedding:  29%|██▊       | 34/119 [00:27<01:07,  1.26it/s]update embedding:  29%|██▉       | 35/119 [00:28<01:06,  1.26it/s]update embedding:  30%|███       | 36/119 [00:28<01:05,  1.26it/s]update embedding:  31%|███       | 37/119 [00:29<01:04,  1.26it/s]update embedding:  32%|███▏      | 38/119 [00:30<01:03,  1.27it/s]update embedding:  33%|███▎      | 39/119 [00:31<01:03,  1.27it/s]update embedding:  34%|███▎      | 40/119 [00:32<01:02,  1.26it/s]update embedding:  34%|███▍      | 41/119 [00:32<01:01,  1.26it/s]update embedding:  35%|███▌      | 42/119 [00:33<01:01,  1.26it/s]update embedding:  36%|███▌      | 43/119 [00:34<00:59,  1.28it/s]update embedding:  37%|███▋      | 44/119 [00:35<00:58,  1.29it/s]update embedding:  38%|███▊      | 45/119 [00:35<00:56,  1.31it/s]update embedding:  39%|███▊      | 46/119 [00:36<00:55,  1.31it/s]update embedding:  39%|███▉      | 47/119 [00:37<00:54,  1.32it/s]update embedding:  40%|████      | 48/119 [00:38<00:53,  1.32it/s]update embedding:  41%|████      | 49/119 [00:38<00:52,  1.32it/s]update embedding:  42%|████▏     | 50/119 [00:39<00:52,  1.33it/s]update embedding:  43%|████▎     | 51/119 [00:40<00:51,  1.32it/s]update embedding:  44%|████▎     | 52/119 [00:41<00:50,  1.32it/s]update embedding:  45%|████▍     | 53/119 [00:41<00:49,  1.32it/s]update embedding:  45%|████▌     | 54/119 [00:42<00:48,  1.33it/s]update embedding:  46%|████▌     | 55/119 [00:43<00:47,  1.34it/s]update embedding:  47%|████▋     | 56/119 [00:44<00:48,  1.31it/s]update embedding:  48%|████▊     | 57/119 [00:45<00:47,  1.30it/s]update embedding:  49%|████▊     | 58/119 [00:45<00:47,  1.30it/s]update embedding:  50%|████▉     | 59/119 [00:46<00:46,  1.29it/s]update embedding:  50%|█████     | 60/119 [00:47<00:46,  1.28it/s]update embedding:  51%|█████▏    | 61/119 [00:48<00:45,  1.27it/s]update embedding:  52%|█████▏    | 62/119 [00:48<00:44,  1.27it/s]update embedding:  53%|█████▎    | 63/119 [00:49<00:44,  1.27it/s]update embedding:  54%|█████▍    | 64/119 [00:50<00:43,  1.27it/s]update embedding:  55%|█████▍    | 65/119 [00:51<00:42,  1.26it/s]update embedding:  55%|█████▌    | 66/119 [00:52<00:41,  1.26it/s]update embedding:  56%|█████▋    | 67/119 [00:52<00:41,  1.26it/s]update embedding:  57%|█████▋    | 68/119 [00:53<00:40,  1.25it/s]update embedding:  58%|█████▊    | 69/119 [00:54<00:39,  1.25it/s]update embedding:  59%|█████▉    | 70/119 [00:55<00:38,  1.26it/s]update embedding:  60%|█████▉    | 71/119 [00:56<00:37,  1.26it/s]update embedding:  61%|██████    | 72/119 [00:56<00:37,  1.27it/s]update embedding:  61%|██████▏   | 73/119 [00:57<00:35,  1.28it/s]update embedding:  62%|██████▏   | 74/119 [00:58<00:34,  1.29it/s]update embedding:  63%|██████▎   | 75/119 [00:59<00:33,  1.29it/s]update embedding:  64%|██████▍   | 76/119 [00:59<00:33,  1.30it/s]update embedding:  65%|██████▍   | 77/119 [01:00<00:32,  1.31it/s]update embedding:  66%|██████▌   | 78/119 [01:01<00:31,  1.31it/s]update embedding:  66%|██████▋   | 79/119 [01:02<00:30,  1.31it/s]update embedding:  67%|██████▋   | 80/119 [01:02<00:29,  1.31it/s]update embedding:  68%|██████▊   | 81/119 [01:03<00:29,  1.31it/s]update embedding:  69%|██████▉   | 82/119 [01:04<00:28,  1.30it/s]update embedding:  70%|██████▉   | 83/119 [01:05<00:27,  1.30it/s]update embedding:  71%|███████   | 84/119 [01:06<00:26,  1.32it/s]update embedding:  71%|███████▏  | 85/119 [01:06<00:25,  1.32it/s]update embedding:  72%|███████▏  | 86/119 [01:07<00:25,  1.31it/s]update embedding:  73%|███████▎  | 87/119 [01:08<00:24,  1.30it/s]update embedding:  74%|███████▍  | 88/119 [01:09<00:24,  1.29it/s]update embedding:  75%|███████▍  | 89/119 [01:09<00:23,  1.29it/s]update embedding:  76%|███████▌  | 90/119 [01:10<00:22,  1.29it/s]update embedding:  76%|███████▋  | 91/119 [01:11<00:22,  1.26it/s]update embedding:  77%|███████▋  | 92/119 [01:12<00:22,  1.22it/s]update embedding:  78%|███████▊  | 93/119 [01:13<00:21,  1.19it/s]update embedding:  79%|███████▉  | 94/119 [01:14<00:21,  1.17it/s]update embedding:  80%|███████▉  | 95/119 [01:15<00:20,  1.16it/s]update embedding:  81%|████████  | 96/119 [01:15<00:20,  1.15it/s]update embedding:  82%|████████▏ | 97/119 [01:16<00:19,  1.14it/s]update embedding:  82%|████████▏ | 98/119 [01:17<00:18,  1.13it/s]update embedding:  83%|████████▎ | 99/119 [01:18<00:17,  1.12it/s]update embedding:  84%|████████▍ | 100/119 [01:19<00:16,  1.12it/s]update embedding:  85%|████████▍ | 101/119 [01:20<00:16,  1.12it/s]update embedding:  86%|████████▌ | 102/119 [01:21<00:15,  1.13it/s]update embedding:  87%|████████▋ | 103/119 [01:22<00:14,  1.13it/s]update embedding:  87%|████████▋ | 104/119 [01:23<00:13,  1.13it/s]update embedding:  88%|████████▊ | 105/119 [01:23<00:12,  1.13it/s]update embedding:  89%|████████▉ | 106/119 [01:24<00:11,  1.13it/s]update embedding:  90%|████████▉ | 107/119 [01:25<00:10,  1.13it/s]update embedding:  91%|█████████ | 108/119 [01:26<00:09,  1.13it/s]update embedding:  92%|█████████▏| 109/119 [01:27<00:08,  1.13it/s]update embedding:  92%|█████████▏| 110/119 [01:28<00:07,  1.14it/s]update embedding:  93%|█████████▎| 111/119 [01:29<00:07,  1.14it/s]update embedding:  94%|█████████▍| 112/119 [01:30<00:06,  1.13it/s]update embedding:  95%|█████████▍| 113/119 [01:31<00:05,  1.12it/s]update embedding:  96%|█████████▌| 114/119 [01:31<00:04,  1.12it/s]update embedding:  97%|█████████▋| 115/119 [01:32<00:03,  1.12it/s]update embedding:  97%|█████████▋| 116/119 [01:33<00:02,  1.11it/s]update embedding:  98%|█████████▊| 117/119 [01:34<00:01,  1.11it/s]update embedding:  99%|█████████▉| 118/119 [01:35<00:00,  1.11it/s]update embedding: 100%|██████████| 119/119 [01:36<00:00,  1.11it/s]update embedding: 100%|██████████| 119/119 [01:36<00:00,  1.23it/s]
update embedding:   0%|          | 0/119 [00:00<?, ?it/s]update embedding:   1%|          | 1/119 [00:00<01:46,  1.10it/s]update embedding:   2%|▏         | 2/119 [00:01<01:46,  1.10it/s]update embedding:   3%|▎         | 3/119 [00:02<01:46,  1.09it/s]update embedding:   3%|▎         | 4/119 [00:03<01:45,  1.09it/s]update embedding:   4%|▍         | 5/119 [00:04<01:44,  1.10it/s]update embedding:   5%|▌         | 6/119 [00:05<01:42,  1.10it/s]update embedding:   6%|▌         | 7/119 [00:06<01:40,  1.11it/s]update embedding:   7%|▋         | 8/119 [00:07<01:38,  1.13it/s]update embedding:   8%|▊         | 9/119 [00:08<01:36,  1.13it/s]update embedding:   8%|▊         | 10/119 [00:08<01:35,  1.14it/s]update embedding:   9%|▉         | 11/119 [00:09<01:34,  1.15it/s]update embedding:  10%|█         | 12/119 [00:10<01:33,  1.14it/s]update embedding:  11%|█         | 13/119 [00:11<01:32,  1.15it/s]update embedding:  12%|█▏        | 14/119 [00:12<01:31,  1.15it/s]update embedding:  13%|█▎        | 15/119 [00:13<01:30,  1.15it/s]update embedding:  13%|█▎        | 16/119 [00:14<01:29,  1.15it/s]update embedding:  14%|█▍        | 17/119 [00:15<01:29,  1.14it/s]update embedding:  15%|█▌        | 18/119 [00:15<01:30,  1.11it/s]update embedding:  16%|█▌        | 19/119 [00:16<01:28,  1.13it/s]update embedding:  17%|█▋        | 20/119 [00:17<01:27,  1.14it/s]update embedding:  18%|█▊        | 21/119 [00:18<01:25,  1.14it/s]update embedding:  18%|█▊        | 22/119 [00:19<01:24,  1.15it/s]update embedding:  19%|█▉        | 23/119 [00:20<01:26,  1.11it/s]update embedding:  20%|██        | 24/119 [00:21<01:26,  1.10it/s]update embedding:  21%|██        | 25/119 [00:22<01:26,  1.09it/s]update embedding:  22%|██▏       | 26/119 [00:23<01:26,  1.08it/s]update embedding:  23%|██▎       | 27/119 [00:24<01:25,  1.08it/s]update embedding:  24%|██▎       | 28/119 [00:25<01:22,  1.11it/s]update embedding:  24%|██▍       | 29/119 [00:25<01:20,  1.12it/s]update embedding:  25%|██▌       | 30/119 [00:26<01:21,  1.10it/s]update embedding:  26%|██▌       | 31/119 [00:27<01:20,  1.10it/s]update embedding:  27%|██▋       | 32/119 [00:28<01:18,  1.11it/s]update embedding:  28%|██▊       | 33/119 [00:29<01:16,  1.12it/s]update embedding:  29%|██▊       | 34/119 [00:30<01:15,  1.13it/s]update embedding:  29%|██▉       | 35/119 [00:31<01:13,  1.14it/s]update embedding:  30%|███       | 36/119 [00:32<01:12,  1.14it/s]update embedding:  31%|███       | 37/119 [00:32<01:12,  1.14it/s]update embedding:  32%|███▏      | 38/119 [00:33<01:10,  1.14it/s]update embedding:  33%|███▎      | 39/119 [00:34<01:09,  1.15it/s]update embedding:  34%|███▎      | 40/119 [00:35<01:08,  1.16it/s]update embedding:  34%|███▍      | 41/119 [00:36<01:09,  1.13it/s]update embedding:  35%|███▌      | 42/119 [00:37<01:11,  1.08it/s]update embedding:  36%|███▌      | 43/119 [00:38<01:11,  1.06it/s]update embedding:  37%|███▋      | 44/119 [00:39<01:14,  1.00it/s]update embedding:  38%|███▊      | 45/119 [00:40<01:14,  1.00s/it]update embedding:  39%|███▊      | 46/119 [00:41<01:12,  1.00it/s]update embedding:  39%|███▉      | 47/119 [00:42<01:11,  1.01it/s]update embedding:  40%|████      | 48/119 [00:43<01:09,  1.02it/s]update embedding:  41%|████      | 49/119 [00:44<01:07,  1.03it/s]update embedding:  42%|████▏     | 50/119 [00:45<01:06,  1.03it/s]update embedding:  43%|████▎     | 51/119 [00:46<01:06,  1.02it/s]update embedding:  44%|████▎     | 52/119 [00:47<01:05,  1.03it/s]update embedding:  45%|████▍     | 53/119 [00:48<01:05,  1.01it/s]update embedding:  45%|████▌     | 54/119 [00:49<01:02,  1.03it/s]update embedding:  46%|████▌     | 55/119 [00:50<01:01,  1.04it/s]update embedding:  47%|████▋     | 56/119 [00:51<01:00,  1.05it/s]update embedding:  48%|████▊     | 57/119 [00:52<00:59,  1.05it/s]update embedding:  49%|████▊     | 58/119 [00:53<00:57,  1.05it/s]update embedding:  50%|████▉     | 59/119 [00:54<00:56,  1.06it/s]update embedding:  50%|█████     | 60/119 [00:55<00:55,  1.07it/s]update embedding:  51%|█████▏    | 61/119 [00:55<00:54,  1.07it/s]update embedding:  52%|█████▏    | 62/119 [00:56<00:53,  1.08it/s]update embedding:  53%|█████▎    | 63/119 [00:57<00:52,  1.07it/s]update embedding:  54%|█████▍    | 64/119 [00:58<00:51,  1.08it/s]update embedding:  55%|█████▍    | 65/119 [00:59<00:49,  1.09it/s]update embedding:  55%|█████▌    | 66/119 [01:00<00:47,  1.11it/s]update embedding:  56%|█████▋    | 67/119 [01:01<00:46,  1.12it/s]update embedding:  57%|█████▋    | 68/119 [01:02<00:45,  1.12it/s]update embedding:  58%|█████▊    | 69/119 [01:03<00:44,  1.13it/s]update embedding:  59%|█████▉    | 70/119 [01:03<00:42,  1.14it/s]update embedding:  60%|█████▉    | 71/119 [01:04<00:42,  1.13it/s]update embedding:  61%|██████    | 72/119 [01:05<00:41,  1.14it/s]update embedding:  61%|██████▏   | 73/119 [01:06<00:40,  1.14it/s]update embedding:  62%|██████▏   | 74/119 [01:07<00:39,  1.15it/s]update embedding:  63%|██████▎   | 75/119 [01:08<00:38,  1.13it/s]update embedding:  64%|██████▍   | 76/119 [01:09<00:38,  1.12it/s]update embedding:  65%|██████▍   | 77/119 [01:10<00:37,  1.12it/s]update embedding:  66%|██████▌   | 78/119 [01:11<00:37,  1.11it/s]update embedding:  66%|██████▋   | 79/119 [01:11<00:35,  1.11it/s]update embedding:  67%|██████▋   | 80/119 [01:12<00:34,  1.13it/s]update embedding:  68%|██████▊   | 81/119 [01:13<00:33,  1.14it/s]update embedding:  69%|██████▉   | 82/119 [01:14<00:32,  1.15it/s]update embedding:  70%|██████▉   | 83/119 [01:15<00:31,  1.15it/s]update embedding:  71%|███████   | 84/119 [01:16<00:30,  1.15it/s]update embedding:  71%|███████▏  | 85/119 [01:17<00:29,  1.16it/s]update embedding:  72%|███████▏  | 86/119 [01:17<00:28,  1.15it/s]update embedding:  73%|███████▎  | 87/119 [01:18<00:27,  1.15it/s]update embedding:  74%|███████▍  | 88/119 [01:19<00:26,  1.15it/s]update embedding:  75%|███████▍  | 89/119 [01:20<00:26,  1.15it/s]update embedding:  76%|███████▌  | 90/119 [01:21<00:25,  1.15it/s]update embedding:  76%|███████▋  | 91/119 [01:22<00:24,  1.15it/s]update embedding:  77%|███████▋  | 92/119 [01:23<00:23,  1.15it/s]update embedding:  78%|███████▊  | 93/119 [01:24<00:22,  1.15it/s]update embedding:  79%|███████▉  | 94/119 [01:24<00:21,  1.15it/s]update embedding:  80%|███████▉  | 95/119 [01:25<00:20,  1.14it/s]update embedding:  81%|████████  | 96/119 [01:26<00:20,  1.15it/s]update embedding:  82%|████████▏ | 97/119 [01:27<00:19,  1.15it/s]update embedding:  82%|████████▏ | 98/119 [01:28<00:18,  1.15it/s]update embedding:  83%|████████▎ | 99/119 [01:29<00:17,  1.15it/s]update embedding:  84%|████████▍ | 100/119 [01:30<00:16,  1.15it/s]update embedding:  85%|████████▍ | 101/119 [01:31<00:15,  1.15it/s]update embedding:  86%|████████▌ | 102/119 [01:31<00:14,  1.15it/s]update embedding:  87%|████████▋ | 103/119 [01:32<00:13,  1.15it/s]update embedding:  87%|████████▋ | 104/119 [01:33<00:13,  1.14it/s]update embedding:  88%|████████▊ | 105/119 [01:34<00:12,  1.14it/s]update embedding:  89%|████████▉ | 106/119 [01:35<00:11,  1.15it/s]update embedding:  90%|████████▉ | 107/119 [01:36<00:10,  1.15it/s]update embedding:  91%|█████████ | 108/119 [01:37<00:09,  1.15it/s]update embedding:  92%|█████████▏| 109/119 [01:37<00:08,  1.16it/s]update embedding:  92%|█████████▏| 110/119 [01:38<00:07,  1.15it/s]update embedding:  93%|█████████▎| 111/119 [01:39<00:06,  1.15it/s]update embedding:  94%|█████████▍| 112/119 [01:40<00:06,  1.15it/s]update embedding:  95%|█████████▍| 113/119 [01:41<00:05,  1.15it/s]update embedding:  96%|█████████▌| 114/119 [01:42<00:04,  1.15it/s]update embedding:  97%|█████████▋| 115/119 [01:43<00:03,  1.15it/s]update embedding:  97%|█████████▋| 116/119 [01:44<00:02,  1.14it/s]update embedding:  98%|█████████▊| 117/119 [01:44<00:01,  1.14it/s]update embedding:  99%|█████████▉| 118/119 [01:45<00:00,  1.14it/s]update embedding: 100%|██████████| 119/119 [01:46<00:00,  1.14it/s]update embedding: 100%|██████████| 119/119 [01:46<00:00,  1.11it/s]
retrival evaluation:   0%|          | 0/3541 [00:00<?, ?it/s]retrival evaluation:   0%|          | 6/3541 [00:00<01:06, 53.36it/s]retrival evaluation:   0%|          | 12/3541 [00:00<01:03, 55.18it/s]retrival evaluation:   1%|          | 20/3541 [00:00<00:59, 59.10it/s]retrival evaluation:   1%|          | 28/3541 [00:00<00:56, 62.21it/s]retrival evaluation:   1%|          | 37/3541 [00:00<00:52, 66.92it/s]retrival evaluation:   1%|▏         | 46/3541 [00:00<00:49, 70.68it/s]retrival evaluation:   2%|▏         | 55/3541 [00:00<00:47, 73.54it/s]retrival evaluation:   2%|▏         | 64/3541 [00:00<00:46, 75.25it/s]retrival evaluation:   2%|▏         | 73/3541 [00:00<00:45, 77.04it/s]retrival evaluation:   2%|▏         | 82/3541 [00:01<00:44, 78.18it/s]retrival evaluation:   3%|▎         | 91/3541 [00:01<00:43, 78.95it/s]retrival evaluation:   3%|▎         | 100/3541 [00:01<00:43, 79.87it/s]retrival evaluation:   3%|▎         | 109/3541 [00:01<00:42, 80.62it/s]retrival evaluation:   3%|▎         | 118/3541 [00:01<00:42, 80.90it/s]retrival evaluation:   4%|▎         | 127/3541 [00:01<00:42, 80.96it/s]retrival evaluation:   4%|▍         | 136/3541 [00:01<00:42, 80.00it/s]retrival evaluation:   4%|▍         | 145/3541 [00:01<00:42, 80.58it/s]retrival evaluation:   4%|▍         | 154/3541 [00:01<00:42, 80.04it/s]retrival evaluation:   5%|▍         | 163/3541 [00:02<00:42, 79.31it/s]retrival evaluation:   5%|▍         | 171/3541 [00:02<00:42, 79.21it/s]retrival evaluation:   5%|▌         | 179/3541 [00:02<00:42, 78.38it/s]retrival evaluation:   5%|▌         | 187/3541 [00:02<00:43, 77.79it/s]retrival evaluation:   6%|▌         | 196/3541 [00:02<00:42, 78.71it/s]retrival evaluation:   6%|▌         | 205/3541 [00:02<00:42, 79.20it/s]retrival evaluation:   6%|▌         | 214/3541 [00:02<00:41, 80.03it/s]retrival evaluation:   6%|▋         | 223/3541 [00:02<00:41, 79.96it/s]retrival evaluation:   7%|▋         | 231/3541 [00:02<00:41, 79.75it/s]retrival evaluation:   7%|▋         | 240/3541 [00:03<00:41, 79.96it/s]retrival evaluation:   7%|▋         | 249/3541 [00:03<00:40, 80.75it/s]retrival evaluation:   7%|▋         | 258/3541 [00:03<00:41, 80.05it/s]retrival evaluation:   8%|▊         | 267/3541 [00:03<00:40, 79.86it/s]retrival evaluation:   8%|▊         | 276/3541 [00:03<00:40, 80.43it/s]retrival evaluation:   8%|▊         | 285/3541 [00:03<00:40, 80.61it/s]retrival evaluation:   8%|▊         | 294/3541 [00:03<00:40, 80.93it/s]retrival evaluation:   9%|▊         | 303/3541 [00:03<00:40, 80.78it/s]retrival evaluation:   9%|▉         | 312/3541 [00:03<00:39, 80.93it/s]retrival evaluation:   9%|▉         | 321/3541 [00:04<00:39, 80.92it/s]retrival evaluation:   9%|▉         | 330/3541 [00:04<00:39, 80.89it/s]retrival evaluation:  10%|▉         | 339/3541 [00:04<00:39, 81.29it/s]retrival evaluation:  10%|▉         | 348/3541 [00:04<00:39, 81.05it/s]retrival evaluation:  10%|█         | 357/3541 [00:04<00:39, 80.89it/s]retrival evaluation:  10%|█         | 366/3541 [00:04<00:39, 80.79it/s]retrival evaluation:  11%|█         | 375/3541 [00:04<00:38, 81.22it/s]retrival evaluation:  11%|█         | 384/3541 [00:04<00:38, 81.34it/s]retrival evaluation:  11%|█         | 393/3541 [00:04<00:38, 80.87it/s]retrival evaluation:  11%|█▏        | 402/3541 [00:05<00:38, 81.03it/s]retrival evaluation:  12%|█▏        | 411/3541 [00:05<00:38, 81.30it/s]retrival evaluation:  12%|█▏        | 420/3541 [00:05<00:38, 81.13it/s]retrival evaluation:  12%|█▏        | 429/3541 [00:05<00:38, 80.71it/s]retrival evaluation:  12%|█▏        | 438/3541 [00:05<00:38, 80.87it/s]retrival evaluation:  13%|█▎        | 447/3541 [00:05<00:38, 81.07it/s]retrival evaluation:  13%|█▎        | 456/3541 [00:05<00:38, 80.97it/s]retrival evaluation:  13%|█▎        | 465/3541 [00:05<00:37, 81.13it/s]retrival evaluation:  13%|█▎        | 474/3541 [00:05<00:37, 81.06it/s]retrival evaluation:  14%|█▎        | 483/3541 [00:06<00:37, 80.96it/s]retrival evaluation:  14%|█▍        | 492/3541 [00:06<00:37, 80.75it/s]retrival evaluation:  14%|█▍        | 501/3541 [00:06<00:37, 81.01it/s]retrival evaluation:  14%|█▍        | 510/3541 [00:06<00:37, 80.81it/s]retrival evaluation:  15%|█▍        | 519/3541 [00:06<00:37, 80.78it/s]retrival evaluation:  15%|█▍        | 528/3541 [00:06<00:37, 80.70it/s]retrival evaluation:  15%|█▌        | 537/3541 [00:06<00:37, 80.83it/s]retrival evaluation:  15%|█▌        | 546/3541 [00:06<00:36, 80.99it/s]retrival evaluation:  16%|█▌        | 555/3541 [00:06<00:37, 80.60it/s]retrival evaluation:  16%|█▌        | 564/3541 [00:07<00:36, 80.60it/s]retrival evaluation:  16%|█▌        | 573/3541 [00:07<00:36, 80.71it/s]retrival evaluation:  16%|█▋        | 582/3541 [00:07<00:36, 80.94it/s]retrival evaluation:  17%|█▋        | 591/3541 [00:07<00:36, 80.86it/s]retrival evaluation:  17%|█▋        | 600/3541 [00:07<00:36, 80.37it/s]retrival evaluation:  17%|█▋        | 609/3541 [00:07<00:36, 80.52it/s]retrival evaluation:  17%|█▋        | 618/3541 [00:07<00:36, 80.54it/s]retrival evaluation:  18%|█▊        | 627/3541 [00:07<00:36, 80.59it/s]retrival evaluation:  18%|█▊        | 636/3541 [00:07<00:36, 80.67it/s]retrival evaluation:  18%|█▊        | 645/3541 [00:08<00:35, 80.83it/s]retrival evaluation:  18%|█▊        | 654/3541 [00:08<00:35, 80.72it/s]retrival evaluation:  19%|█▊        | 663/3541 [00:08<00:35, 80.77it/s]retrival evaluation:  19%|█▉        | 672/3541 [00:08<00:35, 80.97it/s]retrival evaluation:  19%|█▉        | 681/3541 [00:08<00:35, 80.63it/s]retrival evaluation:  19%|█▉        | 690/3541 [00:08<00:35, 80.41it/s]retrival evaluation:  20%|█▉        | 699/3541 [00:08<00:35, 80.59it/s]retrival evaluation:  20%|█▉        | 708/3541 [00:08<00:34, 80.95it/s]retrival evaluation:  20%|██        | 717/3541 [00:08<00:35, 80.67it/s]retrival evaluation:  21%|██        | 726/3541 [00:09<00:34, 80.44it/s]retrival evaluation:  21%|██        | 735/3541 [00:09<00:34, 80.96it/s]retrival evaluation:  21%|██        | 744/3541 [00:09<00:34, 80.54it/s]retrival evaluation:  21%|██▏       | 753/3541 [00:09<00:34, 80.82it/s]retrival evaluation:  22%|██▏       | 762/3541 [00:09<00:34, 80.58it/s]retrival evaluation:  22%|██▏       | 771/3541 [00:09<00:34, 80.78it/s]retrival evaluation:  22%|██▏       | 780/3541 [00:09<00:34, 80.58it/s]retrival evaluation:  22%|██▏       | 789/3541 [00:09<00:34, 80.64it/s]retrival evaluation:  23%|██▎       | 798/3541 [00:09<00:33, 81.10it/s]retrival evaluation:  23%|██▎       | 807/3541 [00:10<00:33, 80.50it/s]retrival evaluation:  23%|██▎       | 816/3541 [00:10<00:33, 80.34it/s]retrival evaluation:  23%|██▎       | 825/3541 [00:10<00:33, 80.42it/s]retrival evaluation:  24%|██▎       | 834/3541 [00:10<00:33, 80.74it/s]retrival evaluation:  24%|██▍       | 843/3541 [00:10<00:33, 80.72it/s]retrival evaluation:  24%|██▍       | 852/3541 [00:10<00:33, 80.50it/s]retrival evaluation:  24%|██▍       | 861/3541 [00:10<00:33, 80.70it/s]retrival evaluation:  25%|██▍       | 870/3541 [00:10<00:33, 80.47it/s]retrival evaluation:  25%|██▍       | 879/3541 [00:10<00:32, 80.69it/s]retrival evaluation:  25%|██▌       | 888/3541 [00:11<00:32, 80.82it/s]retrival evaluation:  25%|██▌       | 897/3541 [00:11<00:32, 81.27it/s]retrival evaluation:  26%|██▌       | 906/3541 [00:11<00:32, 81.46it/s]retrival evaluation:  26%|██▌       | 915/3541 [00:11<00:32, 81.39it/s]retrival evaluation:  26%|██▌       | 924/3541 [00:11<00:32, 81.74it/s]retrival evaluation:  26%|██▋       | 933/3541 [00:11<00:31, 81.71it/s]retrival evaluation:  27%|██▋       | 942/3541 [00:11<00:31, 81.78it/s]retrival evaluation:  27%|██▋       | 951/3541 [00:11<00:31, 81.53it/s]retrival evaluation:  27%|██▋       | 960/3541 [00:11<00:31, 81.61it/s]retrival evaluation:  27%|██▋       | 969/3541 [00:12<00:31, 81.25it/s]retrival evaluation:  28%|██▊       | 978/3541 [00:12<00:31, 80.92it/s]retrival evaluation:  28%|██▊       | 987/3541 [00:12<00:31, 79.98it/s]retrival evaluation:  28%|██▊       | 996/3541 [00:12<00:32, 79.32it/s]retrival evaluation:  28%|██▊       | 1004/3541 [00:12<00:32, 78.90it/s]retrival evaluation:  29%|██▊       | 1012/3541 [00:12<00:31, 79.13it/s]retrival evaluation:  29%|██▉       | 1021/3541 [00:12<00:31, 79.13it/s]retrival evaluation:  29%|██▉       | 1030/3541 [00:12<00:31, 79.83it/s]retrival evaluation:  29%|██▉       | 1038/3541 [00:12<00:31, 79.66it/s]retrival evaluation:  30%|██▉       | 1047/3541 [00:13<00:31, 79.75it/s]retrival evaluation:  30%|██▉       | 1056/3541 [00:13<00:30, 80.56it/s]retrival evaluation:  30%|███       | 1065/3541 [00:13<00:30, 80.86it/s]retrival evaluation:  30%|███       | 1074/3541 [00:13<00:30, 80.65it/s]retrival evaluation:  31%|███       | 1083/3541 [00:13<00:31, 78.85it/s]retrival evaluation:  31%|███       | 1091/3541 [00:13<00:31, 78.96it/s]retrival evaluation:  31%|███       | 1100/3541 [00:13<00:30, 79.53it/s]retrival evaluation:  31%|███▏      | 1108/3541 [00:13<00:30, 78.97it/s]retrival evaluation:  32%|███▏      | 1117/3541 [00:13<00:30, 79.49it/s]retrival evaluation:  32%|███▏      | 1125/3541 [00:14<00:30, 78.76it/s]retrival evaluation:  32%|███▏      | 1134/3541 [00:14<00:30, 79.59it/s]retrival evaluation:  32%|███▏      | 1143/3541 [00:14<00:29, 80.03it/s]retrival evaluation:  33%|███▎      | 1152/3541 [00:14<00:29, 80.02it/s]retrival evaluation:  33%|███▎      | 1161/3541 [00:14<00:29, 80.16it/s]retrival evaluation:  33%|███▎      | 1170/3541 [00:14<00:29, 80.57it/s]retrival evaluation:  33%|███▎      | 1179/3541 [00:14<00:29, 80.71it/s]retrival evaluation:  34%|███▎      | 1188/3541 [00:14<00:31, 74.02it/s]retrival evaluation:  34%|███▍      | 1196/3541 [00:14<00:31, 73.45it/s]retrival evaluation:  34%|███▍      | 1204/3541 [00:15<00:31, 73.05it/s]retrival evaluation:  34%|███▍      | 1212/3541 [00:15<00:31, 72.99it/s]retrival evaluation:  34%|███▍      | 1220/3541 [00:15<00:31, 72.64it/s]retrival evaluation:  35%|███▍      | 1228/3541 [00:15<00:31, 72.59it/s]retrival evaluation:  35%|███▍      | 1236/3541 [00:15<00:31, 72.42it/s]retrival evaluation:  35%|███▌      | 1244/3541 [00:15<00:31, 72.28it/s]retrival evaluation:  35%|███▌      | 1252/3541 [00:15<00:31, 72.23it/s]retrival evaluation:  36%|███▌      | 1260/3541 [00:15<00:31, 72.30it/s]retrival evaluation:  36%|███▌      | 1268/3541 [00:15<00:31, 72.28it/s]retrival evaluation:  36%|███▌      | 1276/3541 [00:16<00:31, 72.34it/s]retrival evaluation:  36%|███▋      | 1284/3541 [00:16<00:31, 72.19it/s]retrival evaluation:  36%|███▋      | 1292/3541 [00:16<00:31, 72.25it/s]retrival evaluation:  37%|███▋      | 1300/3541 [00:16<00:31, 72.27it/s]retrival evaluation:  37%|███▋      | 1308/3541 [00:16<00:30, 72.36it/s]retrival evaluation:  37%|███▋      | 1316/3541 [00:16<00:30, 72.37it/s]retrival evaluation:  37%|███▋      | 1324/3541 [00:16<00:30, 72.30it/s]retrival evaluation:  38%|███▊      | 1332/3541 [00:16<00:30, 72.16it/s]retrival evaluation:  38%|███▊      | 1340/3541 [00:16<00:30, 71.96it/s]retrival evaluation:  38%|███▊      | 1348/3541 [00:17<00:30, 71.85it/s]retrival evaluation:  38%|███▊      | 1356/3541 [00:17<00:30, 71.83it/s]retrival evaluation:  39%|███▊      | 1364/3541 [00:17<00:30, 71.87it/s]retrival evaluation:  39%|███▊      | 1372/3541 [00:17<00:30, 71.73it/s]retrival evaluation:  39%|███▉      | 1380/3541 [00:17<00:30, 71.87it/s]retrival evaluation:  39%|███▉      | 1388/3541 [00:17<00:29, 71.90it/s]retrival evaluation:  39%|███▉      | 1396/3541 [00:17<00:29, 71.91it/s]retrival evaluation:  40%|███▉      | 1404/3541 [00:17<00:29, 71.82it/s]retrival evaluation:  40%|███▉      | 1412/3541 [00:17<00:29, 71.88it/s]retrival evaluation:  40%|████      | 1420/3541 [00:18<00:29, 71.97it/s]retrival evaluation:  40%|████      | 1428/3541 [00:18<00:29, 71.95it/s]retrival evaluation:  41%|████      | 1436/3541 [00:18<00:29, 71.76it/s]retrival evaluation:  41%|████      | 1444/3541 [00:18<00:29, 71.83it/s]retrival evaluation:  41%|████      | 1452/3541 [00:18<00:29, 71.93it/s]retrival evaluation:  41%|████      | 1460/3541 [00:18<00:28, 71.84it/s]retrival evaluation:  41%|████▏     | 1468/3541 [00:18<00:28, 71.76it/s]retrival evaluation:  42%|████▏     | 1476/3541 [00:18<00:28, 71.92it/s]retrival evaluation:  42%|████▏     | 1484/3541 [00:18<00:28, 71.94it/s]retrival evaluation:  42%|████▏     | 1492/3541 [00:19<00:28, 71.83it/s]retrival evaluation:  42%|████▏     | 1500/3541 [00:19<00:28, 71.92it/s]retrival evaluation:  43%|████▎     | 1508/3541 [00:19<00:28, 71.93it/s]retrival evaluation:  43%|████▎     | 1516/3541 [00:19<00:28, 71.91it/s]retrival evaluation:  43%|████▎     | 1524/3541 [00:19<00:28, 71.88it/s]retrival evaluation:  43%|████▎     | 1532/3541 [00:19<00:27, 71.90it/s]retrival evaluation:  43%|████▎     | 1540/3541 [00:19<00:27, 72.01it/s]retrival evaluation:  44%|████▎     | 1548/3541 [00:19<00:27, 71.25it/s]retrival evaluation:  44%|████▍     | 1556/3541 [00:19<00:28, 70.08it/s]retrival evaluation:  44%|████▍     | 1564/3541 [00:20<00:28, 68.93it/s]retrival evaluation:  44%|████▍     | 1571/3541 [00:20<00:28, 68.18it/s]retrival evaluation:  45%|████▍     | 1578/3541 [00:20<00:29, 67.59it/s]retrival evaluation:  45%|████▍     | 1585/3541 [00:20<00:28, 67.70it/s]retrival evaluation:  45%|████▍     | 1592/3541 [00:20<00:28, 68.03it/s]retrival evaluation:  45%|████▌     | 1599/3541 [00:20<00:29, 66.47it/s]retrival evaluation:  45%|████▌     | 1607/3541 [00:20<00:28, 67.95it/s]retrival evaluation:  46%|████▌     | 1615/3541 [00:20<00:27, 69.13it/s]retrival evaluation:  46%|████▌     | 1623/3541 [00:20<00:27, 69.98it/s]retrival evaluation:  46%|████▌     | 1631/3541 [00:21<00:27, 70.53it/s]retrival evaluation:  46%|████▋     | 1639/3541 [00:21<00:26, 70.84it/s]retrival evaluation:  47%|████▋     | 1647/3541 [00:21<00:26, 71.28it/s]retrival evaluation:  47%|████▋     | 1655/3541 [00:21<00:26, 71.52it/s]retrival evaluation:  47%|████▋     | 1663/3541 [00:21<00:26, 71.78it/s]retrival evaluation:  47%|████▋     | 1671/3541 [00:21<00:25, 71.94it/s]retrival evaluation:  47%|████▋     | 1679/3541 [00:21<00:25, 71.94it/s]retrival evaluation:  48%|████▊     | 1687/3541 [00:21<00:25, 72.07it/s]retrival evaluation:  48%|████▊     | 1695/3541 [00:21<00:25, 72.03it/s]retrival evaluation:  48%|████▊     | 1703/3541 [00:22<00:25, 71.86it/s]retrival evaluation:  48%|████▊     | 1711/3541 [00:22<00:25, 72.02it/s]retrival evaluation:  49%|████▊     | 1719/3541 [00:22<00:25, 71.43it/s]retrival evaluation:  49%|████▉     | 1727/3541 [00:22<00:25, 71.11it/s]retrival evaluation:  49%|████▉     | 1735/3541 [00:22<00:25, 71.04it/s]retrival evaluation:  49%|████▉     | 1743/3541 [00:22<00:25, 71.35it/s]retrival evaluation:  49%|████▉     | 1751/3541 [00:22<00:25, 71.46it/s]retrival evaluation:  50%|████▉     | 1759/3541 [00:22<00:24, 71.42it/s]retrival evaluation:  50%|████▉     | 1767/3541 [00:22<00:24, 71.63it/s]retrival evaluation:  50%|█████     | 1775/3541 [00:23<00:24, 71.73it/s]retrival evaluation:  50%|█████     | 1783/3541 [00:23<00:24, 71.62it/s]retrival evaluation:  51%|█████     | 1791/3541 [00:23<00:24, 71.75it/s]retrival evaluation:  51%|█████     | 1799/3541 [00:23<00:24, 71.99it/s]retrival evaluation:  51%|█████     | 1807/3541 [00:23<00:24, 72.06it/s]retrival evaluation:  51%|█████▏    | 1815/3541 [00:23<00:23, 71.97it/s]retrival evaluation:  51%|█████▏    | 1823/3541 [00:23<00:23, 71.90it/s]retrival evaluation:  52%|█████▏    | 1831/3541 [00:23<00:23, 71.90it/s]retrival evaluation:  52%|█████▏    | 1839/3541 [00:23<00:23, 71.98it/s]retrival evaluation:  52%|█████▏    | 1847/3541 [00:24<00:24, 69.91it/s]retrival evaluation:  52%|█████▏    | 1856/3541 [00:24<00:23, 73.03it/s]retrival evaluation:  53%|█████▎    | 1864/3541 [00:24<00:22, 74.94it/s]retrival evaluation:  53%|█████▎    | 1873/3541 [00:24<00:21, 76.70it/s]retrival evaluation:  53%|█████▎    | 1882/3541 [00:24<00:21, 78.65it/s]retrival evaluation:  53%|█████▎    | 1891/3541 [00:24<00:20, 80.04it/s]retrival evaluation:  54%|█████▎    | 1900/3541 [00:24<00:20, 80.77it/s]retrival evaluation:  54%|█████▍    | 1909/3541 [00:24<00:20, 81.04it/s]retrival evaluation:  54%|█████▍    | 1918/3541 [00:24<00:19, 81.31it/s]retrival evaluation:  54%|█████▍    | 1927/3541 [00:25<00:19, 81.89it/s]retrival evaluation:  55%|█████▍    | 1936/3541 [00:25<00:19, 82.12it/s]retrival evaluation:  55%|█████▍    | 1945/3541 [00:25<00:19, 82.34it/s]retrival evaluation:  55%|█████▌    | 1954/3541 [00:25<00:19, 82.37it/s]retrival evaluation:  55%|█████▌    | 1963/3541 [00:25<00:19, 82.59it/s]retrival evaluation:  56%|█████▌    | 1972/3541 [00:25<00:18, 82.74it/s]retrival evaluation:  56%|█████▌    | 1981/3541 [00:25<00:18, 82.48it/s]retrival evaluation:  56%|█████▌    | 1990/3541 [00:25<00:18, 82.58it/s]retrival evaluation:  56%|█████▋    | 1999/3541 [00:25<00:18, 82.45it/s]retrival evaluation:  57%|█████▋    | 2008/3541 [00:26<00:18, 82.55it/s]retrival evaluation:  57%|█████▋    | 2017/3541 [00:26<00:18, 83.22it/s]retrival evaluation:  57%|█████▋    | 2026/3541 [00:26<00:18, 82.76it/s]retrival evaluation:  57%|█████▋    | 2035/3541 [00:26<00:18, 82.27it/s]retrival evaluation:  58%|█████▊    | 2044/3541 [00:26<00:18, 82.36it/s]retrival evaluation:  58%|█████▊    | 2053/3541 [00:26<00:17, 82.83it/s]retrival evaluation:  58%|█████▊    | 2062/3541 [00:26<00:17, 82.81it/s]retrival evaluation:  58%|█████▊    | 2071/3541 [00:26<00:17, 82.54it/s]retrival evaluation:  59%|█████▊    | 2080/3541 [00:26<00:17, 82.69it/s]retrival evaluation:  59%|█████▉    | 2089/3541 [00:27<00:17, 82.28it/s]retrival evaluation:  59%|█████▉    | 2098/3541 [00:27<00:18, 79.48it/s]retrival evaluation:  59%|█████▉    | 2106/3541 [00:27<00:18, 77.23it/s]retrival evaluation:  60%|█████▉    | 2114/3541 [00:27<00:18, 75.74it/s]retrival evaluation:  60%|█████▉    | 2122/3541 [00:27<00:19, 73.06it/s]retrival evaluation:  60%|██████    | 2131/3541 [00:27<00:18, 75.41it/s]retrival evaluation:  60%|██████    | 2140/3541 [00:27<00:18, 77.69it/s]retrival evaluation:  61%|██████    | 2148/3541 [00:27<00:18, 76.65it/s]retrival evaluation:  61%|██████    | 2157/3541 [00:27<00:17, 78.07it/s]retrival evaluation:  61%|██████    | 2166/3541 [00:28<00:17, 79.08it/s]retrival evaluation:  61%|██████▏   | 2174/3541 [00:28<00:17, 78.13it/s]retrival evaluation:  62%|██████▏   | 2182/3541 [00:28<00:17, 76.63it/s]retrival evaluation:  62%|██████▏   | 2190/3541 [00:28<00:17, 75.37it/s]retrival evaluation:  62%|██████▏   | 2198/3541 [00:28<00:17, 74.74it/s]retrival evaluation:  62%|██████▏   | 2206/3541 [00:28<00:17, 75.09it/s]retrival evaluation:  63%|██████▎   | 2215/3541 [00:28<00:17, 77.42it/s]retrival evaluation:  63%|██████▎   | 2223/3541 [00:28<00:17, 77.16it/s]retrival evaluation:  63%|██████▎   | 2232/3541 [00:28<00:16, 78.32it/s]retrival evaluation:  63%|██████▎   | 2241/3541 [00:29<00:16, 79.38it/s]retrival evaluation:  64%|██████▎   | 2250/3541 [00:29<00:16, 80.56it/s]retrival evaluation:  64%|██████▍   | 2259/3541 [00:29<00:15, 81.58it/s]retrival evaluation:  64%|██████▍   | 2268/3541 [00:29<00:16, 79.37it/s]retrival evaluation:  64%|██████▍   | 2277/3541 [00:29<00:15, 79.64it/s]retrival evaluation:  65%|██████▍   | 2286/3541 [00:29<00:15, 80.79it/s]retrival evaluation:  65%|██████▍   | 2295/3541 [00:29<00:15, 81.31it/s]retrival evaluation:  65%|██████▌   | 2304/3541 [00:29<00:15, 78.90it/s]retrival evaluation:  65%|██████▌   | 2312/3541 [00:29<00:15, 76.93it/s]retrival evaluation:  66%|██████▌   | 2320/3541 [00:30<00:15, 76.58it/s]retrival evaluation:  66%|██████▌   | 2328/3541 [00:30<00:16, 74.89it/s]retrival evaluation:  66%|██████▌   | 2337/3541 [00:30<00:15, 77.13it/s]retrival evaluation:  66%|██████▋   | 2346/3541 [00:30<00:15, 78.81it/s]retrival evaluation:  66%|██████▋   | 2354/3541 [00:30<00:15, 78.51it/s]retrival evaluation:  67%|██████▋   | 2363/3541 [00:30<00:14, 79.59it/s]retrival evaluation:  67%|██████▋   | 2372/3541 [00:30<00:14, 80.69it/s]retrival evaluation:  67%|██████▋   | 2381/3541 [00:30<00:14, 79.24it/s]retrival evaluation:  67%|██████▋   | 2390/3541 [00:30<00:14, 79.82it/s]retrival evaluation:  68%|██████▊   | 2399/3541 [00:31<00:14, 80.41it/s]retrival evaluation:  68%|██████▊   | 2408/3541 [00:31<00:13, 81.09it/s]retrival evaluation:  68%|██████▊   | 2417/3541 [00:31<00:13, 81.28it/s]retrival evaluation:  69%|██████▊   | 2426/3541 [00:31<00:13, 82.03it/s]retrival evaluation:  69%|██████▉   | 2435/3541 [00:31<00:13, 82.25it/s]retrival evaluation:  69%|██████▉   | 2444/3541 [00:31<00:13, 80.71it/s]retrival evaluation:  69%|██████▉   | 2453/3541 [00:31<00:13, 80.62it/s]retrival evaluation:  70%|██████▉   | 2462/3541 [00:31<00:13, 81.62it/s]retrival evaluation:  70%|██████▉   | 2471/3541 [00:31<00:13, 82.04it/s]retrival evaluation:  70%|███████   | 2480/3541 [00:31<00:12, 82.40it/s]retrival evaluation:  70%|███████   | 2489/3541 [00:32<00:12, 82.85it/s]retrival evaluation:  71%|███████   | 2498/3541 [00:32<00:12, 82.40it/s]retrival evaluation:  71%|███████   | 2507/3541 [00:32<00:12, 80.01it/s]retrival evaluation:  71%|███████   | 2516/3541 [00:32<00:13, 78.11it/s]retrival evaluation:  71%|███████▏  | 2524/3541 [00:32<00:13, 76.76it/s]retrival evaluation:  72%|███████▏  | 2532/3541 [00:32<00:13, 77.05it/s]retrival evaluation:  72%|███████▏  | 2541/3541 [00:32<00:12, 78.21it/s]retrival evaluation:  72%|███████▏  | 2550/3541 [00:32<00:12, 79.12it/s]retrival evaluation:  72%|███████▏  | 2558/3541 [00:32<00:12, 78.80it/s]retrival evaluation:  72%|███████▏  | 2567/3541 [00:33<00:12, 79.63it/s]retrival evaluation:  73%|███████▎  | 2576/3541 [00:33<00:11, 80.83it/s]retrival evaluation:  73%|███████▎  | 2585/3541 [00:33<00:11, 81.39it/s]retrival evaluation:  73%|███████▎  | 2594/3541 [00:33<00:11, 81.49it/s]retrival evaluation:  74%|███████▎  | 2603/3541 [00:33<00:11, 82.16it/s]retrival evaluation:  74%|███████▍  | 2612/3541 [00:33<00:11, 81.84it/s]retrival evaluation:  74%|███████▍  | 2621/3541 [00:33<00:11, 81.78it/s]retrival evaluation:  74%|███████▍  | 2630/3541 [00:33<00:11, 80.02it/s]retrival evaluation:  75%|███████▍  | 2639/3541 [00:33<00:11, 80.86it/s]retrival evaluation:  75%|███████▍  | 2648/3541 [00:34<00:10, 81.20it/s]retrival evaluation:  75%|███████▌  | 2657/3541 [00:34<00:10, 81.47it/s]retrival evaluation:  75%|███████▌  | 2666/3541 [00:34<00:10, 82.23it/s]retrival evaluation:  76%|███████▌  | 2675/3541 [00:34<00:10, 81.85it/s]retrival evaluation:  76%|███████▌  | 2684/3541 [00:34<00:10, 81.80it/s]retrival evaluation:  76%|███████▌  | 2693/3541 [00:34<00:10, 82.22it/s]retrival evaluation:  76%|███████▋  | 2702/3541 [00:34<00:10, 82.41it/s]retrival evaluation:  77%|███████▋  | 2711/3541 [00:34<00:10, 82.25it/s]retrival evaluation:  77%|███████▋  | 2720/3541 [00:34<00:10, 81.49it/s]retrival evaluation:  77%|███████▋  | 2729/3541 [00:35<00:10, 80.65it/s]retrival evaluation:  77%|███████▋  | 2738/3541 [00:35<00:09, 80.69it/s]retrival evaluation:  78%|███████▊  | 2747/3541 [00:35<00:09, 81.11it/s]retrival evaluation:  78%|███████▊  | 2756/3541 [00:35<00:09, 81.80it/s]retrival evaluation:  78%|███████▊  | 2765/3541 [00:35<00:09, 82.10it/s]retrival evaluation:  78%|███████▊  | 2774/3541 [00:35<00:09, 82.01it/s]retrival evaluation:  79%|███████▊  | 2783/3541 [00:35<00:09, 82.39it/s]retrival evaluation:  79%|███████▉  | 2792/3541 [00:35<00:09, 82.50it/s]retrival evaluation:  79%|███████▉  | 2801/3541 [00:35<00:09, 82.05it/s]retrival evaluation:  79%|███████▉  | 2810/3541 [00:36<00:09, 78.40it/s]retrival evaluation:  80%|███████▉  | 2818/3541 [00:36<00:09, 76.75it/s]retrival evaluation:  80%|███████▉  | 2826/3541 [00:36<00:09, 76.41it/s]retrival evaluation:  80%|████████  | 2834/3541 [00:36<00:09, 76.16it/s]retrival evaluation:  80%|████████  | 2843/3541 [00:36<00:08, 78.19it/s]retrival evaluation:  81%|████████  | 2852/3541 [00:36<00:08, 79.35it/s]retrival evaluation:  81%|████████  | 2861/3541 [00:36<00:08, 79.83it/s]retrival evaluation:  81%|████████  | 2870/3541 [00:36<00:08, 80.69it/s]retrival evaluation:  81%|████████▏ | 2879/3541 [00:36<00:08, 81.43it/s]retrival evaluation:  82%|████████▏ | 2888/3541 [00:37<00:08, 80.57it/s]retrival evaluation:  82%|████████▏ | 2897/3541 [00:37<00:07, 81.26it/s]retrival evaluation:  82%|████████▏ | 2906/3541 [00:37<00:07, 81.72it/s]retrival evaluation:  82%|████████▏ | 2915/3541 [00:37<00:07, 81.63it/s]retrival evaluation:  83%|████████▎ | 2924/3541 [00:37<00:07, 81.63it/s]retrival evaluation:  83%|████████▎ | 2933/3541 [00:37<00:07, 81.99it/s]retrival evaluation:  83%|████████▎ | 2942/3541 [00:37<00:07, 82.38it/s]retrival evaluation:  83%|████████▎ | 2951/3541 [00:37<00:07, 82.19it/s]retrival evaluation:  84%|████████▎ | 2960/3541 [00:37<00:07, 82.56it/s]retrival evaluation:  84%|████████▍ | 2969/3541 [00:38<00:06, 82.44it/s]retrival evaluation:  84%|████████▍ | 2978/3541 [00:38<00:06, 82.16it/s]retrival evaluation:  84%|████████▍ | 2987/3541 [00:38<00:06, 82.37it/s]retrival evaluation:  85%|████████▍ | 2996/3541 [00:38<00:06, 82.62it/s]retrival evaluation:  85%|████████▍ | 3005/3541 [00:38<00:06, 82.28it/s]retrival evaluation:  85%|████████▌ | 3014/3541 [00:38<00:06, 80.37it/s]retrival evaluation:  85%|████████▌ | 3023/3541 [00:38<00:06, 81.26it/s]retrival evaluation:  86%|████████▌ | 3032/3541 [00:38<00:06, 81.59it/s]retrival evaluation:  86%|████████▌ | 3041/3541 [00:38<00:06, 81.47it/s]retrival evaluation:  86%|████████▌ | 3050/3541 [00:39<00:06, 81.80it/s]retrival evaluation:  86%|████████▋ | 3059/3541 [00:39<00:05, 82.28it/s]retrival evaluation:  87%|████████▋ | 3068/3541 [00:39<00:05, 82.28it/s]retrival evaluation:  87%|████████▋ | 3077/3541 [00:39<00:05, 82.25it/s]retrival evaluation:  87%|████████▋ | 3086/3541 [00:39<00:05, 82.78it/s]retrival evaluation:  87%|████████▋ | 3095/3541 [00:39<00:05, 82.44it/s]retrival evaluation:  88%|████████▊ | 3104/3541 [00:39<00:05, 82.19it/s]retrival evaluation:  88%|████████▊ | 3113/3541 [00:39<00:05, 82.64it/s]retrival evaluation:  88%|████████▊ | 3122/3541 [00:39<00:05, 82.62it/s]retrival evaluation:  88%|████████▊ | 3131/3541 [00:40<00:04, 82.46it/s]retrival evaluation:  89%|████████▊ | 3140/3541 [00:40<00:04, 82.50it/s]retrival evaluation:  89%|████████▉ | 3149/3541 [00:40<00:04, 82.53it/s]retrival evaluation:  89%|████████▉ | 3158/3541 [00:40<00:04, 80.10it/s]retrival evaluation:  89%|████████▉ | 3167/3541 [00:40<00:04, 80.83it/s]retrival evaluation:  90%|████████▉ | 3176/3541 [00:40<00:04, 81.61it/s]retrival evaluation:  90%|████████▉ | 3185/3541 [00:40<00:04, 81.63it/s]retrival evaluation:  90%|█████████ | 3194/3541 [00:40<00:04, 81.91it/s]retrival evaluation:  90%|█████████ | 3203/3541 [00:40<00:04, 82.43it/s]retrival evaluation:  91%|█████████ | 3212/3541 [00:41<00:04, 82.21it/s]retrival evaluation:  91%|█████████ | 3221/3541 [00:41<00:03, 81.96it/s]retrival evaluation:  91%|█████████ | 3230/3541 [00:41<00:03, 82.35it/s]retrival evaluation:  91%|█████████▏| 3239/3541 [00:41<00:03, 82.66it/s]retrival evaluation:  92%|█████████▏| 3248/3541 [00:41<00:03, 82.32it/s]retrival evaluation:  92%|█████████▏| 3257/3541 [00:41<00:03, 82.75it/s]retrival evaluation:  92%|█████████▏| 3266/3541 [00:41<00:03, 82.65it/s]retrival evaluation:  92%|█████████▏| 3275/3541 [00:41<00:03, 82.30it/s]retrival evaluation:  93%|█████████▎| 3284/3541 [00:41<00:03, 81.38it/s]retrival evaluation:  93%|█████████▎| 3293/3541 [00:42<00:03, 78.75it/s]retrival evaluation:  93%|█████████▎| 3301/3541 [00:42<00:03, 78.00it/s]retrival evaluation:  93%|█████████▎| 3309/3541 [00:42<00:03, 77.03it/s]retrival evaluation:  94%|█████████▎| 3317/3541 [00:42<00:02, 77.36it/s]retrival evaluation:  94%|█████████▍| 3326/3541 [00:42<00:02, 79.24it/s]retrival evaluation:  94%|█████████▍| 3335/3541 [00:42<00:02, 80.23it/s]retrival evaluation:  94%|█████████▍| 3344/3541 [00:42<00:02, 81.37it/s]retrival evaluation:  95%|█████████▍| 3353/3541 [00:42<00:02, 82.27it/s]retrival evaluation:  95%|█████████▍| 3362/3541 [00:42<00:02, 82.53it/s]retrival evaluation:  95%|█████████▌| 3371/3541 [00:42<00:02, 82.77it/s]retrival evaluation:  95%|█████████▌| 3380/3541 [00:43<00:01, 83.29it/s]retrival evaluation:  96%|█████████▌| 3389/3541 [00:43<00:01, 82.25it/s]retrival evaluation:  96%|█████████▌| 3398/3541 [00:43<00:01, 82.09it/s]retrival evaluation:  96%|█████████▌| 3407/3541 [00:43<00:01, 82.04it/s]retrival evaluation:  96%|█████████▋| 3416/3541 [00:43<00:01, 80.94it/s]retrival evaluation:  97%|█████████▋| 3425/3541 [00:43<00:01, 79.84it/s]retrival evaluation:  97%|█████████▋| 3433/3541 [00:43<00:01, 79.85it/s]retrival evaluation:  97%|█████████▋| 3442/3541 [00:43<00:01, 80.62it/s]retrival evaluation:  97%|█████████▋| 3451/3541 [00:43<00:01, 81.43it/s]retrival evaluation:  98%|█████████▊| 3460/3541 [00:44<00:00, 81.78it/s]retrival evaluation:  98%|█████████▊| 3469/3541 [00:44<00:00, 82.26it/s]retrival evaluation:  98%|█████████▊| 3478/3541 [00:44<00:00, 82.78it/s]retrival evaluation:  98%|█████████▊| 3487/3541 [00:44<00:00, 82.47it/s]retrival evaluation:  99%|█████████▊| 3496/3541 [00:44<00:00, 82.36it/s]retrival evaluation:  99%|█████████▉| 3505/3541 [00:44<00:00, 83.00it/s]retrival evaluation:  99%|█████████▉| 3514/3541 [00:44<00:00, 83.02it/s]retrival evaluation:  99%|█████████▉| 3523/3541 [00:44<00:00, 82.65it/s]retrival evaluation: 100%|█████████▉| 3532/3541 [00:44<00:00, 82.74it/s]retrival evaluation: 100%|██████████| 3541/3541 [00:45<00:00, 84.33it/s]retrival evaluation: 100%|██████████| 3541/3541 [00:45<00:00, 78.61it/s]

pk3=0, pk2=0,pk1=0 best_f1 = 0.025, bets_f2=0.046, MAP=0.036, MRR=0, AP=0.009, exe_time=253.71954345703125

INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:__main__:model loaded
INFO:EMSE.BERTDataReader:Creating examples from dataset file at /afs/crc.nd.edu/user/j/jlin6/data/EMSE/canal/test
update feature:   0%|          | 0/28 [00:00<?, ?it/s]update feature:  46%|████▋     | 13/28 [00:00<00:00, 128.00it/s]update feature: 100%|██████████| 28/28 [00:00<00:00, 169.35it/s]
update feature:   0%|          | 0/28 [00:00<?, ?it/s]update feature: 100%|██████████| 28/28 [00:00<00:00, 474.30it/s]
update embedding:   0%|          | 0/28 [00:00<?, ?it/s]update embedding:   4%|▎         | 1/28 [00:00<00:24,  1.10it/s]update embedding:   7%|▋         | 2/28 [00:01<00:23,  1.12it/s]update embedding:  11%|█         | 3/28 [00:02<00:21,  1.17it/s]update embedding:  14%|█▍        | 4/28 [00:03<00:20,  1.16it/s]update embedding:  18%|█▊        | 5/28 [00:04<00:19,  1.16it/s]update embedding:  21%|██▏       | 6/28 [00:05<00:18,  1.18it/s]update embedding:  25%|██▌       | 7/28 [00:05<00:17,  1.19it/s]update embedding:  29%|██▊       | 8/28 [00:06<00:16,  1.20it/s]update embedding:  32%|███▏      | 9/28 [00:07<00:15,  1.21it/s]update embedding:  36%|███▌      | 10/28 [00:08<00:15,  1.19it/s]update embedding:  39%|███▉      | 11/28 [00:09<00:14,  1.20it/s]update embedding:  43%|████▎     | 12/28 [00:10<00:13,  1.22it/s]update embedding:  46%|████▋     | 13/28 [00:10<00:12,  1.23it/s]update embedding:  50%|█████     | 14/28 [00:11<00:11,  1.24it/s]update embedding:  54%|█████▎    | 15/28 [00:12<00:10,  1.25it/s]update embedding:  57%|█████▋    | 16/28 [00:13<00:09,  1.24it/s]update embedding:  61%|██████    | 17/28 [00:14<00:09,  1.22it/s]update embedding:  64%|██████▍   | 18/28 [00:14<00:08,  1.21it/s]update embedding:  68%|██████▊   | 19/28 [00:15<00:07,  1.24it/s]update embedding:  71%|███████▏  | 20/28 [00:16<00:06,  1.26it/s]update embedding:  75%|███████▌  | 21/28 [00:17<00:05,  1.27it/s]update embedding:  79%|███████▊  | 22/28 [00:17<00:04,  1.26it/s]update embedding:  82%|████████▏ | 23/28 [00:18<00:04,  1.24it/s]update embedding:  86%|████████▌ | 24/28 [00:19<00:03,  1.25it/s]update embedding:  89%|████████▉ | 25/28 [00:20<00:02,  1.27it/s]update embedding:  93%|█████████▎| 26/28 [00:21<00:01,  1.29it/s]update embedding:  96%|█████████▋| 27/28 [00:21<00:00,  1.29it/s]update embedding: 100%|██████████| 28/28 [00:22<00:00,  1.30it/s]update embedding: 100%|██████████| 28/28 [00:22<00:00,  1.24it/s]
update embedding:   0%|          | 0/28 [00:00<?, ?it/s]update embedding:   4%|▎         | 1/28 [00:00<00:21,  1.28it/s]update embedding:   7%|▋         | 2/28 [00:01<00:20,  1.28it/s]update embedding:  11%|█         | 3/28 [00:02<00:19,  1.30it/s]update embedding:  14%|█▍        | 4/28 [00:03<00:18,  1.31it/s]update embedding:  18%|█▊        | 5/28 [00:03<00:17,  1.32it/s]update embedding:  21%|██▏       | 6/28 [00:04<00:16,  1.32it/s]update embedding:  25%|██▌       | 7/28 [00:05<00:15,  1.32it/s]update embedding:  29%|██▊       | 8/28 [00:06<00:15,  1.32it/s]update embedding:  32%|███▏      | 9/28 [00:06<00:14,  1.30it/s]update embedding:  36%|███▌      | 10/28 [00:07<00:13,  1.31it/s]update embedding:  39%|███▉      | 11/28 [00:08<00:13,  1.30it/s]update embedding:  43%|████▎     | 12/28 [00:09<00:12,  1.32it/s]update embedding:  46%|████▋     | 13/28 [00:09<00:11,  1.32it/s]update embedding:  50%|█████     | 14/28 [00:10<00:10,  1.34it/s]update embedding:  54%|█████▎    | 15/28 [00:11<00:09,  1.31it/s]update embedding:  57%|█████▋    | 16/28 [00:12<00:09,  1.28it/s]update embedding:  61%|██████    | 17/28 [00:13<00:08,  1.27it/s]update embedding:  64%|██████▍   | 18/28 [00:13<00:07,  1.25it/s]update embedding:  68%|██████▊   | 19/28 [00:14<00:07,  1.24it/s]update embedding:  71%|███████▏  | 20/28 [00:15<00:06,  1.23it/s]update embedding:  75%|███████▌  | 21/28 [00:16<00:05,  1.23it/s]update embedding:  79%|███████▊  | 22/28 [00:17<00:04,  1.22it/s]update embedding:  82%|████████▏ | 23/28 [00:18<00:04,  1.21it/s]update embedding:  86%|████████▌ | 24/28 [00:18<00:03,  1.22it/s]update embedding:  89%|████████▉ | 25/28 [00:19<00:02,  1.22it/s]update embedding:  93%|█████████▎| 26/28 [00:20<00:01,  1.22it/s]update embedding:  96%|█████████▋| 27/28 [00:21<00:00,  1.22it/s]update embedding: 100%|██████████| 28/28 [00:22<00:00,  1.22it/s]update embedding: 100%|██████████| 28/28 [00:22<00:00,  1.27it/s]
retrival evaluation:   0%|          | 0/196 [00:00<?, ?it/s]retrival evaluation:   4%|▎         | 7/196 [00:00<00:02, 64.91it/s]retrival evaluation:   8%|▊         | 15/196 [00:00<00:02, 67.68it/s]retrival evaluation:  12%|█▏        | 23/196 [00:00<00:02, 70.16it/s]retrival evaluation:  16%|█▌        | 31/196 [00:00<00:02, 71.98it/s]retrival evaluation:  20%|█▉        | 39/196 [00:00<00:02, 73.37it/s]retrival evaluation:  24%|██▍       | 47/196 [00:00<00:02, 73.13it/s]retrival evaluation:  28%|██▊       | 55/196 [00:00<00:01, 74.27it/s]retrival evaluation:  32%|███▏      | 63/196 [00:00<00:01, 75.14it/s]retrival evaluation:  36%|███▌      | 71/196 [00:00<00:01, 75.75it/s]retrival evaluation:  40%|████      | 79/196 [00:01<00:01, 76.18it/s]retrival evaluation:  44%|████▍     | 87/196 [00:01<00:01, 76.44it/s]retrival evaluation:  48%|████▊     | 95/196 [00:01<00:01, 71.61it/s]retrival evaluation:  53%|█████▎    | 103/196 [00:01<00:01, 70.77it/s]retrival evaluation:  57%|█████▋    | 111/196 [00:01<00:01, 71.92it/s]retrival evaluation:  61%|██████    | 119/196 [00:01<00:01, 72.32it/s]retrival evaluation:  65%|██████▍   | 127/196 [00:01<00:00, 72.26it/s]retrival evaluation:  69%|██████▉   | 135/196 [00:01<00:00, 72.57it/s]retrival evaluation:  73%|███████▎  | 143/196 [00:01<00:00, 65.00it/s]retrival evaluation:  77%|███████▋  | 151/196 [00:02<00:00, 66.94it/s]retrival evaluation:  81%|████████  | 159/196 [00:02<00:00, 69.19it/s]retrival evaluation:  85%|████████▌ | 167/196 [00:02<00:00, 70.39it/s]retrival evaluation:  89%|████████▉ | 175/196 [00:02<00:00, 70.83it/s]retrival evaluation:  93%|█████████▎| 183/196 [00:02<00:00, 71.93it/s]retrival evaluation:  97%|█████████▋| 191/196 [00:02<00:00, 67.24it/s]retrival evaluation: 100%|██████████| 196/196 [00:02<00:00, 71.65it/s]

pk3=0, pk2=0,pk1=0 best_f1 = 0.104, bets_f2=0.157, MAP=0.137, MRR=0, AP=0.041, exe_time=47.81457734107971

INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:__main__:model loaded
INFO:EMSE.BERTDataReader:Creating examples from dataset file at /afs/crc.nd.edu/user/j/jlin6/data/EMSE/druid/test
update feature:   0%|          | 0/118 [00:00<?, ?it/s]update feature:   8%|▊         | 9/118 [00:00<00:01, 65.72it/s]update feature:  13%|█▎        | 15/118 [00:00<00:01, 62.59it/s]update feature:  23%|██▎       | 27/118 [00:00<00:01, 71.84it/s]update feature:  28%|██▊       | 33/118 [00:00<00:01, 66.31it/s]update feature:  33%|███▎      | 39/118 [00:00<00:01, 60.79it/s]update feature:  38%|███▊      | 45/118 [00:00<00:01, 59.39it/s]update feature:  45%|████▍     | 53/118 [00:00<00:01, 63.54it/s]update feature:  59%|█████▉    | 70/118 [00:00<00:00, 74.60it/s]update feature:  67%|██████▋   | 79/118 [00:01<00:00, 64.65it/s]update feature:  76%|███████▋  | 90/118 [00:01<00:00, 73.74it/s]update feature:  84%|████████▍ | 99/118 [00:01<00:00, 61.48it/s]update feature:  91%|█████████ | 107/118 [00:01<00:00, 65.20it/s]update feature:  97%|█████████▋| 115/118 [00:01<00:00, 61.02it/s]update feature: 100%|██████████| 118/118 [00:01<00:00, 69.92it/s]
update feature:   0%|          | 0/118 [00:00<?, ?it/s]update feature:  70%|███████   | 83/118 [00:00<00:00, 815.97it/s]update feature: 100%|██████████| 118/118 [00:00<00:00, 858.10it/s]
update embedding:   0%|          | 0/118 [00:00<?, ?it/s]update embedding:   1%|          | 1/118 [00:00<01:38,  1.19it/s]update embedding:   2%|▏         | 2/118 [00:01<01:37,  1.19it/s]update embedding:   3%|▎         | 3/118 [00:02<01:35,  1.20it/s]update embedding:   3%|▎         | 4/118 [00:03<01:32,  1.23it/s]update embedding:   4%|▍         | 5/118 [00:04<01:31,  1.24it/s]update embedding:   5%|▌         | 6/118 [00:04<01:29,  1.25it/s]update embedding:   6%|▌         | 7/118 [00:05<01:27,  1.27it/s]update embedding:   7%|▋         | 8/118 [00:06<01:25,  1.28it/s]update embedding:   8%|▊         | 9/118 [00:07<01:24,  1.30it/s]update embedding:   8%|▊         | 10/118 [00:07<01:23,  1.30it/s]update embedding:   9%|▉         | 11/118 [00:08<01:22,  1.30it/s]update embedding:  10%|█         | 12/118 [00:09<01:20,  1.31it/s]update embedding:  11%|█         | 13/118 [00:10<01:20,  1.30it/s]update embedding:  12%|█▏        | 14/118 [00:10<01:19,  1.31it/s]update embedding:  13%|█▎        | 15/118 [00:11<01:18,  1.30it/s]update embedding:  14%|█▎        | 16/118 [00:12<01:17,  1.31it/s]update embedding:  14%|█▍        | 17/118 [00:13<01:17,  1.31it/s]update embedding:  15%|█▌        | 18/118 [00:13<01:16,  1.31it/s]update embedding:  16%|█▌        | 19/118 [00:14<01:15,  1.31it/s]update embedding:  17%|█▋        | 20/118 [00:15<01:14,  1.32it/s]update embedding:  18%|█▊        | 21/118 [00:16<01:14,  1.30it/s]update embedding:  19%|█▊        | 22/118 [00:17<01:13,  1.30it/s]update embedding:  19%|█▉        | 23/118 [00:17<01:12,  1.31it/s]update embedding:  20%|██        | 24/118 [00:18<01:10,  1.33it/s]update embedding:  21%|██        | 25/118 [00:19<01:08,  1.35it/s]update embedding:  22%|██▏       | 26/118 [00:19<01:07,  1.37it/s]update embedding:  23%|██▎       | 27/118 [00:20<01:05,  1.38it/s]update embedding:  24%|██▎       | 28/118 [00:21<01:06,  1.36it/s]update embedding:  25%|██▍       | 29/118 [00:22<01:07,  1.31it/s]update embedding:  25%|██▌       | 30/118 [00:23<01:09,  1.27it/s]update embedding:  26%|██▋       | 31/118 [00:23<01:09,  1.26it/s]update embedding:  27%|██▋       | 32/118 [00:24<01:09,  1.25it/s]update embedding:  28%|██▊       | 33/118 [00:25<01:08,  1.24it/s]update embedding:  29%|██▉       | 34/118 [00:26<01:08,  1.23it/s]update embedding:  30%|██▉       | 35/118 [00:27<01:07,  1.23it/s]update embedding:  31%|███       | 36/118 [00:28<01:07,  1.22it/s]update embedding:  31%|███▏      | 37/118 [00:28<01:06,  1.22it/s]update embedding:  32%|███▏      | 38/118 [00:29<01:05,  1.22it/s]update embedding:  33%|███▎      | 39/118 [00:30<01:04,  1.22it/s]update embedding:  34%|███▍      | 40/118 [00:31<01:03,  1.22it/s]update embedding:  35%|███▍      | 41/118 [00:32<01:02,  1.22it/s]update embedding:  36%|███▌      | 42/118 [00:32<01:01,  1.23it/s]update embedding:  36%|███▋      | 43/118 [00:33<01:01,  1.23it/s]update embedding:  37%|███▋      | 44/118 [00:34<01:00,  1.23it/s]update embedding:  38%|███▊      | 45/118 [00:35<00:59,  1.23it/s]update embedding:  39%|███▉      | 46/118 [00:36<00:58,  1.23it/s]update embedding:  40%|███▉      | 47/118 [00:36<00:57,  1.23it/s]update embedding:  41%|████      | 48/118 [00:37<00:58,  1.19it/s]update embedding:  42%|████▏     | 49/118 [00:38<00:57,  1.20it/s]update embedding:  42%|████▏     | 50/118 [00:39<00:56,  1.21it/s]update embedding:  43%|████▎     | 51/118 [00:40<00:55,  1.22it/s]update embedding:  44%|████▍     | 52/118 [00:41<00:53,  1.22it/s]update embedding:  45%|████▍     | 53/118 [00:42<00:55,  1.18it/s]update embedding:  46%|████▌     | 54/118 [00:42<00:53,  1.19it/s]update embedding:  47%|████▋     | 55/118 [00:43<00:52,  1.20it/s]update embedding:  47%|████▋     | 56/118 [00:44<00:51,  1.21it/s]update embedding:  48%|████▊     | 57/118 [00:45<00:49,  1.22it/s]update embedding:  49%|████▉     | 58/118 [00:46<00:48,  1.23it/s]update embedding:  50%|█████     | 59/118 [00:46<00:47,  1.24it/s]update embedding:  51%|█████     | 60/118 [00:47<00:46,  1.24it/s]update embedding:  52%|█████▏    | 61/118 [00:48<00:46,  1.23it/s]update embedding:  53%|█████▎    | 62/118 [00:49<00:45,  1.24it/s]update embedding:  53%|█████▎    | 63/118 [00:50<00:45,  1.22it/s]update embedding:  54%|█████▍    | 64/118 [00:51<00:44,  1.22it/s]update embedding:  55%|█████▌    | 65/118 [00:51<00:43,  1.21it/s]update embedding:  56%|█████▌    | 66/118 [00:52<00:42,  1.22it/s]update embedding:  57%|█████▋    | 67/118 [00:53<00:42,  1.21it/s]update embedding:  58%|█████▊    | 68/118 [00:54<00:41,  1.20it/s]update embedding:  58%|█████▊    | 69/118 [00:55<00:39,  1.23it/s]update embedding:  59%|█████▉    | 70/118 [00:55<00:38,  1.24it/s]update embedding:  60%|██████    | 71/118 [00:56<00:37,  1.26it/s]update embedding:  61%|██████    | 72/118 [00:57<00:36,  1.27it/s]update embedding:  62%|██████▏   | 73/118 [00:58<00:35,  1.28it/s]update embedding:  63%|██████▎   | 74/118 [00:58<00:34,  1.29it/s]update embedding:  64%|██████▎   | 75/118 [00:59<00:34,  1.25it/s]update embedding:  64%|██████▍   | 76/118 [01:00<00:33,  1.27it/s]update embedding:  65%|██████▌   | 77/118 [01:01<00:32,  1.27it/s]update embedding:  66%|██████▌   | 78/118 [01:02<00:31,  1.28it/s]update embedding:  67%|██████▋   | 79/118 [01:02<00:31,  1.24it/s]update embedding:  68%|██████▊   | 80/118 [01:03<00:32,  1.18it/s]update embedding:  69%|██████▊   | 81/118 [01:04<00:30,  1.20it/s]update embedding:  69%|██████▉   | 82/118 [01:05<00:29,  1.22it/s]update embedding:  70%|███████   | 83/118 [01:06<00:28,  1.24it/s]update embedding:  71%|███████   | 84/118 [01:07<00:26,  1.26it/s]update embedding:  72%|███████▏  | 85/118 [01:07<00:25,  1.28it/s]update embedding:  73%|███████▎  | 86/118 [01:08<00:25,  1.25it/s]update embedding:  74%|███████▎  | 87/118 [01:09<00:24,  1.26it/s]update embedding:  75%|███████▍  | 88/118 [01:10<00:23,  1.26it/s]update embedding:  75%|███████▌  | 89/118 [01:11<00:22,  1.27it/s]update embedding:  76%|███████▋  | 90/118 [01:11<00:21,  1.28it/s]update embedding:  77%|███████▋  | 91/118 [01:12<00:20,  1.30it/s]update embedding:  78%|███████▊  | 92/118 [01:13<00:19,  1.31it/s]update embedding:  79%|███████▉  | 93/118 [01:14<00:18,  1.32it/s]update embedding:  80%|███████▉  | 94/118 [01:14<00:18,  1.32it/s]update embedding:  81%|████████  | 95/118 [01:15<00:17,  1.29it/s]update embedding:  81%|████████▏ | 96/118 [01:16<00:17,  1.24it/s]update embedding:  82%|████████▏ | 97/118 [01:17<00:17,  1.20it/s]update embedding:  83%|████████▎ | 98/118 [01:18<00:17,  1.17it/s]update embedding:  84%|████████▍ | 99/118 [01:19<00:16,  1.15it/s]update embedding:  85%|████████▍ | 100/118 [01:20<00:16,  1.10it/s]update embedding:  86%|████████▌ | 101/118 [01:21<00:15,  1.10it/s]update embedding:  86%|████████▋ | 102/118 [01:22<00:14,  1.09it/s]update embedding:  87%|████████▋ | 103/118 [01:22<00:13,  1.09it/s]update embedding:  88%|████████▊ | 104/118 [01:23<00:13,  1.07it/s]update embedding:  89%|████████▉ | 105/118 [01:24<00:12,  1.08it/s]update embedding:  90%|████████▉ | 106/118 [01:25<00:11,  1.09it/s]update embedding:  91%|█████████ | 107/118 [01:26<00:10,  1.10it/s]update embedding:  92%|█████████▏| 108/118 [01:27<00:09,  1.10it/s]update embedding:  92%|█████████▏| 109/118 [01:28<00:08,  1.12it/s]update embedding:  93%|█████████▎| 110/118 [01:29<00:07,  1.12it/s]update embedding:  94%|█████████▍| 111/118 [01:30<00:06,  1.13it/s]update embedding:  95%|█████████▍| 112/118 [01:31<00:05,  1.13it/s]update embedding:  96%|█████████▌| 113/118 [01:31<00:04,  1.13it/s]update embedding:  97%|█████████▋| 114/118 [01:32<00:03,  1.12it/s]update embedding:  97%|█████████▋| 115/118 [01:33<00:02,  1.13it/s]update embedding:  98%|█████████▊| 116/118 [01:34<00:01,  1.13it/s]update embedding:  99%|█████████▉| 117/118 [01:35<00:00,  1.13it/s]update embedding: 100%|██████████| 118/118 [01:36<00:00,  1.13it/s]update embedding: 100%|██████████| 118/118 [01:36<00:00,  1.22it/s]
update embedding:   0%|          | 0/118 [00:00<?, ?it/s]update embedding:   1%|          | 1/118 [00:00<01:42,  1.14it/s]update embedding:   2%|▏         | 2/118 [00:01<01:41,  1.14it/s]update embedding:   3%|▎         | 3/118 [00:02<01:41,  1.14it/s]update embedding:   3%|▎         | 4/118 [00:03<01:40,  1.14it/s]update embedding:   4%|▍         | 5/118 [00:04<01:38,  1.15it/s]update embedding:   5%|▌         | 6/118 [00:05<01:38,  1.13it/s]update embedding:   6%|▌         | 7/118 [00:06<01:37,  1.14it/s]update embedding:   7%|▋         | 8/118 [00:07<01:36,  1.14it/s]update embedding:   8%|▊         | 9/118 [00:07<01:35,  1.15it/s]update embedding:   8%|▊         | 10/118 [00:08<01:33,  1.15it/s]update embedding:   9%|▉         | 11/118 [00:09<01:32,  1.15it/s]update embedding:  10%|█         | 12/118 [00:10<01:31,  1.16it/s]update embedding:  11%|█         | 13/118 [00:11<01:31,  1.15it/s]update embedding:  12%|█▏        | 14/118 [00:12<01:30,  1.15it/s]update embedding:  13%|█▎        | 15/118 [00:13<01:29,  1.16it/s]update embedding:  14%|█▎        | 16/118 [00:13<01:28,  1.16it/s]update embedding:  14%|█▍        | 17/118 [00:14<01:26,  1.17it/s]update embedding:  15%|█▌        | 18/118 [00:15<01:27,  1.15it/s]update embedding:  16%|█▌        | 19/118 [00:16<01:26,  1.14it/s]update embedding:  17%|█▋        | 20/118 [00:17<01:25,  1.14it/s]update embedding:  18%|█▊        | 21/118 [00:18<01:24,  1.15it/s]update embedding:  19%|█▊        | 22/118 [00:19<01:23,  1.15it/s]update embedding:  19%|█▉        | 23/118 [00:20<01:22,  1.15it/s]update embedding:  20%|██        | 24/118 [00:20<01:21,  1.15it/s]update embedding:  21%|██        | 25/118 [00:21<01:20,  1.15it/s]update embedding:  22%|██▏       | 26/118 [00:22<01:19,  1.16it/s]update embedding:  23%|██▎       | 27/118 [00:23<01:18,  1.16it/s]update embedding:  24%|██▎       | 28/118 [00:24<01:17,  1.16it/s]update embedding:  25%|██▍       | 29/118 [00:25<01:16,  1.16it/s]update embedding:  25%|██▌       | 30/118 [00:26<01:16,  1.14it/s]update embedding:  26%|██▋       | 31/118 [00:26<01:15,  1.15it/s]update embedding:  27%|██▋       | 32/118 [00:27<01:14,  1.15it/s]update embedding:  28%|██▊       | 33/118 [00:28<01:13,  1.15it/s]update embedding:  29%|██▉       | 34/118 [00:29<01:12,  1.15it/s]update embedding:  30%|██▉       | 35/118 [00:30<01:11,  1.16it/s]update embedding:  31%|███       | 36/118 [00:31<01:10,  1.16it/s]update embedding:  31%|███▏      | 37/118 [00:32<01:10,  1.16it/s]update embedding:  32%|███▏      | 38/118 [00:33<01:09,  1.15it/s]update embedding:  33%|███▎      | 39/118 [00:33<01:08,  1.15it/s]update embedding:  34%|███▍      | 40/118 [00:34<01:07,  1.16it/s]update embedding:  35%|███▍      | 41/118 [00:35<01:07,  1.15it/s]update embedding:  36%|███▌      | 42/118 [00:36<01:05,  1.15it/s]update embedding:  36%|███▋      | 43/118 [00:37<01:05,  1.15it/s]update embedding:  37%|███▋      | 44/118 [00:38<01:03,  1.16it/s]update embedding:  38%|███▊      | 45/118 [00:39<01:03,  1.16it/s]update embedding:  39%|███▉      | 46/118 [00:39<01:02,  1.16it/s]update embedding:  40%|███▉      | 47/118 [00:40<01:01,  1.16it/s]update embedding:  41%|████      | 48/118 [00:41<01:00,  1.16it/s]update embedding:  42%|████▏     | 49/118 [00:42<00:59,  1.16it/s]update embedding:  42%|████▏     | 50/118 [00:43<00:58,  1.16it/s]update embedding:  43%|████▎     | 51/118 [00:44<00:57,  1.16it/s]update embedding:  44%|████▍     | 52/118 [00:45<00:56,  1.16it/s]update embedding:  45%|████▍     | 53/118 [00:46<00:56,  1.15it/s]update embedding:  46%|████▌     | 54/118 [00:46<00:55,  1.15it/s]update embedding:  47%|████▋     | 55/118 [00:47<00:54,  1.15it/s]update embedding:  47%|████▋     | 56/118 [00:48<00:54,  1.14it/s]update embedding:  48%|████▊     | 57/118 [00:49<00:53,  1.15it/s]update embedding:  49%|████▉     | 58/118 [00:50<00:52,  1.15it/s]update embedding:  50%|█████     | 59/118 [00:51<00:51,  1.15it/s]update embedding:  51%|█████     | 60/118 [00:52<00:50,  1.15it/s]update embedding:  52%|█████▏    | 61/118 [00:52<00:49,  1.15it/s]update embedding:  53%|█████▎    | 62/118 [00:53<00:48,  1.15it/s]update embedding:  53%|█████▎    | 63/118 [00:54<00:47,  1.16it/s]update embedding:  54%|█████▍    | 64/118 [00:55<00:46,  1.15it/s]update embedding:  55%|█████▌    | 65/118 [00:56<00:45,  1.16it/s]update embedding:  56%|█████▌    | 66/118 [00:57<00:44,  1.16it/s]update embedding:  57%|█████▋    | 67/118 [00:58<00:44,  1.16it/s]update embedding:  58%|█████▊    | 68/118 [00:58<00:43,  1.16it/s]update embedding:  58%|█████▊    | 69/118 [00:59<00:42,  1.16it/s]update embedding:  59%|█████▉    | 70/118 [01:00<00:41,  1.15it/s]update embedding:  60%|██████    | 71/118 [01:01<00:40,  1.15it/s]update embedding:  61%|██████    | 72/118 [01:02<00:39,  1.16it/s]update embedding:  62%|██████▏   | 73/118 [01:03<00:38,  1.15it/s]update embedding:  63%|██████▎   | 74/118 [01:04<00:37,  1.16it/s]update embedding:  64%|██████▎   | 75/118 [01:05<00:36,  1.16it/s]update embedding:  64%|██████▍   | 76/118 [01:05<00:36,  1.15it/s]update embedding:  65%|██████▌   | 77/118 [01:06<00:35,  1.15it/s]update embedding:  66%|██████▌   | 78/118 [01:07<00:34,  1.16it/s]update embedding:  67%|██████▋   | 79/118 [01:08<00:33,  1.16it/s]update embedding:  68%|██████▊   | 80/118 [01:09<00:32,  1.16it/s]update embedding:  69%|██████▊   | 81/118 [01:10<00:31,  1.17it/s]update embedding:  69%|██████▉   | 82/118 [01:11<00:30,  1.17it/s]update embedding:  70%|███████   | 83/118 [01:11<00:29,  1.17it/s]update embedding:  71%|███████   | 84/118 [01:12<00:29,  1.17it/s]update embedding:  72%|███████▏  | 85/118 [01:13<00:28,  1.16it/s]update embedding:  73%|███████▎  | 86/118 [01:14<00:27,  1.17it/s]update embedding:  74%|███████▎  | 87/118 [01:15<00:26,  1.16it/s]update embedding:  75%|███████▍  | 88/118 [01:16<00:25,  1.16it/s]update embedding:  75%|███████▌  | 89/118 [01:17<00:25,  1.16it/s]update embedding:  76%|███████▋  | 90/118 [01:17<00:24,  1.16it/s]update embedding:  77%|███████▋  | 91/118 [01:18<00:23,  1.16it/s]update embedding:  78%|███████▊  | 92/118 [01:19<00:22,  1.16it/s]update embedding:  79%|███████▉  | 93/118 [01:20<00:21,  1.16it/s]update embedding:  80%|███████▉  | 94/118 [01:21<00:20,  1.17it/s]update embedding:  81%|████████  | 95/118 [01:22<00:19,  1.16it/s]update embedding:  81%|████████▏ | 96/118 [01:23<00:19,  1.15it/s]update embedding:  82%|████████▏ | 97/118 [01:23<00:18,  1.16it/s]update embedding:  83%|████████▎ | 98/118 [01:24<00:17,  1.17it/s]update embedding:  84%|████████▍ | 99/118 [01:25<00:16,  1.16it/s]update embedding:  85%|████████▍ | 100/118 [01:26<00:15,  1.16it/s]update embedding:  86%|████████▌ | 101/118 [01:27<00:14,  1.16it/s]update embedding:  86%|████████▋ | 102/118 [01:28<00:13,  1.16it/s]update embedding:  87%|████████▋ | 103/118 [01:29<00:12,  1.16it/s]update embedding:  88%|████████▊ | 104/118 [01:30<00:12,  1.16it/s]update embedding:  89%|████████▉ | 105/118 [01:30<00:11,  1.16it/s]update embedding:  90%|████████▉ | 106/118 [01:31<00:10,  1.16it/s]update embedding:  91%|█████████ | 107/118 [01:32<00:09,  1.16it/s]update embedding:  92%|█████████▏| 108/118 [01:33<00:08,  1.16it/s]update embedding:  92%|█████████▏| 109/118 [01:34<00:07,  1.16it/s]update embedding:  93%|█████████▎| 110/118 [01:35<00:06,  1.15it/s]update embedding:  94%|█████████▍| 111/118 [01:36<00:06,  1.15it/s]update embedding:  95%|█████████▍| 112/118 [01:36<00:05,  1.15it/s]update embedding:  96%|█████████▌| 113/118 [01:37<00:04,  1.15it/s]update embedding:  97%|█████████▋| 114/118 [01:38<00:03,  1.16it/s]update embedding:  97%|█████████▋| 115/118 [01:39<00:02,  1.15it/s]update embedding:  98%|█████████▊| 116/118 [01:40<00:01,  1.15it/s]update embedding:  99%|█████████▉| 117/118 [01:41<00:00,  1.15it/s]update embedding: 100%|██████████| 118/118 [01:42<00:00,  1.15it/s]update embedding: 100%|██████████| 118/118 [01:42<00:00,  1.15it/s]
retrival evaluation:   0%|          | 0/3481 [00:00<?, ?it/s]retrival evaluation:   0%|          | 5/3481 [00:00<01:13, 47.29it/s]retrival evaluation:   0%|          | 12/3481 [00:00<01:06, 52.28it/s]retrival evaluation:   1%|          | 19/3481 [00:00<01:02, 55.81it/s]retrival evaluation:   1%|          | 27/3481 [00:00<00:56, 60.63it/s]retrival evaluation:   1%|          | 35/3481 [00:00<00:53, 64.31it/s]retrival evaluation:   1%|          | 43/3481 [00:00<00:50, 67.78it/s]retrival evaluation:   1%|▏         | 51/3481 [00:00<00:48, 70.93it/s]retrival evaluation:   2%|▏         | 59/3481 [00:00<00:46, 73.11it/s]retrival evaluation:   2%|▏         | 67/3481 [00:00<00:45, 74.35it/s]retrival evaluation:   2%|▏         | 75/3481 [00:01<00:45, 75.20it/s]retrival evaluation:   2%|▏         | 83/3481 [00:01<00:44, 75.72it/s]retrival evaluation:   3%|▎         | 91/3481 [00:01<00:44, 76.46it/s]retrival evaluation:   3%|▎         | 99/3481 [00:01<00:43, 77.19it/s]retrival evaluation:   3%|▎         | 107/3481 [00:01<00:43, 77.45it/s]retrival evaluation:   3%|▎         | 115/3481 [00:01<00:43, 77.91it/s]retrival evaluation:   4%|▎         | 123/3481 [00:01<00:43, 77.38it/s]retrival evaluation:   4%|▍         | 131/3481 [00:01<00:43, 77.79it/s]retrival evaluation:   4%|▍         | 139/3481 [00:01<00:42, 78.25it/s]retrival evaluation:   4%|▍         | 147/3481 [00:01<00:42, 78.24it/s]retrival evaluation:   4%|▍         | 155/3481 [00:02<00:42, 78.27it/s]retrival evaluation:   5%|▍         | 163/3481 [00:02<00:42, 78.24it/s]retrival evaluation:   5%|▍         | 171/3481 [00:02<00:42, 78.37it/s]retrival evaluation:   5%|▌         | 179/3481 [00:02<00:42, 78.54it/s]retrival evaluation:   5%|▌         | 187/3481 [00:02<00:41, 78.51it/s]retrival evaluation:   6%|▌         | 195/3481 [00:02<00:41, 78.95it/s]retrival evaluation:   6%|▌         | 203/3481 [00:02<00:41, 79.12it/s]retrival evaluation:   6%|▌         | 211/3481 [00:02<00:41, 78.77it/s]retrival evaluation:   6%|▋         | 219/3481 [00:02<00:41, 78.94it/s]retrival evaluation:   7%|▋         | 227/3481 [00:02<00:41, 78.99it/s]retrival evaluation:   7%|▋         | 235/3481 [00:03<00:41, 78.88it/s]retrival evaluation:   7%|▋         | 243/3481 [00:03<00:40, 79.12it/s]retrival evaluation:   7%|▋         | 251/3481 [00:03<00:41, 77.86it/s]retrival evaluation:   7%|▋         | 259/3481 [00:03<00:41, 78.24it/s]retrival evaluation:   8%|▊         | 267/3481 [00:03<00:41, 78.10it/s]retrival evaluation:   8%|▊         | 275/3481 [00:03<00:41, 77.59it/s]retrival evaluation:   8%|▊         | 283/3481 [00:03<00:41, 76.96it/s]retrival evaluation:   8%|▊         | 291/3481 [00:03<00:41, 76.75it/s]retrival evaluation:   9%|▊         | 299/3481 [00:03<00:41, 77.57it/s]retrival evaluation:   9%|▉         | 307/3481 [00:04<00:40, 78.15it/s]retrival evaluation:   9%|▉         | 315/3481 [00:04<00:40, 78.31it/s]retrival evaluation:   9%|▉         | 323/3481 [00:04<00:40, 78.07it/s]retrival evaluation:  10%|▉         | 331/3481 [00:04<00:40, 77.85it/s]retrival evaluation:  10%|▉         | 339/3481 [00:04<00:40, 78.34it/s]retrival evaluation:  10%|▉         | 347/3481 [00:04<00:39, 78.44it/s]retrival evaluation:  10%|█         | 355/3481 [00:04<00:39, 78.23it/s]retrival evaluation:  10%|█         | 363/3481 [00:04<00:40, 77.90it/s]retrival evaluation:  11%|█         | 371/3481 [00:04<00:40, 77.48it/s]retrival evaluation:  11%|█         | 379/3481 [00:04<00:39, 77.93it/s]retrival evaluation:  11%|█         | 387/3481 [00:05<00:39, 78.07it/s]retrival evaluation:  11%|█▏        | 395/3481 [00:05<00:39, 78.02it/s]retrival evaluation:  12%|█▏        | 403/3481 [00:05<00:39, 78.23it/s]retrival evaluation:  12%|█▏        | 411/3481 [00:05<00:39, 77.99it/s]retrival evaluation:  12%|█▏        | 419/3481 [00:05<00:39, 77.84it/s]retrival evaluation:  12%|█▏        | 427/3481 [00:05<00:39, 78.03it/s]retrival evaluation:  12%|█▏        | 435/3481 [00:05<00:39, 78.03it/s]retrival evaluation:  13%|█▎        | 443/3481 [00:05<00:38, 78.09it/s]retrival evaluation:  13%|█▎        | 451/3481 [00:05<00:39, 76.34it/s]retrival evaluation:  13%|█▎        | 459/3481 [00:05<00:39, 76.93it/s]retrival evaluation:  13%|█▎        | 467/3481 [00:06<00:39, 77.23it/s]retrival evaluation:  14%|█▎        | 475/3481 [00:06<00:38, 77.64it/s]retrival evaluation:  14%|█▍        | 483/3481 [00:06<00:38, 77.74it/s]retrival evaluation:  14%|█▍        | 491/3481 [00:06<00:38, 78.03it/s]retrival evaluation:  14%|█▍        | 499/3481 [00:06<00:38, 78.22it/s]retrival evaluation:  15%|█▍        | 507/3481 [00:06<00:38, 77.78it/s]retrival evaluation:  15%|█▍        | 515/3481 [00:06<00:38, 78.02it/s]retrival evaluation:  15%|█▌        | 523/3481 [00:06<00:37, 78.01it/s]retrival evaluation:  15%|█▌        | 531/3481 [00:06<00:37, 77.96it/s]retrival evaluation:  15%|█▌        | 539/3481 [00:06<00:37, 78.38it/s]retrival evaluation:  16%|█▌        | 547/3481 [00:07<00:37, 78.00it/s]retrival evaluation:  16%|█▌        | 555/3481 [00:07<00:37, 77.87it/s]retrival evaluation:  16%|█▌        | 563/3481 [00:07<00:37, 77.88it/s]retrival evaluation:  16%|█▋        | 571/3481 [00:07<00:37, 77.90it/s]retrival evaluation:  17%|█▋        | 580/3481 [00:07<00:36, 78.51it/s]retrival evaluation:  17%|█▋        | 588/3481 [00:07<00:36, 78.42it/s]retrival evaluation:  17%|█▋        | 596/3481 [00:07<00:37, 77.68it/s]retrival evaluation:  17%|█▋        | 604/3481 [00:07<00:36, 77.81it/s]retrival evaluation:  18%|█▊        | 612/3481 [00:07<00:36, 78.14it/s]retrival evaluation:  18%|█▊        | 620/3481 [00:08<00:36, 78.09it/s]retrival evaluation:  18%|█▊        | 628/3481 [00:08<00:36, 78.40it/s]retrival evaluation:  18%|█▊        | 636/3481 [00:08<00:36, 77.95it/s]retrival evaluation:  19%|█▊        | 644/3481 [00:08<00:36, 77.92it/s]retrival evaluation:  19%|█▊        | 652/3481 [00:08<00:36, 78.34it/s]retrival evaluation:  19%|█▉        | 660/3481 [00:08<00:35, 78.42it/s]retrival evaluation:  19%|█▉        | 668/3481 [00:08<00:35, 78.45it/s]retrival evaluation:  19%|█▉        | 676/3481 [00:08<00:35, 77.98it/s]retrival evaluation:  20%|█▉        | 684/3481 [00:08<00:36, 77.69it/s]retrival evaluation:  20%|█▉        | 692/3481 [00:08<00:35, 78.14it/s]retrival evaluation:  20%|██        | 700/3481 [00:09<00:35, 78.32it/s]retrival evaluation:  20%|██        | 708/3481 [00:09<00:35, 78.30it/s]retrival evaluation:  21%|██        | 716/3481 [00:09<00:35, 78.24it/s]retrival evaluation:  21%|██        | 724/3481 [00:09<00:35, 77.65it/s]retrival evaluation:  21%|██        | 732/3481 [00:09<00:35, 77.98it/s]retrival evaluation:  21%|██▏       | 740/3481 [00:09<00:35, 78.04it/s]retrival evaluation:  21%|██▏       | 748/3481 [00:09<00:34, 78.10it/s]retrival evaluation:  22%|██▏       | 756/3481 [00:09<00:34, 78.25it/s]retrival evaluation:  22%|██▏       | 764/3481 [00:09<00:34, 77.89it/s]retrival evaluation:  22%|██▏       | 772/3481 [00:09<00:34, 77.92it/s]retrival evaluation:  22%|██▏       | 780/3481 [00:10<00:34, 78.10it/s]retrival evaluation:  23%|██▎       | 788/3481 [00:10<00:34, 77.97it/s]retrival evaluation:  23%|██▎       | 796/3481 [00:10<00:34, 78.11it/s]retrival evaluation:  23%|██▎       | 804/3481 [00:10<00:34, 77.95it/s]retrival evaluation:  23%|██▎       | 812/3481 [00:10<00:34, 78.10it/s]retrival evaluation:  24%|██▎       | 820/3481 [00:10<00:34, 78.12it/s]retrival evaluation:  24%|██▍       | 828/3481 [00:10<00:33, 78.22it/s]retrival evaluation:  24%|██▍       | 836/3481 [00:10<00:33, 77.94it/s]retrival evaluation:  24%|██▍       | 844/3481 [00:10<00:33, 78.17it/s]retrival evaluation:  24%|██▍       | 852/3481 [00:10<00:33, 78.21it/s]retrival evaluation:  25%|██▍       | 860/3481 [00:11<00:33, 77.80it/s]retrival evaluation:  25%|██▍       | 868/3481 [00:11<00:33, 78.11it/s]retrival evaluation:  25%|██▌       | 876/3481 [00:11<00:33, 77.85it/s]retrival evaluation:  25%|██▌       | 884/3481 [00:11<00:33, 77.98it/s]retrival evaluation:  26%|██▌       | 892/3481 [00:11<00:33, 78.08it/s]retrival evaluation:  26%|██▌       | 900/3481 [00:11<00:33, 77.81it/s]retrival evaluation:  26%|██▌       | 908/3481 [00:11<00:33, 77.96it/s]retrival evaluation:  26%|██▋       | 916/3481 [00:11<00:32, 77.88it/s]retrival evaluation:  27%|██▋       | 924/3481 [00:11<00:32, 77.78it/s]retrival evaluation:  27%|██▋       | 932/3481 [00:12<00:32, 78.40it/s]retrival evaluation:  27%|██▋       | 940/3481 [00:12<00:32, 77.94it/s]retrival evaluation:  27%|██▋       | 948/3481 [00:12<00:32, 77.84it/s]retrival evaluation:  27%|██▋       | 956/3481 [00:12<00:32, 78.12it/s]retrival evaluation:  28%|██▊       | 964/3481 [00:12<00:32, 78.35it/s]retrival evaluation:  28%|██▊       | 973/3481 [00:12<00:31, 78.68it/s]retrival evaluation:  28%|██▊       | 981/3481 [00:12<00:31, 78.98it/s]retrival evaluation:  28%|██▊       | 989/3481 [00:12<00:31, 78.77it/s]retrival evaluation:  29%|██▊       | 997/3481 [00:12<00:31, 78.92it/s]retrival evaluation:  29%|██▉       | 1005/3481 [00:12<00:31, 78.96it/s]retrival evaluation:  29%|██▉       | 1013/3481 [00:13<00:31, 78.90it/s]retrival evaluation:  29%|██▉       | 1022/3481 [00:13<00:31, 79.15it/s]retrival evaluation:  30%|██▉       | 1030/3481 [00:13<00:30, 79.07it/s]retrival evaluation:  30%|██▉       | 1038/3481 [00:13<00:31, 78.75it/s]retrival evaluation:  30%|███       | 1046/3481 [00:13<00:31, 78.12it/s]retrival evaluation:  30%|███       | 1054/3481 [00:13<00:31, 77.51it/s]retrival evaluation:  31%|███       | 1062/3481 [00:13<00:31, 77.42it/s]retrival evaluation:  31%|███       | 1070/3481 [00:13<00:31, 76.84it/s]retrival evaluation:  31%|███       | 1078/3481 [00:13<00:31, 77.11it/s]retrival evaluation:  31%|███       | 1086/3481 [00:13<00:30, 77.52it/s]retrival evaluation:  31%|███▏      | 1094/3481 [00:14<00:30, 77.47it/s]retrival evaluation:  32%|███▏      | 1102/3481 [00:14<00:30, 77.99it/s]retrival evaluation:  32%|███▏      | 1110/3481 [00:14<00:30, 78.00it/s]retrival evaluation:  32%|███▏      | 1118/3481 [00:14<00:30, 77.70it/s]retrival evaluation:  32%|███▏      | 1126/3481 [00:14<00:31, 74.47it/s]retrival evaluation:  33%|███▎      | 1134/3481 [00:14<00:32, 72.91it/s]retrival evaluation:  33%|███▎      | 1142/3481 [00:14<00:32, 71.81it/s]retrival evaluation:  33%|███▎      | 1150/3481 [00:14<00:32, 71.44it/s]retrival evaluation:  33%|███▎      | 1158/3481 [00:14<00:31, 73.35it/s]retrival evaluation:  33%|███▎      | 1166/3481 [00:15<00:30, 74.75it/s]retrival evaluation:  34%|███▎      | 1174/3481 [00:15<00:30, 75.43it/s]retrival evaluation:  34%|███▍      | 1182/3481 [00:15<00:30, 75.73it/s]retrival evaluation:  34%|███▍      | 1190/3481 [00:15<00:29, 76.81it/s]retrival evaluation:  34%|███▍      | 1198/3481 [00:15<00:29, 77.39it/s]retrival evaluation:  35%|███▍      | 1206/3481 [00:15<00:29, 77.65it/s]retrival evaluation:  35%|███▍      | 1214/3481 [00:15<00:29, 77.62it/s]retrival evaluation:  35%|███▌      | 1222/3481 [00:15<00:29, 77.46it/s]retrival evaluation:  35%|███▌      | 1230/3481 [00:15<00:28, 77.79it/s]retrival evaluation:  36%|███▌      | 1238/3481 [00:15<00:28, 78.03it/s]retrival evaluation:  36%|███▌      | 1246/3481 [00:16<00:28, 77.89it/s]retrival evaluation:  36%|███▌      | 1254/3481 [00:16<00:28, 78.26it/s]retrival evaluation:  36%|███▋      | 1262/3481 [00:16<00:28, 77.88it/s]retrival evaluation:  36%|███▋      | 1270/3481 [00:16<00:28, 78.03it/s]retrival evaluation:  37%|███▋      | 1278/3481 [00:16<00:28, 78.18it/s]retrival evaluation:  37%|███▋      | 1286/3481 [00:16<00:28, 77.94it/s]retrival evaluation:  37%|███▋      | 1294/3481 [00:16<00:27, 78.16it/s]retrival evaluation:  37%|███▋      | 1302/3481 [00:16<00:27, 77.98it/s]retrival evaluation:  38%|███▊      | 1310/3481 [00:16<00:27, 78.08it/s]retrival evaluation:  38%|███▊      | 1318/3481 [00:17<00:27, 78.09it/s]retrival evaluation:  38%|███▊      | 1326/3481 [00:17<00:27, 78.14it/s]retrival evaluation:  38%|███▊      | 1334/3481 [00:17<00:27, 77.79it/s]retrival evaluation:  39%|███▊      | 1342/3481 [00:17<00:27, 78.07it/s]retrival evaluation:  39%|███▉      | 1350/3481 [00:17<00:27, 78.11it/s]retrival evaluation:  39%|███▉      | 1358/3481 [00:17<00:27, 77.78it/s]retrival evaluation:  39%|███▉      | 1366/3481 [00:17<00:27, 77.99it/s]retrival evaluation:  39%|███▉      | 1374/3481 [00:17<00:27, 77.95it/s]retrival evaluation:  40%|███▉      | 1382/3481 [00:17<00:26, 78.07it/s]retrival evaluation:  40%|███▉      | 1390/3481 [00:17<00:26, 77.95it/s]retrival evaluation:  40%|████      | 1398/3481 [00:18<00:26, 77.67it/s]retrival evaluation:  40%|████      | 1406/3481 [00:18<00:26, 77.88it/s]retrival evaluation:  41%|████      | 1414/3481 [00:18<00:26, 78.07it/s]retrival evaluation:  41%|████      | 1422/3481 [00:18<00:26, 77.94it/s]retrival evaluation:  41%|████      | 1430/3481 [00:18<00:26, 78.54it/s]retrival evaluation:  41%|████▏     | 1438/3481 [00:18<00:26, 77.96it/s]retrival evaluation:  42%|████▏     | 1446/3481 [00:18<00:26, 77.84it/s]retrival evaluation:  42%|████▏     | 1454/3481 [00:18<00:25, 78.04it/s]retrival evaluation:  42%|████▏     | 1462/3481 [00:18<00:25, 77.99it/s]retrival evaluation:  42%|████▏     | 1470/3481 [00:18<00:25, 78.57it/s]retrival evaluation:  42%|████▏     | 1478/3481 [00:19<00:25, 77.96it/s]retrival evaluation:  43%|████▎     | 1486/3481 [00:19<00:25, 77.59it/s]retrival evaluation:  43%|████▎     | 1494/3481 [00:19<00:25, 77.85it/s]retrival evaluation:  43%|████▎     | 1502/3481 [00:19<00:25, 77.83it/s]retrival evaluation:  43%|████▎     | 1510/3481 [00:19<00:25, 78.22it/s]retrival evaluation:  44%|████▎     | 1518/3481 [00:19<00:25, 78.11it/s]retrival evaluation:  44%|████▍     | 1526/3481 [00:19<00:25, 77.65it/s]retrival evaluation:  44%|████▍     | 1534/3481 [00:19<00:25, 77.58it/s]retrival evaluation:  44%|████▍     | 1542/3481 [00:19<00:24, 77.99it/s]retrival evaluation:  45%|████▍     | 1550/3481 [00:19<00:24, 78.22it/s]retrival evaluation:  45%|████▍     | 1558/3481 [00:20<00:24, 78.37it/s]retrival evaluation:  45%|████▍     | 1566/3481 [00:20<00:24, 77.88it/s]retrival evaluation:  45%|████▌     | 1574/3481 [00:20<00:24, 77.55it/s]retrival evaluation:  45%|████▌     | 1582/3481 [00:20<00:24, 78.17it/s]retrival evaluation:  46%|████▌     | 1590/3481 [00:20<00:24, 78.20it/s]retrival evaluation:  46%|████▌     | 1598/3481 [00:20<00:24, 78.13it/s]retrival evaluation:  46%|████▌     | 1606/3481 [00:20<00:24, 78.11it/s]retrival evaluation:  46%|████▋     | 1614/3481 [00:20<00:24, 77.73it/s]retrival evaluation:  47%|████▋     | 1622/3481 [00:20<00:23, 77.98it/s]retrival evaluation:  47%|████▋     | 1630/3481 [00:21<00:23, 78.17it/s]retrival evaluation:  47%|████▋     | 1638/3481 [00:21<00:23, 77.91it/s]retrival evaluation:  47%|████▋     | 1646/3481 [00:21<00:23, 78.06it/s]retrival evaluation:  48%|████▊     | 1654/3481 [00:21<00:23, 77.67it/s]retrival evaluation:  48%|████▊     | 1662/3481 [00:21<00:23, 78.08it/s]retrival evaluation:  48%|████▊     | 1670/3481 [00:21<00:23, 78.23it/s]retrival evaluation:  48%|████▊     | 1678/3481 [00:21<00:23, 78.10it/s]retrival evaluation:  48%|████▊     | 1686/3481 [00:21<00:22, 78.16it/s]retrival evaluation:  49%|████▊     | 1694/3481 [00:21<00:22, 77.87it/s]retrival evaluation:  49%|████▉     | 1702/3481 [00:21<00:22, 78.03it/s]retrival evaluation:  49%|████▉     | 1710/3481 [00:22<00:22, 78.18it/s]retrival evaluation:  49%|████▉     | 1718/3481 [00:22<00:22, 78.04it/s]retrival evaluation:  50%|████▉     | 1726/3481 [00:22<00:22, 78.07it/s]retrival evaluation:  50%|████▉     | 1734/3481 [00:22<00:22, 78.30it/s]retrival evaluation:  50%|█████     | 1742/3481 [00:22<00:22, 77.97it/s]retrival evaluation:  50%|█████     | 1750/3481 [00:22<00:22, 78.09it/s]retrival evaluation:  51%|█████     | 1758/3481 [00:22<00:21, 78.49it/s]retrival evaluation:  51%|█████     | 1766/3481 [00:22<00:21, 78.57it/s]retrival evaluation:  51%|█████     | 1775/3481 [00:22<00:21, 78.70it/s]retrival evaluation:  51%|█████     | 1783/3481 [00:22<00:21, 79.07it/s]retrival evaluation:  51%|█████▏    | 1791/3481 [00:23<00:21, 78.78it/s]retrival evaluation:  52%|█████▏    | 1799/3481 [00:23<00:21, 78.73it/s]retrival evaluation:  52%|█████▏    | 1807/3481 [00:23<00:21, 78.91it/s]retrival evaluation:  52%|█████▏    | 1815/3481 [00:23<00:21, 78.79it/s]retrival evaluation:  52%|█████▏    | 1824/3481 [00:23<00:20, 79.13it/s]retrival evaluation:  53%|█████▎    | 1832/3481 [00:23<00:20, 79.07it/s]retrival evaluation:  53%|█████▎    | 1840/3481 [00:23<00:21, 77.88it/s]retrival evaluation:  53%|█████▎    | 1848/3481 [00:23<00:20, 78.21it/s]retrival evaluation:  53%|█████▎    | 1856/3481 [00:23<00:20, 77.91it/s]retrival evaluation:  54%|█████▎    | 1864/3481 [00:24<00:20, 77.14it/s]retrival evaluation:  54%|█████▍    | 1872/3481 [00:24<00:20, 76.64it/s]retrival evaluation:  54%|█████▍    | 1880/3481 [00:24<00:20, 77.17it/s]retrival evaluation:  54%|█████▍    | 1888/3481 [00:24<00:20, 77.42it/s]retrival evaluation:  54%|█████▍    | 1896/3481 [00:24<00:20, 77.84it/s]retrival evaluation:  55%|█████▍    | 1904/3481 [00:24<00:20, 76.96it/s]retrival evaluation:  55%|█████▍    | 1912/3481 [00:24<00:20, 76.82it/s]retrival evaluation:  55%|█████▌    | 1920/3481 [00:24<00:20, 77.06it/s]retrival evaluation:  55%|█████▌    | 1928/3481 [00:24<00:19, 77.68it/s]retrival evaluation:  56%|█████▌    | 1936/3481 [00:24<00:19, 77.79it/s]retrival evaluation:  56%|█████▌    | 1944/3481 [00:25<00:19, 78.13it/s]retrival evaluation:  56%|█████▌    | 1952/3481 [00:25<00:19, 77.71it/s]retrival evaluation:  56%|█████▋    | 1960/3481 [00:25<00:19, 77.57it/s]retrival evaluation:  57%|█████▋    | 1968/3481 [00:25<00:19, 78.15it/s]retrival evaluation:  57%|█████▋    | 1976/3481 [00:25<00:19, 78.29it/s]retrival evaluation:  57%|█████▋    | 1984/3481 [00:25<00:19, 78.06it/s]retrival evaluation:  57%|█████▋    | 1992/3481 [00:25<00:19, 78.18it/s]retrival evaluation:  57%|█████▋    | 2000/3481 [00:25<00:19, 77.65it/s]retrival evaluation:  58%|█████▊    | 2008/3481 [00:25<00:18, 77.53it/s]retrival evaluation:  58%|█████▊    | 2016/3481 [00:25<00:18, 77.77it/s]retrival evaluation:  58%|█████▊    | 2024/3481 [00:26<00:18, 77.80it/s]retrival evaluation:  58%|█████▊    | 2032/3481 [00:26<00:18, 78.00it/s]retrival evaluation:  59%|█████▊    | 2040/3481 [00:26<00:18, 77.30it/s]retrival evaluation:  59%|█████▉    | 2048/3481 [00:26<00:18, 77.12it/s]retrival evaluation:  59%|█████▉    | 2056/3481 [00:26<00:18, 77.44it/s]retrival evaluation:  59%|█████▉    | 2064/3481 [00:26<00:18, 77.79it/s]retrival evaluation:  60%|█████▉    | 2072/3481 [00:26<00:18, 77.30it/s]retrival evaluation:  60%|█████▉    | 2080/3481 [00:26<00:18, 77.66it/s]retrival evaluation:  60%|█████▉    | 2088/3481 [00:26<00:18, 77.38it/s]retrival evaluation:  60%|██████    | 2096/3481 [00:26<00:18, 76.94it/s]retrival evaluation:  60%|██████    | 2104/3481 [00:27<00:17, 77.44it/s]retrival evaluation:  61%|██████    | 2112/3481 [00:27<00:17, 77.59it/s]retrival evaluation:  61%|██████    | 2120/3481 [00:27<00:17, 77.84it/s]retrival evaluation:  61%|██████    | 2128/3481 [00:27<00:17, 77.12it/s]retrival evaluation:  61%|██████▏   | 2136/3481 [00:27<00:17, 77.00it/s]retrival evaluation:  62%|██████▏   | 2144/3481 [00:27<00:17, 77.36it/s]retrival evaluation:  62%|██████▏   | 2152/3481 [00:27<00:17, 77.44it/s]retrival evaluation:  62%|██████▏   | 2160/3481 [00:27<00:17, 77.09it/s]retrival evaluation:  62%|██████▏   | 2168/3481 [00:27<00:16, 77.40it/s]retrival evaluation:  63%|██████▎   | 2176/3481 [00:28<00:16, 76.99it/s]retrival evaluation:  63%|██████▎   | 2184/3481 [00:28<00:16, 76.99it/s]retrival evaluation:  63%|██████▎   | 2192/3481 [00:28<00:16, 77.37it/s]retrival evaluation:  63%|██████▎   | 2200/3481 [00:28<00:16, 77.61it/s]retrival evaluation:  63%|██████▎   | 2208/3481 [00:28<00:16, 78.06it/s]retrival evaluation:  64%|██████▎   | 2216/3481 [00:28<00:16, 77.38it/s]retrival evaluation:  64%|██████▍   | 2224/3481 [00:28<00:16, 77.24it/s]retrival evaluation:  64%|██████▍   | 2232/3481 [00:28<00:16, 77.67it/s]retrival evaluation:  64%|██████▍   | 2240/3481 [00:28<00:15, 77.80it/s]retrival evaluation:  65%|██████▍   | 2248/3481 [00:28<00:15, 77.45it/s]retrival evaluation:  65%|██████▍   | 2256/3481 [00:29<00:15, 77.88it/s]retrival evaluation:  65%|██████▌   | 2264/3481 [00:29<00:15, 77.49it/s]retrival evaluation:  65%|██████▌   | 2272/3481 [00:29<00:15, 77.17it/s]retrival evaluation:  65%|██████▌   | 2280/3481 [00:29<00:15, 77.68it/s]retrival evaluation:  66%|██████▌   | 2288/3481 [00:29<00:15, 77.76it/s]retrival evaluation:  66%|██████▌   | 2296/3481 [00:29<00:15, 78.17it/s]retrival evaluation:  66%|██████▌   | 2304/3481 [00:29<00:15, 77.51it/s]retrival evaluation:  66%|██████▋   | 2312/3481 [00:29<00:15, 77.18it/s]retrival evaluation:  67%|██████▋   | 2320/3481 [00:29<00:14, 77.65it/s]retrival evaluation:  67%|██████▋   | 2328/3481 [00:29<00:14, 77.82it/s]retrival evaluation:  67%|██████▋   | 2336/3481 [00:30<00:16, 70.93it/s]retrival evaluation:  67%|██████▋   | 2344/3481 [00:30<00:16, 69.06it/s]retrival evaluation:  68%|██████▊   | 2352/3481 [00:30<00:15, 71.39it/s]retrival evaluation:  68%|██████▊   | 2360/3481 [00:30<00:15, 73.66it/s]retrival evaluation:  68%|██████▊   | 2368/3481 [00:30<00:15, 74.02it/s]retrival evaluation:  68%|██████▊   | 2376/3481 [00:30<00:14, 74.62it/s]retrival evaluation:  68%|██████▊   | 2384/3481 [00:30<00:14, 75.49it/s]retrival evaluation:  69%|██████▊   | 2392/3481 [00:30<00:14, 76.17it/s]retrival evaluation:  69%|██████▉   | 2400/3481 [00:30<00:14, 76.68it/s]retrival evaluation:  69%|██████▉   | 2408/3481 [00:31<00:13, 77.08it/s]retrival evaluation:  69%|██████▉   | 2416/3481 [00:31<00:13, 76.98it/s]retrival evaluation:  70%|██████▉   | 2424/3481 [00:31<00:13, 76.72it/s]retrival evaluation:  70%|██████▉   | 2432/3481 [00:31<00:13, 77.17it/s]retrival evaluation:  70%|███████   | 2440/3481 [00:31<00:13, 77.43it/s]retrival evaluation:  70%|███████   | 2448/3481 [00:31<00:13, 77.60it/s]retrival evaluation:  71%|███████   | 2456/3481 [00:31<00:13, 77.34it/s]retrival evaluation:  71%|███████   | 2464/3481 [00:31<00:13, 77.07it/s]retrival evaluation:  71%|███████   | 2472/3481 [00:31<00:13, 77.49it/s]retrival evaluation:  71%|███████   | 2480/3481 [00:32<00:12, 77.64it/s]retrival evaluation:  71%|███████▏  | 2488/3481 [00:32<00:12, 77.47it/s]retrival evaluation:  72%|███████▏  | 2496/3481 [00:32<00:12, 77.72it/s]retrival evaluation:  72%|███████▏  | 2504/3481 [00:32<00:12, 77.37it/s]retrival evaluation:  72%|███████▏  | 2512/3481 [00:32<00:12, 77.49it/s]retrival evaluation:  72%|███████▏  | 2520/3481 [00:32<00:12, 77.69it/s]retrival evaluation:  73%|███████▎  | 2528/3481 [00:32<00:12, 77.50it/s]retrival evaluation:  73%|███████▎  | 2536/3481 [00:32<00:12, 77.65it/s]retrival evaluation:  73%|███████▎  | 2544/3481 [00:32<00:12, 77.77it/s]retrival evaluation:  73%|███████▎  | 2552/3481 [00:32<00:11, 77.64it/s]retrival evaluation:  74%|███████▎  | 2560/3481 [00:33<00:11, 77.98it/s]retrival evaluation:  74%|███████▍  | 2568/3481 [00:33<00:11, 78.12it/s]retrival evaluation:  74%|███████▍  | 2576/3481 [00:33<00:11, 78.04it/s]retrival evaluation:  74%|███████▍  | 2584/3481 [00:33<00:11, 78.56it/s]retrival evaluation:  74%|███████▍  | 2592/3481 [00:33<00:11, 78.37it/s]retrival evaluation:  75%|███████▍  | 2600/3481 [00:33<00:11, 78.08it/s]retrival evaluation:  75%|███████▍  | 2608/3481 [00:33<00:11, 78.29it/s]retrival evaluation:  75%|███████▌  | 2616/3481 [00:33<00:11, 78.16it/s]retrival evaluation:  75%|███████▌  | 2624/3481 [00:33<00:10, 77.96it/s]retrival evaluation:  76%|███████▌  | 2632/3481 [00:33<00:11, 76.92it/s]retrival evaluation:  76%|███████▌  | 2640/3481 [00:34<00:10, 76.55it/s]retrival evaluation:  76%|███████▌  | 2648/3481 [00:34<00:10, 76.05it/s]retrival evaluation:  76%|███████▋  | 2656/3481 [00:34<00:10, 75.48it/s]retrival evaluation:  77%|███████▋  | 2664/3481 [00:34<00:10, 75.26it/s]retrival evaluation:  77%|███████▋  | 2672/3481 [00:34<00:10, 74.53it/s]retrival evaluation:  77%|███████▋  | 2680/3481 [00:34<00:10, 74.93it/s]retrival evaluation:  77%|███████▋  | 2688/3481 [00:34<00:11, 70.80it/s]retrival evaluation:  77%|███████▋  | 2696/3481 [00:34<00:10, 72.90it/s]retrival evaluation:  78%|███████▊  | 2704/3481 [00:34<00:10, 73.55it/s]retrival evaluation:  78%|███████▊  | 2712/3481 [00:35<00:10, 75.17it/s]retrival evaluation:  78%|███████▊  | 2720/3481 [00:35<00:10, 75.38it/s]retrival evaluation:  78%|███████▊  | 2728/3481 [00:35<00:10, 73.73it/s]retrival evaluation:  79%|███████▊  | 2736/3481 [00:35<00:10, 72.41it/s]retrival evaluation:  79%|███████▉  | 2744/3481 [00:35<00:10, 69.44it/s]retrival evaluation:  79%|███████▉  | 2752/3481 [00:35<00:10, 70.52it/s]retrival evaluation:  79%|███████▉  | 2761/3481 [00:35<00:09, 73.08it/s]retrival evaluation:  80%|███████▉  | 2769/3481 [00:35<00:09, 74.87it/s]retrival evaluation:  80%|███████▉  | 2777/3481 [00:35<00:09, 74.29it/s]retrival evaluation:  80%|████████  | 2786/3481 [00:36<00:09, 76.08it/s]retrival evaluation:  80%|████████  | 2794/3481 [00:36<00:09, 76.00it/s]retrival evaluation:  80%|████████  | 2802/3481 [00:36<00:09, 74.45it/s]retrival evaluation:  81%|████████  | 2810/3481 [00:36<00:09, 73.22it/s]retrival evaluation:  81%|████████  | 2818/3481 [00:36<00:09, 72.40it/s]retrival evaluation:  81%|████████  | 2826/3481 [00:36<00:08, 72.82it/s]retrival evaluation:  81%|████████▏ | 2834/3481 [00:36<00:08, 74.23it/s]retrival evaluation:  82%|████████▏ | 2843/3481 [00:36<00:08, 75.75it/s]retrival evaluation:  82%|████████▏ | 2851/3481 [00:36<00:08, 74.35it/s]retrival evaluation:  82%|████████▏ | 2859/3481 [00:37<00:08, 75.58it/s]retrival evaluation:  82%|████████▏ | 2867/3481 [00:37<00:08, 76.60it/s]retrival evaluation:  83%|████████▎ | 2876/3481 [00:37<00:07, 77.56it/s]retrival evaluation:  83%|████████▎ | 2885/3481 [00:37<00:07, 78.41it/s]retrival evaluation:  83%|████████▎ | 2893/3481 [00:37<00:07, 76.90it/s]retrival evaluation:  83%|████████▎ | 2902/3481 [00:37<00:07, 77.70it/s]retrival evaluation:  84%|████████▎ | 2911/3481 [00:37<00:07, 78.42it/s]retrival evaluation:  84%|████████▍ | 2919/3481 [00:37<00:07, 78.52it/s]retrival evaluation:  84%|████████▍ | 2927/3481 [00:37<00:07, 75.14it/s]retrival evaluation:  84%|████████▍ | 2935/3481 [00:38<00:07, 73.58it/s]retrival evaluation:  85%|████████▍ | 2943/3481 [00:38<00:07, 72.75it/s]retrival evaluation:  85%|████████▍ | 2951/3481 [00:38<00:07, 72.86it/s]retrival evaluation:  85%|████████▌ | 2959/3481 [00:38<00:06, 74.75it/s]retrival evaluation:  85%|████████▌ | 2968/3481 [00:38<00:06, 76.12it/s]retrival evaluation:  85%|████████▌ | 2976/3481 [00:38<00:06, 77.22it/s]retrival evaluation:  86%|████████▌ | 2984/3481 [00:38<00:06, 77.23it/s]retrival evaluation:  86%|████████▌ | 2992/3481 [00:38<00:06, 77.87it/s]retrival evaluation:  86%|████████▌ | 3000/3481 [00:38<00:06, 76.73it/s]retrival evaluation:  86%|████████▋ | 3008/3481 [00:38<00:06, 76.51it/s]retrival evaluation:  87%|████████▋ | 3017/3481 [00:39<00:05, 77.37it/s]retrival evaluation:  87%|████████▋ | 3026/3481 [00:39<00:05, 78.39it/s]retrival evaluation:  87%|████████▋ | 3034/3481 [00:39<00:05, 78.55it/s]retrival evaluation:  87%|████████▋ | 3042/3481 [00:39<00:05, 78.54it/s]retrival evaluation:  88%|████████▊ | 3051/3481 [00:39<00:05, 79.03it/s]retrival evaluation:  88%|████████▊ | 3060/3481 [00:39<00:05, 78.54it/s]retrival evaluation:  88%|████████▊ | 3068/3481 [00:39<00:05, 78.11it/s]retrival evaluation:  88%|████████▊ | 3076/3481 [00:39<00:05, 78.58it/s]retrival evaluation:  89%|████████▊ | 3084/3481 [00:39<00:05, 78.58it/s]retrival evaluation:  89%|████████▉ | 3092/3481 [00:40<00:04, 78.48it/s]retrival evaluation:  89%|████████▉ | 3101/3481 [00:40<00:04, 78.83it/s]retrival evaluation:  89%|████████▉ | 3110/3481 [00:40<00:04, 79.24it/s]retrival evaluation:  90%|████████▉ | 3118/3481 [00:40<00:04, 76.33it/s]retrival evaluation:  90%|████████▉ | 3126/3481 [00:40<00:04, 74.53it/s]retrival evaluation:  90%|█████████ | 3134/3481 [00:40<00:04, 73.51it/s]retrival evaluation:  90%|█████████ | 3142/3481 [00:40<00:04, 72.92it/s]retrival evaluation:  90%|█████████ | 3150/3481 [00:40<00:04, 74.41it/s]retrival evaluation:  91%|█████████ | 3158/3481 [00:40<00:04, 75.43it/s]retrival evaluation:  91%|█████████ | 3167/3481 [00:41<00:04, 76.64it/s]retrival evaluation:  91%|█████████ | 3176/3481 [00:41<00:03, 77.76it/s]retrival evaluation:  91%|█████████▏| 3184/3481 [00:41<00:03, 78.32it/s]retrival evaluation:  92%|█████████▏| 3192/3481 [00:41<00:03, 78.44it/s]retrival evaluation:  92%|█████████▏| 3200/3481 [00:41<00:03, 78.60it/s]retrival evaluation:  92%|█████████▏| 3208/3481 [00:41<00:03, 78.61it/s]retrival evaluation:  92%|█████████▏| 3217/3481 [00:41<00:03, 78.90it/s]retrival evaluation:  93%|█████████▎| 3225/3481 [00:41<00:03, 79.20it/s]retrival evaluation:  93%|█████████▎| 3233/3481 [00:41<00:03, 79.20it/s]retrival evaluation:  93%|█████████▎| 3241/3481 [00:41<00:03, 77.25it/s]retrival evaluation:  93%|█████████▎| 3249/3481 [00:42<00:03, 77.24it/s]retrival evaluation:  94%|█████████▎| 3257/3481 [00:42<00:02, 77.84it/s]retrival evaluation:  94%|█████████▍| 3266/3481 [00:42<00:02, 78.49it/s]retrival evaluation:  94%|█████████▍| 3275/3481 [00:42<00:02, 78.90it/s]retrival evaluation:  94%|█████████▍| 3283/3481 [00:42<00:02, 78.93it/s]retrival evaluation:  95%|█████████▍| 3292/3481 [00:42<00:02, 79.10it/s]retrival evaluation:  95%|█████████▍| 3301/3481 [00:42<00:02, 79.60it/s]retrival evaluation:  95%|█████████▌| 3309/3481 [00:42<00:02, 79.22it/s]retrival evaluation:  95%|█████████▌| 3317/3481 [00:42<00:02, 79.24it/s]retrival evaluation:  96%|█████████▌| 3326/3481 [00:43<00:01, 79.66it/s]retrival evaluation:  96%|█████████▌| 3334/3481 [00:43<00:01, 78.33it/s]retrival evaluation:  96%|█████████▌| 3343/3481 [00:43<00:01, 78.96it/s]retrival evaluation:  96%|█████████▋| 3352/3481 [00:43<00:01, 79.39it/s]retrival evaluation:  97%|█████████▋| 3361/3481 [00:43<00:01, 79.97it/s]retrival evaluation:  97%|█████████▋| 3370/3481 [00:43<00:01, 80.11it/s]retrival evaluation:  97%|█████████▋| 3379/3481 [00:43<00:01, 80.19it/s]retrival evaluation:  97%|█████████▋| 3388/3481 [00:43<00:01, 80.28it/s]retrival evaluation:  98%|█████████▊| 3397/3481 [00:43<00:01, 80.36it/s]retrival evaluation:  98%|█████████▊| 3406/3481 [00:44<00:00, 80.54it/s]retrival evaluation:  98%|█████████▊| 3415/3481 [00:44<00:00, 77.98it/s]retrival evaluation:  98%|█████████▊| 3423/3481 [00:44<00:00, 75.48it/s]retrival evaluation:  99%|█████████▊| 3431/3481 [00:44<00:00, 73.76it/s]retrival evaluation:  99%|█████████▉| 3439/3481 [00:44<00:00, 71.66it/s]retrival evaluation:  99%|█████████▉| 3447/3481 [00:44<00:00, 71.94it/s]retrival evaluation:  99%|█████████▉| 3455/3481 [00:44<00:00, 73.51it/s]retrival evaluation: 100%|█████████▉| 3464/3481 [00:44<00:00, 75.64it/s]retrival evaluation: 100%|█████████▉| 3472/3481 [00:44<00:00, 76.89it/s]retrival evaluation: 100%|██████████| 3481/3481 [00:45<00:00, 77.76it/s]retrival evaluation: 100%|██████████| 3481/3481 [00:45<00:00, 77.27it/s]

pk3=0, pk2=0,pk1=0 best_f1 = 0.024, bets_f2=0.043, MAP=0.047, MRR=0, AP=0.009, exe_time=246.21895933151245

INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:__main__:model loaded
INFO:EMSE.BERTDataReader:Creating examples from dataset file at /afs/crc.nd.edu/user/j/jlin6/data/EMSE/Emmagee/test
update feature:   0%|          | 0/11 [00:00<?, ?it/s]update feature:  91%|█████████ | 10/11 [00:00<00:00, 90.03it/s]update feature: 100%|██████████| 11/11 [00:00<00:00, 95.63it/s]
update feature:   0%|          | 0/11 [00:00<?, ?it/s]update feature: 100%|██████████| 11/11 [00:00<00:00, 1481.66it/s]
update embedding:   0%|          | 0/11 [00:00<?, ?it/s]update embedding:   9%|▉         | 1/11 [00:00<00:07,  1.30it/s]update embedding:  18%|█▊        | 2/11 [00:01<00:06,  1.31it/s]update embedding:  27%|██▋       | 3/11 [00:02<00:05,  1.34it/s]update embedding:  36%|███▋      | 4/11 [00:02<00:05,  1.34it/s]update embedding:  45%|████▌     | 5/11 [00:03<00:04,  1.36it/s]update embedding:  55%|█████▍    | 6/11 [00:04<00:03,  1.36it/s]update embedding:  64%|██████▎   | 7/11 [00:05<00:02,  1.33it/s]update embedding:  73%|███████▎  | 8/11 [00:05<00:02,  1.34it/s]update embedding:  82%|████████▏ | 9/11 [00:06<00:01,  1.33it/s]update embedding:  91%|█████████ | 10/11 [00:07<00:00,  1.32it/s]update embedding: 100%|██████████| 11/11 [00:08<00:00,  1.33it/s]update embedding: 100%|██████████| 11/11 [00:08<00:00,  1.34it/s]
update embedding:   0%|          | 0/11 [00:00<?, ?it/s]update embedding:   9%|▉         | 1/11 [00:00<00:07,  1.36it/s]update embedding:  18%|█▊        | 2/11 [00:01<00:06,  1.36it/s]update embedding:  27%|██▋       | 3/11 [00:02<00:05,  1.36it/s]update embedding:  36%|███▋      | 4/11 [00:02<00:05,  1.36it/s]update embedding:  45%|████▌     | 5/11 [00:03<00:04,  1.34it/s]update embedding:  55%|█████▍    | 6/11 [00:04<00:03,  1.33it/s]update embedding:  64%|██████▎   | 7/11 [00:05<00:02,  1.34it/s]update embedding:  73%|███████▎  | 8/11 [00:05<00:02,  1.35it/s]update embedding:  82%|████████▏ | 9/11 [00:06<00:01,  1.32it/s]update embedding:  91%|█████████ | 10/11 [00:07<00:00,  1.32it/s]update embedding: 100%|██████████| 11/11 [00:08<00:00,  1.33it/s]update embedding: 100%|██████████| 11/11 [00:08<00:00,  1.34it/s]
retrival evaluation:   0%|          | 0/31 [00:00<?, ?it/s]retrival evaluation:  26%|██▌       | 8/31 [00:00<00:00, 72.63it/s]retrival evaluation:  52%|█████▏    | 16/31 [00:00<00:00, 74.26it/s]retrival evaluation:  77%|███████▋  | 24/31 [00:00<00:00, 75.81it/s]retrival evaluation: 100%|██████████| 31/31 [00:00<00:00, 78.54it/s]

pk3=0, pk2=0,pk1=0 best_f1 = 0.213, bets_f2=0.37, MAP=0.198, MRR=0, AP=0.096, exe_time=17.027623414993286

INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:__main__:model loaded
INFO:EMSE.BERTDataReader:Creating examples from dataset file at /afs/crc.nd.edu/user/j/jlin6/data/EMSE/nacos/test
update feature:   0%|          | 0/17 [00:00<?, ?it/s]update feature:  71%|███████   | 12/17 [00:00<00:00, 105.48it/s]update feature: 100%|██████████| 17/17 [00:00<00:00, 104.16it/s]
update feature:   0%|          | 0/17 [00:00<?, ?it/s]update feature: 100%|██████████| 17/17 [00:00<00:00, 663.90it/s]
update embedding:   0%|          | 0/17 [00:00<?, ?it/s]update embedding:   6%|▌         | 1/17 [00:00<00:12,  1.23it/s]update embedding:  12%|█▏        | 2/17 [00:01<00:12,  1.20it/s]update embedding:  18%|█▊        | 3/17 [00:02<00:11,  1.22it/s]update embedding:  24%|██▎       | 4/17 [00:03<00:10,  1.23it/s]update embedding:  29%|██▉       | 5/17 [00:04<00:09,  1.27it/s]update embedding:  35%|███▌      | 6/17 [00:04<00:08,  1.26it/s]update embedding:  41%|████      | 7/17 [00:05<00:08,  1.24it/s]update embedding:  47%|████▋     | 8/17 [00:06<00:07,  1.22it/s]update embedding:  53%|█████▎    | 9/17 [00:07<00:06,  1.15it/s]update embedding:  59%|█████▉    | 10/17 [00:08<00:05,  1.18it/s]update embedding:  65%|██████▍   | 11/17 [00:09<00:05,  1.19it/s]update embedding:  71%|███████   | 12/17 [00:09<00:04,  1.18it/s]update embedding:  76%|███████▋  | 13/17 [00:10<00:03,  1.18it/s]update embedding:  82%|████████▏ | 14/17 [00:11<00:02,  1.19it/s]update embedding:  88%|████████▊ | 15/17 [00:12<00:01,  1.19it/s]update embedding:  94%|█████████▍| 16/17 [00:13<00:00,  1.20it/s]update embedding: 100%|██████████| 17/17 [00:14<00:00,  1.14it/s]update embedding: 100%|██████████| 17/17 [00:14<00:00,  1.19it/s]
update embedding:   0%|          | 0/17 [00:00<?, ?it/s]update embedding:   6%|▌         | 1/17 [00:00<00:13,  1.19it/s]update embedding:  12%|█▏        | 2/17 [00:01<00:12,  1.18it/s]update embedding:  18%|█▊        | 3/17 [00:02<00:11,  1.17it/s]update embedding:  24%|██▎       | 4/17 [00:03<00:10,  1.19it/s]update embedding:  29%|██▉       | 5/17 [00:04<00:10,  1.15it/s]update embedding:  35%|███▌      | 6/17 [00:05<00:09,  1.14it/s]update embedding:  41%|████      | 7/17 [00:06<00:08,  1.15it/s]update embedding:  47%|████▋     | 8/17 [00:06<00:07,  1.18it/s]update embedding:  53%|█████▎    | 9/17 [00:07<00:06,  1.19it/s]update embedding:  59%|█████▉    | 10/17 [00:08<00:05,  1.23it/s]update embedding:  65%|██████▍   | 11/17 [00:09<00:04,  1.24it/s]update embedding:  71%|███████   | 12/17 [00:09<00:03,  1.26it/s]update embedding:  76%|███████▋  | 13/17 [00:10<00:03,  1.23it/s]update embedding:  82%|████████▏ | 14/17 [00:11<00:02,  1.23it/s]update embedding:  88%|████████▊ | 15/17 [00:12<00:01,  1.21it/s]update embedding:  94%|█████████▍| 16/17 [00:13<00:00,  1.19it/s]update embedding: 100%|██████████| 17/17 [00:14<00:00,  1.20it/s]update embedding: 100%|██████████| 17/17 [00:14<00:00,  1.20it/s]
retrival evaluation:   0%|          | 0/73 [00:00<?, ?it/s]retrival evaluation:   8%|▊         | 6/73 [00:00<00:01, 55.60it/s]retrival evaluation:  19%|█▉        | 14/73 [00:00<00:00, 60.13it/s]retrival evaluation:  30%|███       | 22/73 [00:00<00:00, 63.77it/s]retrival evaluation:  41%|████      | 30/73 [00:00<00:00, 66.32it/s]retrival evaluation:  52%|█████▏    | 38/73 [00:00<00:00, 68.57it/s]retrival evaluation:  63%|██████▎   | 46/73 [00:00<00:00, 69.92it/s]retrival evaluation:  74%|███████▍  | 54/73 [00:00<00:00, 70.83it/s]retrival evaluation:  84%|████████▎ | 61/73 [00:00<00:00, 70.43it/s]retrival evaluation:  95%|█████████▍| 69/73 [00:00<00:00, 71.72it/s]retrival evaluation: 100%|██████████| 73/73 [00:01<00:00, 72.20it/s]

pk3=0, pk2=0,pk1=0 best_f1 = 0.133, bets_f2=0.246, MAP=0.202, MRR=0, AP=0.067, exe_time=30.164702653884888

INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:__main__:model loaded
INFO:EMSE.BERTDataReader:Creating examples from dataset file at /afs/crc.nd.edu/user/j/jlin6/data/EMSE/ncnn/test
update feature:   0%|          | 0/11 [00:00<?, ?it/s]update feature: 100%|██████████| 11/11 [00:00<00:00, 309.41it/s]
update feature:   0%|          | 0/11 [00:00<?, ?it/s]update feature: 100%|██████████| 11/11 [00:00<00:00, 552.03it/s]
update embedding:   0%|          | 0/11 [00:00<?, ?it/s]update embedding:   9%|▉         | 1/11 [00:00<00:09,  1.05it/s]update embedding:  18%|█▊        | 2/11 [00:01<00:08,  1.08it/s]update embedding:  27%|██▋       | 3/11 [00:02<00:07,  1.10it/s]update embedding:  36%|███▋      | 4/11 [00:03<00:06,  1.12it/s]update embedding:  45%|████▌     | 5/11 [00:04<00:05,  1.12it/s]update embedding:  55%|█████▍    | 6/11 [00:05<00:04,  1.13it/s]update embedding:  64%|██████▎   | 7/11 [00:06<00:03,  1.15it/s]update embedding:  73%|███████▎  | 8/11 [00:07<00:02,  1.15it/s]update embedding:  82%|████████▏ | 9/11 [00:07<00:01,  1.15it/s]update embedding:  91%|█████████ | 10/11 [00:08<00:00,  1.15it/s]update embedding: 100%|██████████| 11/11 [00:09<00:00,  1.15it/s]update embedding: 100%|██████████| 11/11 [00:09<00:00,  1.14it/s]
update embedding:   0%|          | 0/11 [00:00<?, ?it/s]update embedding:   9%|▉         | 1/11 [00:00<00:07,  1.29it/s]update embedding:  18%|█▊        | 2/11 [00:01<00:07,  1.27it/s]update embedding:  27%|██▋       | 3/11 [00:02<00:06,  1.26it/s]update embedding:  36%|███▋      | 4/11 [00:03<00:05,  1.21it/s]update embedding:  45%|████▌     | 5/11 [00:04<00:05,  1.19it/s]update embedding:  55%|█████▍    | 6/11 [00:05<00:04,  1.18it/s]update embedding:  64%|██████▎   | 7/11 [00:05<00:03,  1.21it/s]update embedding:  73%|███████▎  | 8/11 [00:06<00:02,  1.21it/s]update embedding:  82%|████████▏ | 9/11 [00:07<00:01,  1.23it/s]update embedding:  91%|█████████ | 10/11 [00:08<00:00,  1.24it/s]update embedding: 100%|██████████| 11/11 [00:08<00:00,  1.25it/s]update embedding: 100%|██████████| 11/11 [00:08<00:00,  1.22it/s]
retrival evaluation:   0%|          | 0/31 [00:00<?, ?it/s]retrival evaluation:  16%|█▌        | 5/31 [00:00<00:00, 49.28it/s]retrival evaluation:  42%|████▏     | 13/31 [00:00<00:00, 55.51it/s]retrival evaluation:  68%|██████▊   | 21/31 [00:00<00:00, 59.50it/s]retrival evaluation:  94%|█████████▎| 29/31 [00:00<00:00, 64.23it/s]retrival evaluation: 100%|██████████| 31/31 [00:00<00:00, 71.55it/s]

pk3=0, pk2=0,pk1=0 best_f1 = 0.231, bets_f2=0.34, MAP=0.277, MRR=0, AP=0.12, exe_time=19.176095724105835

INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:__main__:model loaded
INFO:EMSE.BERTDataReader:Creating examples from dataset file at /afs/crc.nd.edu/user/j/jlin6/data/EMSE/pegasus/test
update feature:   0%|          | 0/17 [00:00<?, ?it/s]update feature: 100%|██████████| 17/17 [00:00<00:00, 246.52it/s]
update feature:   0%|          | 0/17 [00:00<?, ?it/s]update feature: 100%|██████████| 17/17 [00:00<00:00, 1783.65it/s]
update embedding:   0%|          | 0/17 [00:00<?, ?it/s]update embedding:   6%|▌         | 1/17 [00:00<00:12,  1.25it/s]update embedding:  12%|█▏        | 2/17 [00:01<00:11,  1.26it/s]update embedding:  18%|█▊        | 3/17 [00:02<00:11,  1.27it/s]update embedding:  24%|██▎       | 4/17 [00:03<00:10,  1.28it/s]update embedding:  29%|██▉       | 5/17 [00:03<00:09,  1.29it/s]update embedding:  35%|███▌      | 6/17 [00:04<00:08,  1.30it/s]update embedding:  41%|████      | 7/17 [00:05<00:07,  1.30it/s]update embedding:  47%|████▋     | 8/17 [00:06<00:06,  1.31it/s]update embedding:  53%|█████▎    | 9/17 [00:06<00:06,  1.32it/s]update embedding:  59%|█████▉    | 10/17 [00:07<00:05,  1.33it/s]update embedding:  65%|██████▍   | 11/17 [00:08<00:04,  1.32it/s]update embedding:  71%|███████   | 12/17 [00:09<00:03,  1.32it/s]update embedding:  76%|███████▋  | 13/17 [00:09<00:03,  1.33it/s]update embedding:  82%|████████▏ | 14/17 [00:10<00:02,  1.34it/s]update embedding:  88%|████████▊ | 15/17 [00:11<00:01,  1.35it/s]update embedding:  94%|█████████▍| 16/17 [00:12<00:00,  1.35it/s]update embedding: 100%|██████████| 17/17 [00:12<00:00,  1.34it/s]update embedding: 100%|██████████| 17/17 [00:12<00:00,  1.32it/s]
update embedding:   0%|          | 0/17 [00:00<?, ?it/s]update embedding:   6%|▌         | 1/17 [00:00<00:11,  1.35it/s]update embedding:  12%|█▏        | 2/17 [00:01<00:11,  1.35it/s]update embedding:  18%|█▊        | 3/17 [00:02<00:10,  1.35it/s]update embedding:  24%|██▎       | 4/17 [00:02<00:09,  1.36it/s]update embedding:  29%|██▉       | 5/17 [00:03<00:08,  1.34it/s]update embedding:  35%|███▌      | 6/17 [00:04<00:08,  1.34it/s]update embedding:  41%|████      | 7/17 [00:05<00:07,  1.35it/s]update embedding:  47%|████▋     | 8/17 [00:05<00:06,  1.34it/s]update embedding:  53%|█████▎    | 9/17 [00:06<00:05,  1.34it/s]update embedding:  59%|█████▉    | 10/17 [00:07<00:05,  1.33it/s]update embedding:  65%|██████▍   | 11/17 [00:08<00:04,  1.32it/s]update embedding:  71%|███████   | 12/17 [00:08<00:03,  1.32it/s]update embedding:  76%|███████▋  | 13/17 [00:09<00:03,  1.31it/s]update embedding:  82%|████████▏ | 14/17 [00:10<00:02,  1.31it/s]update embedding:  88%|████████▊ | 15/17 [00:11<00:01,  1.31it/s]update embedding:  94%|█████████▍| 16/17 [00:12<00:00,  1.31it/s]update embedding: 100%|██████████| 17/17 [00:12<00:00,  1.31it/s]update embedding: 100%|██████████| 17/17 [00:12<00:00,  1.33it/s]
retrival evaluation:   0%|          | 0/73 [00:00<?, ?it/s]retrival evaluation:  10%|▉         | 7/73 [00:00<00:01, 65.10it/s]retrival evaluation:  21%|██        | 15/73 [00:00<00:00, 68.92it/s]retrival evaluation:  32%|███▏      | 23/73 [00:00<00:00, 71.74it/s]retrival evaluation:  44%|████▍     | 32/73 [00:00<00:00, 74.06it/s]retrival evaluation:  55%|█████▍    | 40/73 [00:00<00:00, 75.60it/s]retrival evaluation:  66%|██████▌   | 48/73 [00:00<00:00, 76.24it/s]retrival evaluation:  78%|███████▊  | 57/73 [00:00<00:00, 77.36it/s]retrival evaluation:  90%|█████████ | 66/73 [00:00<00:00, 78.18it/s]retrival evaluation: 100%|██████████| 73/73 [00:00<00:00, 78.62it/s]

pk3=0, pk2=0,pk1=0 best_f1 = 0.182, bets_f2=0.273, MAP=0.294, MRR=0, AP=0.136, exe_time=26.781126499176025

INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:__main__:model loaded
INFO:EMSE.BERTDataReader:Creating examples from dataset file at /afs/crc.nd.edu/user/j/jlin6/data/EMSE/QMUI_iOS/test
update feature:   0%|          | 0/12 [00:00<?, ?it/s]update feature: 100%|██████████| 12/12 [00:00<00:00, 327.24it/s]
update feature:   0%|          | 0/12 [00:00<?, ?it/s]update feature: 100%|██████████| 12/12 [00:00<00:00, 1178.75it/s]
update embedding:   0%|          | 0/12 [00:00<?, ?it/s]update embedding:   8%|▊         | 1/12 [00:00<00:09,  1.15it/s]update embedding:  17%|█▋        | 2/12 [00:01<00:08,  1.16it/s]update embedding:  25%|██▌       | 3/12 [00:02<00:07,  1.17it/s]update embedding:  33%|███▎      | 4/12 [00:03<00:06,  1.18it/s]update embedding:  42%|████▏     | 5/12 [00:04<00:06,  1.16it/s]update embedding:  50%|█████     | 6/12 [00:05<00:05,  1.19it/s]update embedding:  58%|█████▊    | 7/12 [00:05<00:04,  1.15it/s]update embedding:  67%|██████▋   | 8/12 [00:06<00:03,  1.16it/s]update embedding:  75%|███████▌  | 9/12 [00:07<00:02,  1.18it/s]update embedding:  83%|████████▎ | 10/12 [00:08<00:01,  1.20it/s]update embedding:  92%|█████████▏| 11/12 [00:09<00:00,  1.21it/s]update embedding: 100%|██████████| 12/12 [00:10<00:00,  1.23it/s]update embedding: 100%|██████████| 12/12 [00:10<00:00,  1.19it/s]
update embedding:   0%|          | 0/12 [00:00<?, ?it/s]update embedding:   8%|▊         | 1/12 [00:00<00:08,  1.35it/s]update embedding:  17%|█▋        | 2/12 [00:01<00:07,  1.35it/s]update embedding:  25%|██▌       | 3/12 [00:02<00:06,  1.34it/s]update embedding:  33%|███▎      | 4/12 [00:03<00:06,  1.32it/s]update embedding:  42%|████▏     | 5/12 [00:03<00:05,  1.30it/s]update embedding:  50%|█████     | 6/12 [00:04<00:04,  1.31it/s]update embedding:  58%|█████▊    | 7/12 [00:05<00:03,  1.31it/s]update embedding:  67%|██████▋   | 8/12 [00:06<00:03,  1.30it/s]update embedding:  75%|███████▌  | 9/12 [00:06<00:02,  1.31it/s]update embedding:  83%|████████▎ | 10/12 [00:07<00:01,  1.30it/s]update embedding:  92%|█████████▏| 11/12 [00:08<00:00,  1.30it/s]update embedding: 100%|██████████| 12/12 [00:09<00:00,  1.32it/s]update embedding: 100%|██████████| 12/12 [00:09<00:00,  1.31it/s]
retrival evaluation:   0%|          | 0/36 [00:00<?, ?it/s]retrival evaluation:  19%|█▉        | 7/36 [00:00<00:00, 64.27it/s]retrival evaluation:  42%|████▏     | 15/36 [00:00<00:00, 67.78it/s]retrival evaluation:  64%|██████▍   | 23/36 [00:00<00:00, 70.42it/s]retrival evaluation:  86%|████████▌ | 31/36 [00:00<00:00, 72.60it/s]retrival evaluation: 100%|██████████| 36/36 [00:00<00:00, 74.52it/s]

pk3=0, pk2=0,pk1=0 best_f1 = 0.182, bets_f2=0.347, MAP=0.316, MRR=0, AP=0.103, exe_time=19.86102819442749

INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:__main__:model loaded
INFO:EMSE.BERTDataReader:Creating examples from dataset file at /afs/crc.nd.edu/user/j/jlin6/data/EMSE/QMUI_Android/test
update feature:   0%|          | 0/8 [00:00<?, ?it/s]update feature: 100%|██████████| 8/8 [00:00<00:00, 88.90it/s]
update feature:   0%|          | 0/8 [00:00<?, ?it/s]update feature: 100%|██████████| 8/8 [00:00<00:00, 513.41it/s]
update embedding:   0%|          | 0/8 [00:00<?, ?it/s]update embedding:  12%|█▎        | 1/8 [00:00<00:05,  1.22it/s]update embedding:  25%|██▌       | 2/8 [00:01<00:04,  1.21it/s]update embedding:  38%|███▊      | 3/8 [00:02<00:04,  1.21it/s]update embedding:  50%|█████     | 4/8 [00:03<00:03,  1.22it/s]update embedding:  62%|██████▎   | 5/8 [00:04<00:02,  1.20it/s]update embedding:  75%|███████▌  | 6/8 [00:05<00:01,  1.18it/s]update embedding:  88%|████████▊ | 7/8 [00:05<00:00,  1.19it/s]update embedding: 100%|██████████| 8/8 [00:06<00:00,  1.15it/s]update embedding: 100%|██████████| 8/8 [00:06<00:00,  1.18it/s]
update embedding:   0%|          | 0/8 [00:00<?, ?it/s]update embedding:  12%|█▎        | 1/8 [00:00<00:05,  1.24it/s]update embedding:  25%|██▌       | 2/8 [00:01<00:04,  1.25it/s]update embedding:  38%|███▊      | 3/8 [00:02<00:03,  1.25it/s]update embedding:  50%|█████     | 4/8 [00:03<00:03,  1.26it/s]update embedding:  62%|██████▎   | 5/8 [00:04<00:02,  1.23it/s]update embedding:  75%|███████▌  | 6/8 [00:04<00:01,  1.23it/s]update embedding:  88%|████████▊ | 7/8 [00:05<00:00,  1.15it/s]update embedding: 100%|██████████| 8/8 [00:06<00:00,  1.16it/s]update embedding: 100%|██████████| 8/8 [00:06<00:00,  1.20it/s]
retrival evaluation:   0%|          | 0/16 [00:00<?, ?it/s]retrival evaluation:  38%|███▊      | 6/16 [00:00<00:00, 55.11it/s]retrival evaluation:  88%|████████▊ | 14/16 [00:00<00:00, 59.53it/s]retrival evaluation: 100%|██████████| 16/16 [00:00<00:00, 65.40it/s]

pk3=0, pk2=0,pk1=0 best_f1 = 0.267, bets_f2=0.44, MAP=0.336, MRR=0, AP=0.163, exe_time=13.929566860198975

INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:__main__:model loaded
INFO:EMSE.BERTDataReader:Creating examples from dataset file at /afs/crc.nd.edu/user/j/jlin6/data/EMSE/rax/test
update feature:   0%|          | 0/56 [00:00<?, ?it/s]update feature:  52%|█████▏    | 29/56 [00:00<00:00, 289.85it/s]update feature: 100%|██████████| 56/56 [00:00<00:00, 396.64it/s]
update feature:   0%|          | 0/56 [00:00<?, ?it/s]update feature: 100%|██████████| 56/56 [00:00<00:00, 2024.26it/s]
update embedding:   0%|          | 0/56 [00:00<?, ?it/s]update embedding:   2%|▏         | 1/56 [00:00<00:44,  1.25it/s]update embedding:   4%|▎         | 2/56 [00:01<00:42,  1.27it/s]update embedding:   5%|▌         | 3/56 [00:02<00:41,  1.27it/s]update embedding:   7%|▋         | 4/56 [00:03<00:40,  1.27it/s]update embedding:   9%|▉         | 5/56 [00:03<00:40,  1.26it/s]update embedding:  11%|█         | 6/56 [00:04<00:39,  1.27it/s]update embedding:  12%|█▎        | 7/56 [00:05<00:38,  1.27it/s]update embedding:  14%|█▍        | 8/56 [00:06<00:37,  1.27it/s]update embedding:  16%|█▌        | 9/56 [00:07<00:36,  1.29it/s]update embedding:  18%|█▊        | 10/56 [00:07<00:35,  1.28it/s]update embedding:  20%|█▉        | 11/56 [00:08<00:34,  1.29it/s]update embedding:  21%|██▏       | 12/56 [00:09<00:33,  1.30it/s]update embedding:  23%|██▎       | 13/56 [00:10<00:33,  1.29it/s]update embedding:  25%|██▌       | 14/56 [00:10<00:32,  1.30it/s]update embedding:  27%|██▋       | 15/56 [00:11<00:31,  1.31it/s]update embedding:  29%|██▊       | 16/56 [00:12<00:30,  1.31it/s]update embedding:  30%|███       | 17/56 [00:13<00:29,  1.31it/s]update embedding:  32%|███▏      | 18/56 [00:13<00:29,  1.31it/s]update embedding:  34%|███▍      | 19/56 [00:14<00:28,  1.29it/s]update embedding:  36%|███▌      | 20/56 [00:15<00:27,  1.29it/s]update embedding:  38%|███▊      | 21/56 [00:16<00:27,  1.29it/s]update embedding:  39%|███▉      | 22/56 [00:17<00:26,  1.30it/s]update embedding:  41%|████      | 23/56 [00:17<00:25,  1.30it/s]update embedding:  43%|████▎     | 24/56 [00:18<00:24,  1.31it/s]update embedding:  45%|████▍     | 25/56 [00:19<00:23,  1.32it/s]update embedding:  46%|████▋     | 26/56 [00:20<00:22,  1.31it/s]update embedding:  48%|████▊     | 27/56 [00:20<00:21,  1.32it/s]update embedding:  50%|█████     | 28/56 [00:21<00:21,  1.32it/s]update embedding:  52%|█████▏    | 29/56 [00:22<00:20,  1.33it/s]update embedding:  54%|█████▎    | 30/56 [00:23<00:19,  1.33it/s]update embedding:  55%|█████▌    | 31/56 [00:23<00:18,  1.33it/s]update embedding:  57%|█████▋    | 32/56 [00:24<00:18,  1.32it/s]update embedding:  59%|█████▉    | 33/56 [00:25<00:17,  1.32it/s]update embedding:  61%|██████    | 34/56 [00:26<00:16,  1.32it/s]update embedding:  62%|██████▎   | 35/56 [00:26<00:15,  1.33it/s]update embedding:  64%|██████▍   | 36/56 [00:27<00:14,  1.34it/s]update embedding:  66%|██████▌   | 37/56 [00:28<00:14,  1.34it/s]update embedding:  68%|██████▊   | 38/56 [00:29<00:13,  1.34it/s]update embedding:  70%|██████▉   | 39/56 [00:29<00:12,  1.34it/s]update embedding:  71%|███████▏  | 40/56 [00:30<00:11,  1.33it/s]update embedding:  73%|███████▎  | 41/56 [00:31<00:11,  1.33it/s]update embedding:  75%|███████▌  | 42/56 [00:32<00:10,  1.33it/s]update embedding:  77%|███████▋  | 43/56 [00:32<00:09,  1.34it/s]update embedding:  79%|███████▊  | 44/56 [00:33<00:08,  1.34it/s]update embedding:  80%|████████  | 45/56 [00:34<00:08,  1.34it/s]update embedding:  82%|████████▏ | 46/56 [00:35<00:07,  1.34it/s]update embedding:  84%|████████▍ | 47/56 [00:35<00:06,  1.34it/s]update embedding:  86%|████████▌ | 48/56 [00:36<00:05,  1.34it/s]update embedding:  88%|████████▊ | 49/56 [00:37<00:05,  1.35it/s]update embedding:  89%|████████▉ | 50/56 [00:38<00:04,  1.34it/s]update embedding:  91%|█████████ | 51/56 [00:38<00:03,  1.32it/s]update embedding:  93%|█████████▎| 52/56 [00:39<00:03,  1.32it/s]update embedding:  95%|█████████▍| 53/56 [00:40<00:02,  1.32it/s]update embedding:  96%|█████████▋| 54/56 [00:41<00:01,  1.33it/s]update embedding:  98%|█████████▊| 55/56 [00:41<00:00,  1.32it/s]update embedding: 100%|██████████| 56/56 [00:42<00:00,  1.33it/s]update embedding: 100%|██████████| 56/56 [00:42<00:00,  1.31it/s]
update embedding:   0%|          | 0/56 [00:00<?, ?it/s]update embedding:   2%|▏         | 1/56 [00:00<00:41,  1.33it/s]update embedding:   4%|▎         | 2/56 [00:01<00:40,  1.33it/s]update embedding:   5%|▌         | 3/56 [00:02<00:39,  1.33it/s]update embedding:   7%|▋         | 4/56 [00:02<00:38,  1.33it/s]update embedding:   9%|▉         | 5/56 [00:03<00:38,  1.33it/s]update embedding:  11%|█         | 6/56 [00:04<00:37,  1.33it/s]update embedding:  12%|█▎        | 7/56 [00:05<00:36,  1.35it/s]update embedding:  14%|█▍        | 8/56 [00:06<00:36,  1.30it/s]update embedding:  16%|█▌        | 9/56 [00:06<00:35,  1.31it/s]update embedding:  18%|█▊        | 10/56 [00:07<00:34,  1.32it/s]update embedding:  20%|█▉        | 11/56 [00:08<00:33,  1.33it/s]update embedding:  21%|██▏       | 12/56 [00:09<00:33,  1.31it/s]update embedding:  23%|██▎       | 13/56 [00:09<00:32,  1.32it/s]update embedding:  25%|██▌       | 14/56 [00:10<00:31,  1.33it/s]update embedding:  27%|██▋       | 15/56 [00:11<00:30,  1.33it/s]update embedding:  29%|██▊       | 16/56 [00:12<00:29,  1.33it/s]update embedding:  30%|███       | 17/56 [00:12<00:29,  1.34it/s]update embedding:  32%|███▏      | 18/56 [00:13<00:28,  1.34it/s]update embedding:  34%|███▍      | 19/56 [00:14<00:27,  1.34it/s]update embedding:  36%|███▌      | 20/56 [00:15<00:26,  1.34it/s]update embedding:  38%|███▊      | 21/56 [00:15<00:25,  1.35it/s]update embedding:  39%|███▉      | 22/56 [00:16<00:25,  1.33it/s]update embedding:  41%|████      | 23/56 [00:17<00:24,  1.33it/s]update embedding:  43%|████▎     | 24/56 [00:18<00:24,  1.33it/s]update embedding:  45%|████▍     | 25/56 [00:18<00:23,  1.33it/s]update embedding:  46%|████▋     | 26/56 [00:19<00:22,  1.33it/s]update embedding:  48%|████▊     | 27/56 [00:20<00:21,  1.33it/s]update embedding:  50%|█████     | 28/56 [00:21<00:21,  1.31it/s]update embedding:  52%|█████▏    | 29/56 [00:21<00:20,  1.32it/s]update embedding:  54%|█████▎    | 30/56 [00:22<00:19,  1.33it/s]update embedding:  55%|█████▌    | 31/56 [00:23<00:18,  1.33it/s]update embedding:  57%|█████▋    | 32/56 [00:24<00:17,  1.33it/s]update embedding:  59%|█████▉    | 33/56 [00:24<00:17,  1.33it/s]update embedding:  61%|██████    | 34/56 [00:25<00:16,  1.33it/s]update embedding:  62%|██████▎   | 35/56 [00:26<00:15,  1.32it/s]update embedding:  64%|██████▍   | 36/56 [00:27<00:15,  1.30it/s]update embedding:  66%|██████▌   | 37/56 [00:27<00:14,  1.29it/s]update embedding:  68%|██████▊   | 38/56 [00:28<00:14,  1.25it/s]update embedding:  70%|██████▉   | 39/56 [00:29<00:13,  1.22it/s]update embedding:  71%|███████▏  | 40/56 [00:30<00:13,  1.21it/s]update embedding:  73%|███████▎  | 41/56 [00:31<00:12,  1.20it/s]update embedding:  75%|███████▌  | 42/56 [00:32<00:11,  1.19it/s]update embedding:  77%|███████▋  | 43/56 [00:33<00:11,  1.18it/s]update embedding:  79%|███████▊  | 44/56 [00:33<00:10,  1.18it/s]update embedding:  80%|████████  | 45/56 [00:34<00:09,  1.17it/s]update embedding:  82%|████████▏ | 46/56 [00:35<00:08,  1.17it/s]update embedding:  84%|████████▍ | 47/56 [00:36<00:07,  1.17it/s]update embedding:  86%|████████▌ | 48/56 [00:37<00:06,  1.16it/s]update embedding:  88%|████████▊ | 49/56 [00:38<00:06,  1.16it/s]update embedding:  89%|████████▉ | 50/56 [00:39<00:05,  1.16it/s]update embedding:  91%|█████████ | 51/56 [00:39<00:04,  1.16it/s]update embedding:  93%|█████████▎| 52/56 [00:40<00:03,  1.16it/s]update embedding:  95%|█████████▍| 53/56 [00:41<00:02,  1.16it/s]update embedding:  96%|█████████▋| 54/56 [00:42<00:01,  1.15it/s]update embedding:  98%|█████████▊| 55/56 [00:43<00:00,  1.15it/s]update embedding: 100%|██████████| 56/56 [00:44<00:00,  1.15it/s]update embedding: 100%|██████████| 56/56 [00:44<00:00,  1.26it/s]
retrival evaluation:   0%|          | 0/784 [00:00<?, ?it/s]retrival evaluation:   1%|          | 7/784 [00:00<00:12, 61.42it/s]retrival evaluation:   2%|▏         | 15/784 [00:00<00:11, 66.02it/s]retrival evaluation:   3%|▎         | 24/784 [00:00<00:10, 69.85it/s]retrival evaluation:   4%|▍         | 33/784 [00:00<00:10, 72.87it/s]retrival evaluation:   5%|▌         | 42/784 [00:00<00:09, 75.24it/s]retrival evaluation:   6%|▋         | 50/784 [00:00<00:09, 76.43it/s]retrival evaluation:   8%|▊         | 59/784 [00:00<00:09, 77.72it/s]retrival evaluation:   9%|▊         | 68/784 [00:00<00:09, 78.91it/s]retrival evaluation:  10%|▉         | 77/784 [00:00<00:08, 79.47it/s]retrival evaluation:  11%|█         | 86/784 [00:01<00:08, 79.87it/s]retrival evaluation:  12%|█▏        | 95/784 [00:01<00:08, 80.71it/s]retrival evaluation:  13%|█▎        | 104/784 [00:01<00:08, 81.08it/s]retrival evaluation:  14%|█▍        | 113/784 [00:01<00:08, 81.28it/s]retrival evaluation:  16%|█▌        | 122/784 [00:01<00:08, 81.51it/s]retrival evaluation:  17%|█▋        | 131/784 [00:01<00:07, 81.64it/s]retrival evaluation:  18%|█▊        | 140/784 [00:01<00:07, 81.83it/s]retrival evaluation:  19%|█▉        | 149/784 [00:01<00:07, 81.68it/s]retrival evaluation:  20%|██        | 158/784 [00:01<00:07, 81.86it/s]retrival evaluation:  21%|██▏       | 167/784 [00:02<00:07, 82.28it/s]retrival evaluation:  22%|██▏       | 176/784 [00:02<00:07, 82.11it/s]retrival evaluation:  24%|██▎       | 185/784 [00:02<00:07, 80.89it/s]retrival evaluation:  25%|██▍       | 194/784 [00:02<00:07, 81.12it/s]retrival evaluation:  26%|██▌       | 203/784 [00:02<00:07, 80.89it/s]retrival evaluation:  27%|██▋       | 212/784 [00:02<00:07, 80.16it/s]retrival evaluation:  28%|██▊       | 221/784 [00:02<00:06, 80.70it/s]retrival evaluation:  29%|██▉       | 230/784 [00:02<00:06, 80.60it/s]retrival evaluation:  30%|███       | 239/784 [00:02<00:06, 80.86it/s]retrival evaluation:  32%|███▏      | 248/784 [00:03<00:06, 80.93it/s]retrival evaluation:  33%|███▎      | 257/784 [00:03<00:06, 81.11it/s]retrival evaluation:  34%|███▍      | 266/784 [00:03<00:06, 81.13it/s]retrival evaluation:  35%|███▌      | 275/784 [00:03<00:06, 80.95it/s]retrival evaluation:  36%|███▌      | 284/784 [00:03<00:06, 81.54it/s]retrival evaluation:  37%|███▋      | 293/784 [00:03<00:06, 81.30it/s]retrival evaluation:  39%|███▊      | 302/784 [00:03<00:05, 80.87it/s]retrival evaluation:  40%|███▉      | 311/784 [00:03<00:05, 80.64it/s]retrival evaluation:  41%|████      | 320/784 [00:03<00:05, 81.26it/s]retrival evaluation:  42%|████▏     | 329/784 [00:04<00:05, 81.21it/s]retrival evaluation:  43%|████▎     | 338/784 [00:04<00:05, 81.09it/s]retrival evaluation:  44%|████▍     | 347/784 [00:04<00:05, 80.99it/s]retrival evaluation:  45%|████▌     | 356/784 [00:04<00:05, 81.29it/s]retrival evaluation:  47%|████▋     | 365/784 [00:04<00:05, 81.29it/s]retrival evaluation:  48%|████▊     | 374/784 [00:04<00:05, 80.99it/s]retrival evaluation:  49%|████▉     | 383/784 [00:04<00:04, 80.92it/s]retrival evaluation:  50%|█████     | 392/784 [00:04<00:04, 81.23it/s]retrival evaluation:  51%|█████     | 401/784 [00:04<00:04, 81.18it/s]retrival evaluation:  52%|█████▏    | 410/784 [00:05<00:04, 81.47it/s]retrival evaluation:  53%|█████▎    | 419/784 [00:05<00:04, 81.48it/s]retrival evaluation:  55%|█████▍    | 428/784 [00:05<00:04, 81.22it/s]retrival evaluation:  56%|█████▌    | 437/784 [00:05<00:04, 80.83it/s]retrival evaluation:  57%|█████▋    | 446/784 [00:05<00:04, 81.20it/s]retrival evaluation:  58%|█████▊    | 455/784 [00:05<00:04, 81.15it/s]retrival evaluation:  59%|█████▉    | 464/784 [00:05<00:03, 81.12it/s]retrival evaluation:  60%|██████    | 473/784 [00:05<00:03, 81.00it/s]retrival evaluation:  61%|██████▏   | 482/784 [00:05<00:03, 81.10it/s]retrival evaluation:  63%|██████▎   | 491/784 [00:06<00:03, 81.41it/s]retrival evaluation:  64%|██████▍   | 500/784 [00:06<00:03, 81.03it/s]retrival evaluation:  65%|██████▍   | 509/784 [00:06<00:03, 80.87it/s]retrival evaluation:  66%|██████▌   | 518/784 [00:06<00:03, 80.99it/s]retrival evaluation:  67%|██████▋   | 527/784 [00:06<00:03, 81.34it/s]retrival evaluation:  68%|██████▊   | 536/784 [00:06<00:03, 81.34it/s]retrival evaluation:  70%|██████▉   | 545/784 [00:06<00:02, 81.15it/s]retrival evaluation:  71%|███████   | 554/784 [00:06<00:02, 80.88it/s]retrival evaluation:  72%|███████▏  | 563/784 [00:06<00:02, 80.69it/s]retrival evaluation:  73%|███████▎  | 572/784 [00:07<00:02, 80.83it/s]retrival evaluation:  74%|███████▍  | 581/784 [00:07<00:02, 80.71it/s]retrival evaluation:  75%|███████▌  | 590/784 [00:07<00:02, 80.81it/s]retrival evaluation:  76%|███████▋  | 599/784 [00:07<00:02, 80.93it/s]retrival evaluation:  78%|███████▊  | 608/784 [00:07<00:02, 80.91it/s]retrival evaluation:  79%|███████▊  | 617/784 [00:07<00:02, 81.43it/s]retrival evaluation:  80%|███████▉  | 626/784 [00:07<00:01, 81.18it/s]retrival evaluation:  81%|████████  | 635/784 [00:07<00:01, 80.88it/s]retrival evaluation:  82%|████████▏ | 644/784 [00:07<00:01, 80.75it/s]retrival evaluation:  83%|████████▎ | 653/784 [00:08<00:01, 81.05it/s]retrival evaluation:  84%|████████▍ | 662/784 [00:08<00:01, 81.22it/s]retrival evaluation:  86%|████████▌ | 671/784 [00:08<00:01, 81.18it/s]retrival evaluation:  87%|████████▋ | 680/784 [00:08<00:01, 80.99it/s]retrival evaluation:  88%|████████▊ | 689/784 [00:08<00:01, 81.20it/s]retrival evaluation:  89%|████████▉ | 698/784 [00:08<00:01, 81.28it/s]retrival evaluation:  90%|█████████ | 707/784 [00:08<00:00, 80.87it/s]retrival evaluation:  91%|█████████▏| 716/784 [00:08<00:00, 80.85it/s]retrival evaluation:  92%|█████████▏| 725/784 [00:08<00:00, 81.13it/s]retrival evaluation:  94%|█████████▎| 734/784 [00:09<00:00, 81.06it/s]retrival evaluation:  95%|█████████▍| 743/784 [00:09<00:00, 81.25it/s]retrival evaluation:  96%|█████████▌| 752/784 [00:09<00:00, 81.38it/s]retrival evaluation:  97%|█████████▋| 761/784 [00:09<00:00, 81.15it/s]retrival evaluation:  98%|█████████▊| 770/784 [00:09<00:00, 81.09it/s]retrival evaluation:  99%|█████████▉| 779/784 [00:09<00:00, 81.15it/s]retrival evaluation: 100%|██████████| 784/784 [00:09<00:00, 80.90it/s]

pk3=0, pk2=0,pk1=0 best_f1 = 0.048, bets_f2=0.089, MAP=0.079, MRR=0, AP=0.02, exe_time=96.94206309318542

INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:__main__:model loaded
INFO:EMSE.BERTDataReader:Creating examples from dataset file at /afs/crc.nd.edu/user/j/jlin6/data/EMSE/san/test
update feature:   0%|          | 0/3 [00:00<?, ?it/s]update feature: 100%|██████████| 3/3 [00:00<00:00, 567.90it/s]
update feature:   0%|          | 0/3 [00:00<?, ?it/s]update feature: 100%|██████████| 3/3 [00:00<00:00, 575.09it/s]
update embedding:   0%|          | 0/3 [00:00<?, ?it/s]update embedding:  33%|███▎      | 1/3 [00:00<00:01,  1.24it/s]update embedding:  67%|██████▋   | 2/3 [00:01<00:00,  1.24it/s]update embedding: 100%|██████████| 3/3 [00:02<00:00,  1.21it/s]update embedding: 100%|██████████| 3/3 [00:02<00:00,  1.20it/s]
update embedding:   0%|          | 0/3 [00:00<?, ?it/s]update embedding:  33%|███▎      | 1/3 [00:00<00:01,  1.32it/s]update embedding:  67%|██████▋   | 2/3 [00:01<00:00,  1.33it/s]update embedding: 100%|██████████| 3/3 [00:02<00:00,  1.34it/s]update embedding: 100%|██████████| 3/3 [00:02<00:00,  1.34it/s]
retrival evaluation:   0%|          | 0/3 [00:00<?, ?it/s]retrival evaluation: 100%|██████████| 3/3 [00:00<00:00, 93.32it/s]

pk3=0, pk2=0,pk1=0 best_f1 = 0.5, bets_f2=0.714, MAP=0.556, MRR=0, AP=0.361, exe_time=4.835742950439453

INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:__main__:model loaded
INFO:EMSE.BERTDataReader:Creating examples from dataset file at /afs/crc.nd.edu/user/j/jlin6/data/EMSE/weui/test
update feature:   0%|          | 0/16 [00:00<?, ?it/s]update feature:   6%|▋         | 1/16 [00:00<00:01,  7.76it/s]update feature:  12%|█▎        | 2/16 [00:00<00:03,  4.11it/s]update feature:  19%|█▉        | 3/16 [00:01<00:03,  3.38it/s]update feature:  38%|███▊      | 6/16 [00:01<00:02,  3.93it/s]update feature:  44%|████▍     | 7/16 [00:01<00:02,  3.72it/s]update feature:  50%|█████     | 8/16 [00:02<00:02,  3.30it/s]update feature:  62%|██████▎   | 10/16 [00:02<00:01,  4.26it/s]update feature:  75%|███████▌  | 12/16 [00:02<00:00,  4.58it/s]update feature:  81%|████████▏ | 13/16 [00:03<00:00,  4.03it/s]update feature:  94%|█████████▍| 15/16 [00:03<00:00,  4.15it/s]update feature: 100%|██████████| 16/16 [00:04<00:00,  1.86it/s]update feature: 100%|██████████| 16/16 [00:04<00:00,  3.39it/s]
update feature:   0%|          | 0/16 [00:00<?, ?it/s]update feature: 100%|██████████| 16/16 [00:00<00:00, 1181.60it/s]
update embedding:   0%|          | 0/16 [00:00<?, ?it/s]update embedding:   6%|▋         | 1/16 [00:00<00:12,  1.23it/s]update embedding:  12%|█▎        | 2/16 [00:01<00:11,  1.25it/s]update embedding:  19%|█▉        | 3/16 [00:02<00:10,  1.28it/s]update embedding:  25%|██▌       | 4/16 [00:03<00:09,  1.30it/s]update embedding:  31%|███▏      | 5/16 [00:03<00:08,  1.31it/s]update embedding:  38%|███▊      | 6/16 [00:04<00:07,  1.32it/s]update embedding:  44%|████▍     | 7/16 [00:05<00:06,  1.32it/s]update embedding:  50%|█████     | 8/16 [00:06<00:06,  1.32it/s]update embedding:  56%|█████▋    | 9/16 [00:06<00:05,  1.34it/s]update embedding:  62%|██████▎   | 10/16 [00:07<00:04,  1.31it/s]update embedding:  69%|██████▉   | 11/16 [00:08<00:03,  1.33it/s]update embedding:  75%|███████▌  | 12/16 [00:09<00:02,  1.34it/s]update embedding:  81%|████████▏ | 13/16 [00:09<00:02,  1.34it/s]update embedding:  88%|████████▊ | 14/16 [00:10<00:01,  1.35it/s]update embedding:  94%|█████████▍| 15/16 [00:11<00:00,  1.35it/s]update embedding: 100%|██████████| 16/16 [00:12<00:00,  1.36it/s]update embedding: 100%|██████████| 16/16 [00:12<00:00,  1.33it/s]
update embedding:   0%|          | 0/16 [00:00<?, ?it/s]update embedding:   6%|▋         | 1/16 [00:00<00:10,  1.37it/s]update embedding:  12%|█▎        | 2/16 [00:01<00:10,  1.37it/s]update embedding:  19%|█▉        | 3/16 [00:02<00:09,  1.37it/s]update embedding:  25%|██▌       | 4/16 [00:02<00:08,  1.37it/s]update embedding:  31%|███▏      | 5/16 [00:03<00:08,  1.36it/s]update embedding:  38%|███▊      | 6/16 [00:04<00:07,  1.37it/s]update embedding:  44%|████▍     | 7/16 [00:05<00:06,  1.36it/s]update embedding:  50%|█████     | 8/16 [00:05<00:05,  1.36it/s]update embedding:  56%|█████▋    | 9/16 [00:06<00:05,  1.36it/s]update embedding:  62%|██████▎   | 10/16 [00:07<00:04,  1.36it/s]update embedding:  69%|██████▉   | 11/16 [00:08<00:03,  1.36it/s]update embedding:  75%|███████▌  | 12/16 [00:08<00:02,  1.35it/s]update embedding:  81%|████████▏ | 13/16 [00:09<00:02,  1.36it/s]update embedding:  88%|████████▊ | 14/16 [00:10<00:01,  1.32it/s]update embedding:  94%|█████████▍| 15/16 [00:11<00:00,  1.30it/s]update embedding: 100%|██████████| 16/16 [00:12<00:00,  1.26it/s]update embedding: 100%|██████████| 16/16 [00:12<00:00,  1.33it/s]
retrival evaluation:   0%|          | 0/64 [00:00<?, ?it/s]retrival evaluation:   9%|▉         | 6/64 [00:00<00:00, 59.95it/s]retrival evaluation:  22%|██▏       | 14/64 [00:00<00:00, 62.85it/s]retrival evaluation:  34%|███▍      | 22/64 [00:00<00:00, 65.01it/s]retrival evaluation:  47%|████▋     | 30/64 [00:00<00:00, 66.25it/s]retrival evaluation:  59%|█████▉    | 38/64 [00:00<00:00, 67.62it/s]retrival evaluation:  70%|███████   | 45/64 [00:00<00:00, 68.20it/s]retrival evaluation:  81%|████████▏ | 52/64 [00:00<00:00, 65.74it/s]retrival evaluation:  95%|█████████▌| 61/64 [00:00<00:00, 69.45it/s]retrival evaluation: 100%|██████████| 64/64 [00:00<00:00, 69.52it/s]

pk3=0, pk2=0,pk1=0 best_f1 = 0.129, bets_f2=0.27, MAP=0.244, MRR=0, AP=0.083, exe_time=30.030826568603516

INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:__main__:model loaded
INFO:EMSE.BERTDataReader:Creating examples from dataset file at /afs/crc.nd.edu/user/j/jlin6/data/EMSE/xLua/test
update feature:   0%|          | 0/19 [00:00<?, ?it/s]update feature: 100%|██████████| 19/19 [00:00<00:00, 349.00it/s]
update feature:   0%|          | 0/19 [00:00<?, ?it/s]update feature: 100%|██████████| 19/19 [00:00<00:00, 1654.15it/s]
update embedding:   0%|          | 0/19 [00:00<?, ?it/s]update embedding:   5%|▌         | 1/19 [00:00<00:14,  1.24it/s]update embedding:  11%|█         | 2/19 [00:01<00:13,  1.27it/s]update embedding:  16%|█▌        | 3/19 [00:02<00:12,  1.28it/s]update embedding:  21%|██        | 4/19 [00:03<00:11,  1.29it/s]update embedding:  26%|██▋       | 5/19 [00:03<00:10,  1.31it/s]update embedding:  32%|███▏      | 6/19 [00:04<00:09,  1.32it/s]update embedding:  37%|███▋      | 7/19 [00:05<00:09,  1.32it/s]update embedding:  42%|████▏     | 8/19 [00:06<00:08,  1.32it/s]update embedding:  47%|████▋     | 9/19 [00:06<00:07,  1.32it/s]update embedding:  53%|█████▎    | 10/19 [00:07<00:06,  1.33it/s]update embedding:  58%|█████▊    | 11/19 [00:08<00:05,  1.34it/s]update embedding:  63%|██████▎   | 12/19 [00:09<00:05,  1.34it/s]update embedding:  68%|██████▊   | 13/19 [00:09<00:04,  1.34it/s]update embedding:  74%|███████▎  | 14/19 [00:10<00:03,  1.33it/s]update embedding:  79%|███████▉  | 15/19 [00:11<00:02,  1.34it/s]update embedding:  84%|████████▍ | 16/19 [00:12<00:02,  1.34it/s]update embedding:  89%|████████▉ | 17/19 [00:12<00:01,  1.34it/s]update embedding:  95%|█████████▍| 18/19 [00:13<00:00,  1.33it/s]update embedding: 100%|██████████| 19/19 [00:14<00:00,  1.33it/s]update embedding: 100%|██████████| 19/19 [00:14<00:00,  1.33it/s]
update embedding:   0%|          | 0/19 [00:00<?, ?it/s]update embedding:   5%|▌         | 1/19 [00:00<00:13,  1.35it/s]update embedding:  11%|█         | 2/19 [00:01<00:12,  1.35it/s]update embedding:  16%|█▌        | 3/19 [00:02<00:11,  1.35it/s]update embedding:  21%|██        | 4/19 [00:02<00:11,  1.35it/s]update embedding:  26%|██▋       | 5/19 [00:03<00:10,  1.35it/s]update embedding:  32%|███▏      | 6/19 [00:04<00:09,  1.35it/s]update embedding:  37%|███▋      | 7/19 [00:05<00:08,  1.36it/s]update embedding:  42%|████▏     | 8/19 [00:05<00:08,  1.34it/s]update embedding:  47%|████▋     | 9/19 [00:06<00:07,  1.32it/s]update embedding:  53%|█████▎    | 10/19 [00:07<00:06,  1.33it/s]update embedding:  58%|█████▊    | 11/19 [00:08<00:06,  1.33it/s]update embedding:  63%|██████▎   | 12/19 [00:08<00:05,  1.33it/s]update embedding:  68%|██████▊   | 13/19 [00:09<00:04,  1.33it/s]update embedding:  74%|███████▎  | 14/19 [00:10<00:03,  1.33it/s]update embedding:  79%|███████▉  | 15/19 [00:11<00:02,  1.33it/s]update embedding:  84%|████████▍ | 16/19 [00:11<00:02,  1.33it/s]update embedding:  89%|████████▉ | 17/19 [00:12<00:01,  1.33it/s]update embedding:  95%|█████████▍| 18/19 [00:13<00:00,  1.34it/s]update embedding: 100%|██████████| 19/19 [00:14<00:00,  1.33it/s]update embedding: 100%|██████████| 19/19 [00:14<00:00,  1.34it/s]
retrival evaluation:   0%|          | 0/91 [00:00<?, ?it/s]retrival evaluation:   9%|▉         | 8/91 [00:00<00:01, 72.34it/s]retrival evaluation:  19%|█▊        | 17/91 [00:00<00:00, 74.89it/s]retrival evaluation:  27%|██▋       | 25/91 [00:00<00:00, 76.18it/s]retrival evaluation:  37%|███▋      | 34/91 [00:00<00:00, 77.46it/s]retrival evaluation:  47%|████▋     | 43/91 [00:00<00:00, 78.55it/s]retrival evaluation:  57%|█████▋    | 52/91 [00:00<00:00, 79.57it/s]retrival evaluation:  67%|██████▋   | 61/91 [00:00<00:00, 80.24it/s]retrival evaluation:  77%|███████▋  | 70/91 [00:00<00:00, 80.46it/s]retrival evaluation:  87%|████████▋ | 79/91 [00:00<00:00, 80.68it/s]retrival evaluation:  97%|█████████▋| 88/91 [00:01<00:00, 81.07it/s]retrival evaluation: 100%|██████████| 91/91 [00:01<00:00, 80.92it/s]

pk3=0, pk2=0,pk1=0 best_f1 = 0.133, bets_f2=0.241, MAP=0.185, MRR=0, AP=0.063, exe_time=29.790462493896484

