Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Loading pytorch/1.1.0
  Loading requirement: cuda/10.0 cudnn/7.4
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:__main__:model loaded
INFO:EMSE.BERTDataReader:Creating examples from dataset file at /afs/crc.nd.edu/user/j/jlin6/data/EMSE/arthas/test
update feature:   0%|          | 0/17 [00:00<?, ?it/s]update feature: 100%|██████████| 17/17 [00:00<00:00, 363.62it/s]
update feature:   0%|          | 0/17 [00:00<?, ?it/s]update feature: 100%|██████████| 17/17 [00:00<00:00, 361.40it/s]
update embedding:   0%|          | 0/17 [00:00<?, ?it/s]update embedding:   6%|▌         | 1/17 [00:00<00:14,  1.09it/s]update embedding:  12%|█▏        | 2/17 [00:01<00:13,  1.14it/s]update embedding:  18%|█▊        | 3/17 [00:02<00:11,  1.18it/s]update embedding:  24%|██▎       | 4/17 [00:03<00:10,  1.21it/s]update embedding:  29%|██▉       | 5/17 [00:04<00:09,  1.23it/s]update embedding:  35%|███▌      | 6/17 [00:04<00:08,  1.23it/s]update embedding:  41%|████      | 7/17 [00:05<00:08,  1.24it/s]update embedding:  47%|████▋     | 8/17 [00:06<00:07,  1.25it/s]update embedding:  53%|█████▎    | 9/17 [00:07<00:06,  1.25it/s]update embedding:  59%|█████▉    | 10/17 [00:08<00:05,  1.26it/s]update embedding:  65%|██████▍   | 11/17 [00:08<00:04,  1.26it/s]update embedding:  71%|███████   | 12/17 [00:09<00:03,  1.27it/s]update embedding:  76%|███████▋  | 13/17 [00:10<00:03,  1.27it/s]update embedding:  82%|████████▏ | 14/17 [00:11<00:02,  1.27it/s]update embedding:  88%|████████▊ | 15/17 [00:11<00:01,  1.27it/s]update embedding:  94%|█████████▍| 16/17 [00:12<00:00,  1.27it/s]update embedding: 100%|██████████| 17/17 [00:13<00:00,  1.27it/s]update embedding: 100%|██████████| 17/17 [00:13<00:00,  1.26it/s]
update embedding:   0%|          | 0/17 [00:00<?, ?it/s]update embedding:   6%|▌         | 1/17 [00:00<00:12,  1.26it/s]update embedding:  12%|█▏        | 2/17 [00:01<00:11,  1.27it/s]update embedding:  18%|█▊        | 3/17 [00:02<00:11,  1.27it/s]update embedding:  24%|██▎       | 4/17 [00:03<00:10,  1.27it/s]update embedding:  29%|██▉       | 5/17 [00:03<00:09,  1.27it/s]update embedding:  35%|███▌      | 6/17 [00:04<00:08,  1.27it/s]update embedding:  41%|████      | 7/17 [00:05<00:07,  1.27it/s]update embedding:  47%|████▋     | 8/17 [00:06<00:07,  1.27it/s]update embedding:  53%|█████▎    | 9/17 [00:07<00:06,  1.28it/s]update embedding:  59%|█████▉    | 10/17 [00:07<00:05,  1.28it/s]update embedding:  65%|██████▍   | 11/17 [00:08<00:04,  1.27it/s]update embedding:  71%|███████   | 12/17 [00:09<00:03,  1.27it/s]update embedding:  76%|███████▋  | 13/17 [00:10<00:03,  1.27it/s]update embedding:  82%|████████▏ | 14/17 [00:11<00:02,  1.27it/s]update embedding:  88%|████████▊ | 15/17 [00:11<00:01,  1.26it/s]update embedding:  94%|█████████▍| 16/17 [00:12<00:00,  1.26it/s]update embedding: 100%|██████████| 17/17 [00:13<00:00,  1.26it/s]update embedding: 100%|██████████| 17/17 [00:13<00:00,  1.27it/s]
retrival evaluation:   0%|          | 0/73 [00:00<?, ?it/s]retrival evaluation:  10%|▉         | 7/73 [00:00<00:01, 63.23it/s]retrival evaluation:  21%|██        | 15/73 [00:00<00:00, 66.73it/s]retrival evaluation:  32%|███▏      | 23/73 [00:00<00:00, 68.83it/s]retrival evaluation:  42%|████▏     | 31/73 [00:00<00:00, 71.11it/s]retrival evaluation:  53%|█████▎    | 39/73 [00:00<00:00, 72.78it/s]retrival evaluation:  64%|██████▍   | 47/73 [00:00<00:00, 73.90it/s]retrival evaluation:  75%|███████▌  | 55/73 [00:00<00:00, 75.24it/s]retrival evaluation:  86%|████████▋ | 63/73 [00:00<00:00, 75.86it/s]retrival evaluation:  97%|█████████▋| 71/73 [00:00<00:00, 76.39it/s]retrival evaluation: 100%|██████████| 73/73 [00:00<00:00, 75.99it/s]

pk3=0, pk2=0,pk1=0 best_f1 = 0.452, bets_f2=0.517, MAP=0.671, MRR=0, AP=0.413, exe_time=28.022704601287842

INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:__main__:model loaded
INFO:EMSE.BERTDataReader:Creating examples from dataset file at /afs/crc.nd.edu/user/j/jlin6/data/EMSE/bk-cmdb/test
update feature:   0%|          | 0/119 [00:00<?, ?it/s]update feature:  15%|█▌        | 18/119 [00:00<00:00, 154.95it/s]update feature:  34%|███▎      | 40/119 [00:00<00:00, 170.01it/s]update feature:  67%|██████▋   | 80/119 [00:00<00:00, 204.16it/s]update feature: 100%|██████████| 119/119 [00:00<00:00, 289.83it/s]
update feature:   0%|          | 0/119 [00:00<?, ?it/s]update feature: 100%|██████████| 119/119 [00:00<00:00, 1837.49it/s]
update embedding:   0%|          | 0/119 [00:00<?, ?it/s]update embedding:   1%|          | 1/119 [00:00<01:39,  1.18it/s]update embedding:   2%|▏         | 2/119 [00:01<01:37,  1.20it/s]update embedding:   3%|▎         | 3/119 [00:02<01:34,  1.22it/s]update embedding:   3%|▎         | 4/119 [00:03<01:32,  1.24it/s]update embedding:   4%|▍         | 5/119 [00:03<01:31,  1.25it/s]update embedding:   5%|▌         | 6/119 [00:04<01:30,  1.25it/s]update embedding:   6%|▌         | 7/119 [00:05<01:28,  1.26it/s]update embedding:   7%|▋         | 8/119 [00:06<01:27,  1.26it/s]update embedding:   8%|▊         | 9/119 [00:07<01:27,  1.26it/s]update embedding:   8%|▊         | 10/119 [00:07<01:26,  1.26it/s]update embedding:   9%|▉         | 11/119 [00:08<01:25,  1.27it/s]update embedding:  10%|█         | 12/119 [00:09<01:24,  1.27it/s]update embedding:  11%|█         | 13/119 [00:10<01:23,  1.27it/s]update embedding:  12%|█▏        | 14/119 [00:11<01:22,  1.27it/s]update embedding:  13%|█▎        | 15/119 [00:11<01:22,  1.26it/s]update embedding:  13%|█▎        | 16/119 [00:12<01:21,  1.26it/s]update embedding:  14%|█▍        | 17/119 [00:13<01:20,  1.26it/s]update embedding:  15%|█▌        | 18/119 [00:14<01:19,  1.27it/s]update embedding:  16%|█▌        | 19/119 [00:15<01:18,  1.27it/s]update embedding:  17%|█▋        | 20/119 [00:15<01:18,  1.26it/s]update embedding:  18%|█▊        | 21/119 [00:16<01:15,  1.29it/s]update embedding:  18%|█▊        | 22/119 [00:17<01:13,  1.32it/s]update embedding:  19%|█▉        | 23/119 [00:18<01:13,  1.30it/s]update embedding:  20%|██        | 24/119 [00:18<01:13,  1.30it/s]update embedding:  21%|██        | 25/119 [00:19<01:12,  1.29it/s]update embedding:  22%|██▏       | 26/119 [00:20<01:13,  1.27it/s]update embedding:  23%|██▎       | 27/119 [00:21<01:12,  1.27it/s]update embedding:  24%|██▎       | 28/119 [00:22<01:12,  1.26it/s]update embedding:  24%|██▍       | 29/119 [00:22<01:11,  1.25it/s]update embedding:  25%|██▌       | 30/119 [00:23<01:11,  1.25it/s]update embedding:  26%|██▌       | 31/119 [00:24<01:10,  1.24it/s]update embedding:  27%|██▋       | 32/119 [00:25<01:10,  1.24it/s]update embedding:  28%|██▊       | 33/119 [00:26<01:09,  1.24it/s]update embedding:  29%|██▊       | 34/119 [00:26<01:08,  1.24it/s]update embedding:  29%|██▉       | 35/119 [00:27<01:07,  1.24it/s]update embedding:  30%|███       | 36/119 [00:28<01:07,  1.23it/s]update embedding:  31%|███       | 37/119 [00:29<01:06,  1.23it/s]update embedding:  32%|███▏      | 38/119 [00:30<01:05,  1.23it/s]update embedding:  33%|███▎      | 39/119 [00:30<01:05,  1.23it/s]update embedding:  34%|███▎      | 40/119 [00:31<01:03,  1.24it/s]update embedding:  34%|███▍      | 41/119 [00:32<01:01,  1.27it/s]update embedding:  35%|███▌      | 42/119 [00:33<01:00,  1.27it/s]update embedding:  36%|███▌      | 43/119 [00:34<00:59,  1.27it/s]update embedding:  37%|███▋      | 44/119 [00:34<00:58,  1.28it/s]update embedding:  38%|███▊      | 45/119 [00:35<00:58,  1.28it/s]update embedding:  39%|███▊      | 46/119 [00:36<00:57,  1.27it/s]update embedding:  39%|███▉      | 47/119 [00:37<00:56,  1.27it/s]update embedding:  40%|████      | 48/119 [00:38<00:56,  1.27it/s]update embedding:  41%|████      | 49/119 [00:38<00:55,  1.27it/s]update embedding:  42%|████▏     | 50/119 [00:39<00:54,  1.27it/s]update embedding:  43%|████▎     | 51/119 [00:40<00:53,  1.27it/s]update embedding:  44%|████▎     | 52/119 [00:41<00:52,  1.27it/s]update embedding:  45%|████▍     | 53/119 [00:41<00:52,  1.27it/s]update embedding:  45%|████▌     | 54/119 [00:42<00:51,  1.27it/s]update embedding:  46%|████▌     | 55/119 [00:43<00:50,  1.27it/s]update embedding:  47%|████▋     | 56/119 [00:44<00:49,  1.28it/s]update embedding:  48%|████▊     | 57/119 [00:45<00:48,  1.28it/s]update embedding:  49%|████▊     | 58/119 [00:45<00:47,  1.28it/s]update embedding:  50%|████▉     | 59/119 [00:46<00:46,  1.28it/s]update embedding:  50%|█████     | 60/119 [00:47<00:46,  1.28it/s]update embedding:  51%|█████▏    | 61/119 [00:48<00:45,  1.28it/s]update embedding:  52%|█████▏    | 62/119 [00:49<00:45,  1.25it/s]update embedding:  53%|█████▎    | 63/119 [00:49<00:45,  1.24it/s]update embedding:  54%|█████▍    | 64/119 [00:50<00:43,  1.25it/s]update embedding:  55%|█████▍    | 65/119 [00:51<00:42,  1.26it/s]update embedding:  55%|█████▌    | 66/119 [00:52<00:41,  1.27it/s]update embedding:  56%|█████▋    | 67/119 [00:53<00:41,  1.24it/s]update embedding:  57%|█████▋    | 68/119 [00:53<00:40,  1.25it/s]update embedding:  58%|█████▊    | 69/119 [00:54<00:39,  1.26it/s]update embedding:  59%|█████▉    | 70/119 [00:55<00:38,  1.27it/s]update embedding:  60%|█████▉    | 71/119 [00:56<00:37,  1.27it/s]update embedding:  61%|██████    | 72/119 [00:56<00:37,  1.26it/s]update embedding:  61%|██████▏   | 73/119 [00:57<00:37,  1.23it/s]update embedding:  62%|██████▏   | 74/119 [00:58<00:36,  1.22it/s]update embedding:  63%|██████▎   | 75/119 [00:59<00:36,  1.21it/s]update embedding:  64%|██████▍   | 76/119 [01:00<00:35,  1.21it/s]update embedding:  65%|██████▍   | 77/119 [01:01<00:34,  1.22it/s]update embedding:  66%|██████▌   | 78/119 [01:01<00:33,  1.23it/s]update embedding:  66%|██████▋   | 79/119 [01:02<00:32,  1.23it/s]update embedding:  67%|██████▋   | 80/119 [01:03<00:31,  1.22it/s]update embedding:  68%|██████▊   | 81/119 [01:04<00:30,  1.24it/s]update embedding:  69%|██████▉   | 82/119 [01:05<00:29,  1.25it/s]update embedding:  70%|██████▉   | 83/119 [01:05<00:28,  1.25it/s]update embedding:  71%|███████   | 84/119 [01:06<00:28,  1.25it/s]update embedding:  71%|███████▏  | 85/119 [01:07<00:27,  1.25it/s]update embedding:  72%|███████▏  | 86/119 [01:08<00:26,  1.26it/s]update embedding:  73%|███████▎  | 87/119 [01:09<00:25,  1.26it/s]update embedding:  74%|███████▍  | 88/119 [01:09<00:24,  1.27it/s]update embedding:  75%|███████▍  | 89/119 [01:10<00:23,  1.26it/s]update embedding:  76%|███████▌  | 90/119 [01:11<00:22,  1.26it/s]update embedding:  76%|███████▋  | 91/119 [01:12<00:22,  1.26it/s]update embedding:  77%|███████▋  | 92/119 [01:13<00:21,  1.26it/s]update embedding:  78%|███████▊  | 93/119 [01:13<00:20,  1.27it/s]update embedding:  79%|███████▉  | 94/119 [01:14<00:19,  1.27it/s]update embedding:  80%|███████▉  | 95/119 [01:15<00:18,  1.28it/s]update embedding:  81%|████████  | 96/119 [01:16<00:18,  1.28it/s]update embedding:  82%|████████▏ | 97/119 [01:17<00:17,  1.28it/s]update embedding:  82%|████████▏ | 98/119 [01:17<00:16,  1.28it/s]update embedding:  83%|████████▎ | 99/119 [01:18<00:15,  1.27it/s]update embedding:  84%|████████▍ | 100/119 [01:19<00:14,  1.28it/s]update embedding:  85%|████████▍ | 101/119 [01:20<00:14,  1.27it/s]update embedding:  86%|████████▌ | 102/119 [01:20<00:13,  1.27it/s]update embedding:  87%|████████▋ | 103/119 [01:21<00:12,  1.26it/s]update embedding:  87%|████████▋ | 104/119 [01:22<00:11,  1.27it/s]update embedding:  88%|████████▊ | 105/119 [01:23<00:11,  1.27it/s]update embedding:  89%|████████▉ | 106/119 [01:24<00:10,  1.27it/s]update embedding:  90%|████████▉ | 107/119 [01:24<00:09,  1.27it/s]update embedding:  91%|█████████ | 108/119 [01:25<00:08,  1.27it/s]update embedding:  92%|█████████▏| 109/119 [01:26<00:07,  1.27it/s]update embedding:  92%|█████████▏| 110/119 [01:27<00:07,  1.27it/s]update embedding:  93%|█████████▎| 111/119 [01:28<00:06,  1.27it/s]update embedding:  94%|█████████▍| 112/119 [01:28<00:05,  1.27it/s]update embedding:  95%|█████████▍| 113/119 [01:29<00:04,  1.27it/s]update embedding:  96%|█████████▌| 114/119 [01:30<00:03,  1.27it/s]update embedding:  97%|█████████▋| 115/119 [01:31<00:03,  1.28it/s]update embedding:  97%|█████████▋| 116/119 [01:31<00:02,  1.28it/s]update embedding:  98%|█████████▊| 117/119 [01:32<00:01,  1.27it/s]update embedding:  99%|█████████▉| 118/119 [01:33<00:00,  1.27it/s]update embedding: 100%|██████████| 119/119 [01:34<00:00,  1.27it/s]update embedding: 100%|██████████| 119/119 [01:34<00:00,  1.26it/s]
update embedding:   0%|          | 0/119 [00:00<?, ?it/s]update embedding:   1%|          | 1/119 [00:00<01:31,  1.30it/s]update embedding:   2%|▏         | 2/119 [00:01<01:31,  1.28it/s]update embedding:   3%|▎         | 3/119 [00:02<01:30,  1.28it/s]update embedding:   3%|▎         | 4/119 [00:03<01:29,  1.29it/s]update embedding:   4%|▍         | 5/119 [00:03<01:28,  1.29it/s]update embedding:   5%|▌         | 6/119 [00:04<01:28,  1.28it/s]update embedding:   6%|▌         | 7/119 [00:05<01:27,  1.28it/s]update embedding:   7%|▋         | 8/119 [00:06<01:26,  1.28it/s]update embedding:   8%|▊         | 9/119 [00:07<01:25,  1.28it/s]update embedding:   8%|▊         | 10/119 [00:07<01:25,  1.28it/s]update embedding:   9%|▉         | 11/119 [00:08<01:24,  1.28it/s]update embedding:  10%|█         | 12/119 [00:09<01:23,  1.28it/s]update embedding:  11%|█         | 13/119 [00:10<01:22,  1.28it/s]update embedding:  12%|█▏        | 14/119 [00:10<01:21,  1.28it/s]update embedding:  13%|█▎        | 15/119 [00:11<01:20,  1.29it/s]update embedding:  13%|█▎        | 16/119 [00:12<01:20,  1.29it/s]update embedding:  14%|█▍        | 17/119 [00:13<01:19,  1.29it/s]update embedding:  15%|█▌        | 18/119 [00:14<01:19,  1.28it/s]update embedding:  16%|█▌        | 19/119 [00:14<01:18,  1.28it/s]update embedding:  17%|█▋        | 20/119 [00:15<01:17,  1.28it/s]update embedding:  18%|█▊        | 21/119 [00:16<01:16,  1.28it/s]update embedding:  18%|█▊        | 22/119 [00:17<01:15,  1.29it/s]update embedding:  19%|█▉        | 23/119 [00:17<01:15,  1.27it/s]update embedding:  20%|██        | 24/119 [00:18<01:14,  1.27it/s]update embedding:  21%|██        | 25/119 [00:19<01:13,  1.28it/s]update embedding:  22%|██▏       | 26/119 [00:20<01:12,  1.28it/s]update embedding:  23%|██▎       | 27/119 [00:21<01:11,  1.28it/s]update embedding:  24%|██▎       | 28/119 [00:21<01:10,  1.28it/s]update embedding:  24%|██▍       | 29/119 [00:22<01:10,  1.28it/s]update embedding:  25%|██▌       | 30/119 [00:23<01:09,  1.28it/s]update embedding:  26%|██▌       | 31/119 [00:24<01:08,  1.28it/s]update embedding:  27%|██▋       | 32/119 [00:25<01:08,  1.27it/s]update embedding:  28%|██▊       | 33/119 [00:25<01:07,  1.28it/s]update embedding:  29%|██▊       | 34/119 [00:26<01:06,  1.28it/s]update embedding:  29%|██▉       | 35/119 [00:27<01:06,  1.27it/s]update embedding:  30%|███       | 36/119 [00:28<01:05,  1.27it/s]update embedding:  31%|███       | 37/119 [00:28<01:04,  1.27it/s]update embedding:  32%|███▏      | 38/119 [00:29<01:03,  1.27it/s]update embedding:  33%|███▎      | 39/119 [00:30<01:02,  1.28it/s]update embedding:  34%|███▎      | 40/119 [00:31<01:01,  1.28it/s]update embedding:  34%|███▍      | 41/119 [00:32<01:00,  1.28it/s]update embedding:  35%|███▌      | 42/119 [00:32<01:00,  1.28it/s]update embedding:  36%|███▌      | 43/119 [00:33<00:59,  1.28it/s]update embedding:  37%|███▋      | 44/119 [00:34<00:58,  1.28it/s]update embedding:  38%|███▊      | 45/119 [00:35<00:57,  1.28it/s]update embedding:  39%|███▊      | 46/119 [00:35<00:57,  1.28it/s]update embedding:  39%|███▉      | 47/119 [00:36<00:56,  1.28it/s]update embedding:  40%|████      | 48/119 [00:37<00:55,  1.27it/s]update embedding:  41%|████      | 49/119 [00:38<00:54,  1.27it/s]update embedding:  42%|████▏     | 50/119 [00:39<00:54,  1.27it/s]update embedding:  43%|████▎     | 51/119 [00:39<00:53,  1.27it/s]update embedding:  44%|████▎     | 52/119 [00:40<00:52,  1.27it/s]update embedding:  45%|████▍     | 53/119 [00:41<00:52,  1.27it/s]update embedding:  45%|████▌     | 54/119 [00:42<00:51,  1.26it/s]update embedding:  46%|████▌     | 55/119 [00:43<00:50,  1.26it/s]update embedding:  47%|████▋     | 56/119 [00:43<00:49,  1.27it/s]update embedding:  48%|████▊     | 57/119 [00:44<00:48,  1.27it/s]update embedding:  49%|████▊     | 58/119 [00:45<00:47,  1.27it/s]update embedding:  50%|████▉     | 59/119 [00:46<00:47,  1.26it/s]update embedding:  50%|█████     | 60/119 [00:47<00:46,  1.27it/s]update embedding:  51%|█████▏    | 61/119 [00:47<00:45,  1.27it/s]update embedding:  52%|█████▏    | 62/119 [00:48<00:45,  1.25it/s]update embedding:  53%|█████▎    | 63/119 [00:49<00:44,  1.26it/s]update embedding:  54%|█████▍    | 64/119 [00:50<00:43,  1.27it/s]update embedding:  55%|█████▍    | 65/119 [00:50<00:42,  1.28it/s]update embedding:  55%|█████▌    | 66/119 [00:51<00:41,  1.28it/s]update embedding:  56%|█████▋    | 67/119 [00:52<00:40,  1.28it/s]update embedding:  57%|█████▋    | 68/119 [00:53<00:39,  1.28it/s]update embedding:  58%|█████▊    | 69/119 [00:54<00:38,  1.28it/s]update embedding:  59%|█████▉    | 70/119 [00:54<00:38,  1.29it/s]update embedding:  60%|█████▉    | 71/119 [00:55<00:37,  1.29it/s]update embedding:  61%|██████    | 72/119 [00:56<00:36,  1.29it/s]update embedding:  61%|██████▏   | 73/119 [00:57<00:35,  1.28it/s]update embedding:  62%|██████▏   | 74/119 [00:57<00:35,  1.28it/s]update embedding:  63%|██████▎   | 75/119 [00:58<00:34,  1.28it/s]update embedding:  64%|██████▍   | 76/119 [00:59<00:33,  1.28it/s]update embedding:  65%|██████▍   | 77/119 [01:00<00:32,  1.28it/s]update embedding:  66%|██████▌   | 78/119 [01:01<00:32,  1.28it/s]update embedding:  66%|██████▋   | 79/119 [01:01<00:31,  1.27it/s]update embedding:  67%|██████▋   | 80/119 [01:02<00:30,  1.27it/s]update embedding:  68%|██████▊   | 81/119 [01:03<00:30,  1.27it/s]update embedding:  69%|██████▉   | 82/119 [01:04<00:29,  1.27it/s]update embedding:  70%|██████▉   | 83/119 [01:05<00:28,  1.27it/s]update embedding:  71%|███████   | 84/119 [01:05<00:27,  1.27it/s]update embedding:  71%|███████▏  | 85/119 [01:06<00:26,  1.26it/s]update embedding:  72%|███████▏  | 86/119 [01:07<00:26,  1.27it/s]update embedding:  73%|███████▎  | 87/119 [01:08<00:25,  1.27it/s]update embedding:  74%|███████▍  | 88/119 [01:08<00:24,  1.28it/s]update embedding:  75%|███████▍  | 89/119 [01:09<00:23,  1.28it/s]update embedding:  76%|███████▌  | 90/119 [01:10<00:22,  1.28it/s]update embedding:  76%|███████▋  | 91/119 [01:11<00:22,  1.26it/s]update embedding:  77%|███████▋  | 92/119 [01:12<00:21,  1.26it/s]update embedding:  78%|███████▊  | 93/119 [01:12<00:20,  1.27it/s]update embedding:  79%|███████▉  | 94/119 [01:13<00:19,  1.27it/s]update embedding:  80%|███████▉  | 95/119 [01:14<00:18,  1.27it/s]update embedding:  81%|████████  | 96/119 [01:15<00:17,  1.28it/s]update embedding:  82%|████████▏ | 97/119 [01:16<00:17,  1.28it/s]update embedding:  82%|████████▏ | 98/119 [01:16<00:16,  1.27it/s]update embedding:  83%|████████▎ | 99/119 [01:17<00:15,  1.28it/s]update embedding:  84%|████████▍ | 100/119 [01:18<00:14,  1.28it/s]update embedding:  85%|████████▍ | 101/119 [01:19<00:14,  1.28it/s]update embedding:  86%|████████▌ | 102/119 [01:19<00:13,  1.28it/s]update embedding:  87%|████████▋ | 103/119 [01:20<00:12,  1.28it/s]update embedding:  87%|████████▋ | 104/119 [01:21<00:11,  1.28it/s]update embedding:  88%|████████▊ | 105/119 [01:22<00:10,  1.28it/s]update embedding:  89%|████████▉ | 106/119 [01:23<00:10,  1.28it/s]update embedding:  90%|████████▉ | 107/119 [01:23<00:09,  1.29it/s]update embedding:  91%|█████████ | 108/119 [01:24<00:08,  1.28it/s]update embedding:  92%|█████████▏| 109/119 [01:25<00:07,  1.28it/s]update embedding:  92%|█████████▏| 110/119 [01:26<00:07,  1.27it/s]update embedding:  93%|█████████▎| 111/119 [01:27<00:06,  1.27it/s]update embedding:  94%|█████████▍| 112/119 [01:27<00:05,  1.27it/s]update embedding:  95%|█████████▍| 113/119 [01:28<00:04,  1.27it/s]update embedding:  96%|█████████▌| 114/119 [01:29<00:03,  1.27it/s]update embedding:  97%|█████████▋| 115/119 [01:30<00:03,  1.26it/s]update embedding:  97%|█████████▋| 116/119 [01:30<00:02,  1.27it/s]update embedding:  98%|█████████▊| 117/119 [01:31<00:01,  1.27it/s]update embedding:  99%|█████████▉| 118/119 [01:32<00:00,  1.27it/s]update embedding: 100%|██████████| 119/119 [01:33<00:00,  1.27it/s]update embedding: 100%|██████████| 119/119 [01:33<00:00,  1.28it/s]
retrival evaluation:   0%|          | 0/3541 [00:00<?, ?it/s]retrival evaluation:   0%|          | 7/3541 [00:00<00:57, 61.01it/s]retrival evaluation:   0%|          | 14/3541 [00:00<00:56, 62.92it/s]retrival evaluation:   1%|          | 22/3541 [00:00<00:54, 64.96it/s]retrival evaluation:   1%|          | 30/3541 [00:00<00:51, 67.64it/s]retrival evaluation:   1%|          | 38/3541 [00:00<00:49, 70.63it/s]retrival evaluation:   1%|▏         | 46/3541 [00:00<00:47, 73.02it/s]retrival evaluation:   2%|▏         | 54/3541 [00:00<00:46, 74.87it/s]retrival evaluation:   2%|▏         | 62/3541 [00:00<00:45, 76.11it/s]retrival evaluation:   2%|▏         | 70/3541 [00:00<00:44, 77.21it/s]retrival evaluation:   2%|▏         | 78/3541 [00:01<00:44, 78.00it/s]retrival evaluation:   2%|▏         | 87/3541 [00:01<00:43, 78.67it/s]retrival evaluation:   3%|▎         | 95/3541 [00:01<00:43, 78.70it/s]retrival evaluation:   3%|▎         | 103/3541 [00:01<00:43, 78.67it/s]retrival evaluation:   3%|▎         | 111/3541 [00:01<00:43, 78.62it/s]retrival evaluation:   3%|▎         | 119/3541 [00:01<00:43, 78.65it/s]retrival evaluation:   4%|▎         | 127/3541 [00:01<00:43, 78.37it/s]retrival evaluation:   4%|▍         | 135/3541 [00:01<00:43, 78.39it/s]retrival evaluation:   4%|▍         | 144/3541 [00:01<00:43, 78.87it/s]retrival evaluation:   4%|▍         | 152/3541 [00:01<00:42, 79.07it/s]retrival evaluation:   5%|▍         | 160/3541 [00:02<00:42, 78.92it/s]retrival evaluation:   5%|▍         | 168/3541 [00:02<00:42, 78.80it/s]retrival evaluation:   5%|▍         | 176/3541 [00:02<00:42, 78.89it/s]retrival evaluation:   5%|▌         | 184/3541 [00:02<00:42, 79.12it/s]retrival evaluation:   5%|▌         | 193/3541 [00:02<00:42, 79.62it/s]retrival evaluation:   6%|▌         | 202/3541 [00:02<00:41, 79.83it/s]retrival evaluation:   6%|▌         | 210/3541 [00:02<00:41, 79.59it/s]retrival evaluation:   6%|▌         | 218/3541 [00:02<00:41, 79.48it/s]retrival evaluation:   6%|▋         | 227/3541 [00:02<00:41, 79.85it/s]retrival evaluation:   7%|▋         | 236/3541 [00:03<00:41, 79.97it/s]retrival evaluation:   7%|▋         | 244/3541 [00:03<00:41, 79.78it/s]retrival evaluation:   7%|▋         | 253/3541 [00:03<00:41, 79.97it/s]retrival evaluation:   7%|▋         | 261/3541 [00:03<00:41, 79.84it/s]retrival evaluation:   8%|▊         | 269/3541 [00:03<00:41, 79.50it/s]retrival evaluation:   8%|▊         | 277/3541 [00:03<00:41, 79.52it/s]retrival evaluation:   8%|▊         | 285/3541 [00:03<00:40, 79.65it/s]retrival evaluation:   8%|▊         | 293/3541 [00:03<00:40, 79.68it/s]retrival evaluation:   9%|▊         | 302/3541 [00:03<00:40, 79.75it/s]retrival evaluation:   9%|▉         | 311/3541 [00:03<00:40, 79.89it/s]retrival evaluation:   9%|▉         | 319/3541 [00:04<00:40, 79.74it/s]retrival evaluation:   9%|▉         | 327/3541 [00:04<00:40, 79.19it/s]retrival evaluation:   9%|▉         | 335/3541 [00:04<00:40, 78.80it/s]retrival evaluation:  10%|▉         | 344/3541 [00:04<00:40, 79.18it/s]retrival evaluation:  10%|▉         | 352/3541 [00:04<00:40, 79.30it/s]retrival evaluation:  10%|█         | 360/3541 [00:04<00:40, 79.20it/s]retrival evaluation:  10%|█         | 368/3541 [00:04<00:39, 79.44it/s]retrival evaluation:  11%|█         | 376/3541 [00:04<00:40, 79.11it/s]retrival evaluation:  11%|█         | 384/3541 [00:04<00:39, 79.33it/s]retrival evaluation:  11%|█         | 392/3541 [00:04<00:39, 79.10it/s]retrival evaluation:  11%|█▏        | 400/3541 [00:05<00:39, 79.20it/s]retrival evaluation:  12%|█▏        | 408/3541 [00:05<00:39, 79.42it/s]retrival evaluation:  12%|█▏        | 416/3541 [00:05<00:39, 79.56it/s]retrival evaluation:  12%|█▏        | 424/3541 [00:05<00:39, 79.40it/s]retrival evaluation:  12%|█▏        | 432/3541 [00:05<00:39, 79.01it/s]retrival evaluation:  12%|█▏        | 440/3541 [00:05<00:39, 78.81it/s]retrival evaluation:  13%|█▎        | 448/3541 [00:05<00:39, 78.57it/s]retrival evaluation:  13%|█▎        | 456/3541 [00:05<00:39, 78.26it/s]retrival evaluation:  13%|█▎        | 464/3541 [00:05<00:39, 78.41it/s]retrival evaluation:  13%|█▎        | 472/3541 [00:06<00:39, 78.42it/s]retrival evaluation:  14%|█▎        | 480/3541 [00:06<00:39, 78.19it/s]retrival evaluation:  14%|█▍        | 488/3541 [00:06<00:38, 78.41it/s]retrival evaluation:  14%|█▍        | 496/3541 [00:06<00:38, 78.58it/s]retrival evaluation:  14%|█▍        | 504/3541 [00:06<00:38, 78.82it/s]retrival evaluation:  14%|█▍        | 512/3541 [00:06<00:38, 78.82it/s]retrival evaluation:  15%|█▍        | 520/3541 [00:06<00:38, 78.66it/s]retrival evaluation:  15%|█▍        | 528/3541 [00:06<00:38, 78.61it/s]retrival evaluation:  15%|█▌        | 536/3541 [00:06<00:38, 78.64it/s]retrival evaluation:  15%|█▌        | 544/3541 [00:06<00:38, 78.43it/s]retrival evaluation:  16%|█▌        | 553/3541 [00:07<00:37, 78.93it/s]retrival evaluation:  16%|█▌        | 561/3541 [00:07<00:37, 79.20it/s]retrival evaluation:  16%|█▌        | 569/3541 [00:07<00:37, 78.99it/s]retrival evaluation:  16%|█▋        | 578/3541 [00:07<00:37, 79.38it/s]retrival evaluation:  17%|█▋        | 586/3541 [00:07<00:37, 79.55it/s]retrival evaluation:  17%|█▋        | 594/3541 [00:07<00:37, 79.53it/s]retrival evaluation:  17%|█▋        | 602/3541 [00:07<00:36, 79.49it/s]retrival evaluation:  17%|█▋        | 610/3541 [00:07<00:36, 79.42it/s]retrival evaluation:  17%|█▋        | 618/3541 [00:07<00:37, 78.50it/s]retrival evaluation:  18%|█▊        | 626/3541 [00:07<00:37, 78.56it/s]retrival evaluation:  18%|█▊        | 634/3541 [00:08<00:36, 78.65it/s]retrival evaluation:  18%|█▊        | 642/3541 [00:08<00:36, 79.02it/s]retrival evaluation:  18%|█▊        | 650/3541 [00:08<00:36, 79.09it/s]retrival evaluation:  19%|█▊        | 658/3541 [00:08<00:36, 79.17it/s]retrival evaluation:  19%|█▉        | 666/3541 [00:08<00:36, 79.38it/s]retrival evaluation:  19%|█▉        | 674/3541 [00:08<00:36, 79.36it/s]retrival evaluation:  19%|█▉        | 682/3541 [00:08<00:36, 78.99it/s]retrival evaluation:  19%|█▉        | 690/3541 [00:08<00:36, 78.66it/s]retrival evaluation:  20%|█▉        | 698/3541 [00:08<00:35, 79.04it/s]retrival evaluation:  20%|█▉        | 706/3541 [00:08<00:35, 78.91it/s]retrival evaluation:  20%|██        | 714/3541 [00:09<00:35, 79.16it/s]retrival evaluation:  20%|██        | 722/3541 [00:09<00:35, 79.13it/s]retrival evaluation:  21%|██        | 730/3541 [00:09<00:35, 79.14it/s]retrival evaluation:  21%|██        | 738/3541 [00:09<00:35, 79.23it/s]retrival evaluation:  21%|██        | 746/3541 [00:09<00:35, 79.45it/s]retrival evaluation:  21%|██▏       | 754/3541 [00:09<00:35, 79.37it/s]retrival evaluation:  22%|██▏       | 763/3541 [00:09<00:34, 79.50it/s]retrival evaluation:  22%|██▏       | 772/3541 [00:09<00:34, 79.85it/s]retrival evaluation:  22%|██▏       | 780/3541 [00:09<00:34, 79.52it/s]retrival evaluation:  22%|██▏       | 788/3541 [00:10<00:34, 79.51it/s]retrival evaluation:  23%|██▎       | 797/3541 [00:10<00:34, 79.79it/s]retrival evaluation:  23%|██▎       | 805/3541 [00:10<00:34, 79.79it/s]retrival evaluation:  23%|██▎       | 813/3541 [00:10<00:34, 79.80it/s]retrival evaluation:  23%|██▎       | 821/3541 [00:10<00:34, 79.39it/s]retrival evaluation:  23%|██▎       | 829/3541 [00:10<00:34, 79.47it/s]retrival evaluation:  24%|██▎       | 837/3541 [00:10<00:34, 79.43it/s]retrival evaluation:  24%|██▍       | 845/3541 [00:10<00:33, 79.50it/s]retrival evaluation:  24%|██▍       | 853/3541 [00:10<00:33, 79.58it/s]retrival evaluation:  24%|██▍       | 861/3541 [00:10<00:33, 79.47it/s]retrival evaluation:  25%|██▍       | 869/3541 [00:11<00:33, 79.39it/s]retrival evaluation:  25%|██▍       | 877/3541 [00:11<00:33, 79.41it/s]retrival evaluation:  25%|██▍       | 885/3541 [00:11<00:33, 79.37it/s]retrival evaluation:  25%|██▌       | 893/3541 [00:11<00:33, 79.02it/s]retrival evaluation:  25%|██▌       | 901/3541 [00:11<00:33, 79.13it/s]retrival evaluation:  26%|██▌       | 909/3541 [00:11<00:33, 79.32it/s]retrival evaluation:  26%|██▌       | 917/3541 [00:11<00:33, 79.29it/s]retrival evaluation:  26%|██▌       | 925/3541 [00:11<00:33, 79.23it/s]retrival evaluation:  26%|██▋       | 933/3541 [00:11<00:32, 79.10it/s]retrival evaluation:  27%|██▋       | 941/3541 [00:11<00:32, 79.17it/s]retrival evaluation:  27%|██▋       | 949/3541 [00:12<00:32, 79.11it/s]retrival evaluation:  27%|██▋       | 957/3541 [00:12<00:32, 79.25it/s]retrival evaluation:  27%|██▋       | 965/3541 [00:12<00:32, 79.47it/s]retrival evaluation:  27%|██▋       | 973/3541 [00:12<00:32, 79.48it/s]retrival evaluation:  28%|██▊       | 982/3541 [00:12<00:32, 79.52it/s]retrival evaluation:  28%|██▊       | 990/3541 [00:12<00:32, 79.63it/s]retrival evaluation:  28%|██▊       | 998/3541 [00:12<00:31, 79.59it/s]retrival evaluation:  28%|██▊       | 1006/3541 [00:12<00:31, 79.68it/s]retrival evaluation:  29%|██▊       | 1014/3541 [00:12<00:31, 79.13it/s]retrival evaluation:  29%|██▉       | 1022/3541 [00:12<00:32, 78.43it/s]retrival evaluation:  29%|██▉       | 1030/3541 [00:13<00:31, 78.65it/s]retrival evaluation:  29%|██▉       | 1038/3541 [00:13<00:31, 78.71it/s]retrival evaluation:  30%|██▉       | 1046/3541 [00:13<00:31, 78.61it/s]retrival evaluation:  30%|██▉       | 1055/3541 [00:13<00:31, 79.12it/s]retrival evaluation:  30%|███       | 1064/3541 [00:13<00:31, 79.50it/s]retrival evaluation:  30%|███       | 1072/3541 [00:13<00:31, 79.38it/s]retrival evaluation:  31%|███       | 1081/3541 [00:13<00:30, 79.80it/s]retrival evaluation:  31%|███       | 1089/3541 [00:13<00:30, 79.63it/s]retrival evaluation:  31%|███       | 1097/3541 [00:13<00:30, 79.68it/s]retrival evaluation:  31%|███       | 1105/3541 [00:14<00:30, 79.43it/s]retrival evaluation:  31%|███▏      | 1114/3541 [00:14<00:30, 79.71it/s]retrival evaluation:  32%|███▏      | 1123/3541 [00:14<00:30, 79.93it/s]retrival evaluation:  32%|███▏      | 1131/3541 [00:14<00:30, 79.57it/s]retrival evaluation:  32%|███▏      | 1139/3541 [00:14<00:30, 79.66it/s]retrival evaluation:  32%|███▏      | 1148/3541 [00:14<00:30, 79.61it/s]retrival evaluation:  33%|███▎      | 1156/3541 [00:14<00:29, 79.62it/s]retrival evaluation:  33%|███▎      | 1164/3541 [00:14<00:30, 79.14it/s]retrival evaluation:  33%|███▎      | 1172/3541 [00:14<00:29, 79.34it/s]retrival evaluation:  33%|███▎      | 1180/3541 [00:14<00:29, 79.31it/s]retrival evaluation:  34%|███▎      | 1188/3541 [00:15<00:29, 79.46it/s]retrival evaluation:  34%|███▍      | 1196/3541 [00:15<00:29, 79.43it/s]retrival evaluation:  34%|███▍      | 1204/3541 [00:15<00:29, 79.55it/s]retrival evaluation:  34%|███▍      | 1212/3541 [00:15<00:29, 79.29it/s]retrival evaluation:  34%|███▍      | 1220/3541 [00:15<00:29, 79.04it/s]retrival evaluation:  35%|███▍      | 1228/3541 [00:15<00:29, 78.76it/s]retrival evaluation:  35%|███▍      | 1236/3541 [00:15<00:29, 79.08it/s]retrival evaluation:  35%|███▌      | 1244/3541 [00:15<00:29, 79.14it/s]retrival evaluation:  35%|███▌      | 1252/3541 [00:15<00:29, 78.79it/s]retrival evaluation:  36%|███▌      | 1261/3541 [00:15<00:28, 79.40it/s]retrival evaluation:  36%|███▌      | 1270/3541 [00:16<00:28, 79.71it/s]retrival evaluation:  36%|███▌      | 1279/3541 [00:16<00:28, 80.00it/s]retrival evaluation:  36%|███▋      | 1288/3541 [00:16<00:28, 80.02it/s]retrival evaluation:  37%|███▋      | 1297/3541 [00:16<00:28, 79.79it/s]retrival evaluation:  37%|███▋      | 1306/3541 [00:16<00:27, 80.03it/s]retrival evaluation:  37%|███▋      | 1315/3541 [00:16<00:27, 79.77it/s]retrival evaluation:  37%|███▋      | 1323/3541 [00:16<00:27, 79.67it/s]retrival evaluation:  38%|███▊      | 1331/3541 [00:16<00:27, 79.39it/s]retrival evaluation:  38%|███▊      | 1339/3541 [00:16<00:27, 79.31it/s]retrival evaluation:  38%|███▊      | 1348/3541 [00:17<00:27, 79.56it/s]retrival evaluation:  38%|███▊      | 1356/3541 [00:17<00:27, 79.27it/s]retrival evaluation:  39%|███▊      | 1364/3541 [00:17<00:27, 79.05it/s]retrival evaluation:  39%|███▊      | 1372/3541 [00:17<00:27, 79.09it/s]retrival evaluation:  39%|███▉      | 1381/3541 [00:17<00:27, 79.59it/s]retrival evaluation:  39%|███▉      | 1390/3541 [00:17<00:26, 79.73it/s]retrival evaluation:  40%|███▉      | 1399/3541 [00:17<00:26, 80.01it/s]retrival evaluation:  40%|███▉      | 1408/3541 [00:17<00:26, 80.19it/s]retrival evaluation:  40%|████      | 1417/3541 [00:17<00:26, 80.39it/s]retrival evaluation:  40%|████      | 1426/3541 [00:18<00:26, 79.46it/s]retrival evaluation:  41%|████      | 1435/3541 [00:18<00:26, 79.84it/s]retrival evaluation:  41%|████      | 1444/3541 [00:18<00:26, 79.70it/s]retrival evaluation:  41%|████      | 1452/3541 [00:18<00:26, 78.70it/s]retrival evaluation:  41%|████▏     | 1461/3541 [00:18<00:26, 79.09it/s]retrival evaluation:  41%|████▏     | 1469/3541 [00:18<00:26, 79.25it/s]retrival evaluation:  42%|████▏     | 1478/3541 [00:18<00:25, 79.64it/s]retrival evaluation:  42%|████▏     | 1487/3541 [00:18<00:25, 79.78it/s]retrival evaluation:  42%|████▏     | 1495/3541 [00:18<00:25, 79.69it/s]retrival evaluation:  42%|████▏     | 1504/3541 [00:19<00:25, 79.66it/s]retrival evaluation:  43%|████▎     | 1512/3541 [00:19<00:25, 79.47it/s]retrival evaluation:  43%|████▎     | 1520/3541 [00:19<00:25, 79.47it/s]retrival evaluation:  43%|████▎     | 1529/3541 [00:19<00:25, 79.87it/s]retrival evaluation:  43%|████▎     | 1538/3541 [00:19<00:25, 80.04it/s]retrival evaluation:  44%|████▎     | 1547/3541 [00:19<00:24, 79.90it/s]retrival evaluation:  44%|████▍     | 1556/3541 [00:19<00:24, 80.52it/s]retrival evaluation:  44%|████▍     | 1565/3541 [00:19<00:24, 80.74it/s]retrival evaluation:  44%|████▍     | 1574/3541 [00:19<00:24, 80.79it/s]retrival evaluation:  45%|████▍     | 1583/3541 [00:20<00:24, 80.60it/s]retrival evaluation:  45%|████▍     | 1592/3541 [00:20<00:24, 80.49it/s]retrival evaluation:  45%|████▌     | 1601/3541 [00:20<00:24, 80.13it/s]retrival evaluation:  45%|████▌     | 1610/3541 [00:20<00:24, 79.66it/s]retrival evaluation:  46%|████▌     | 1618/3541 [00:20<00:24, 79.64it/s]retrival evaluation:  46%|████▌     | 1626/3541 [00:20<00:24, 79.65it/s]retrival evaluation:  46%|████▌     | 1634/3541 [00:20<00:23, 79.75it/s]retrival evaluation:  46%|████▋     | 1642/3541 [00:20<00:23, 79.77it/s]retrival evaluation:  47%|████▋     | 1651/3541 [00:20<00:23, 79.96it/s]retrival evaluation:  47%|████▋     | 1659/3541 [00:20<00:23, 79.93it/s]retrival evaluation:  47%|████▋     | 1667/3541 [00:21<00:23, 79.73it/s]retrival evaluation:  47%|████▋     | 1675/3541 [00:21<00:23, 79.65it/s]retrival evaluation:  48%|████▊     | 1683/3541 [00:21<00:23, 79.64it/s]retrival evaluation:  48%|████▊     | 1692/3541 [00:21<00:23, 79.90it/s]retrival evaluation:  48%|████▊     | 1701/3541 [00:21<00:23, 79.95it/s]retrival evaluation:  48%|████▊     | 1710/3541 [00:21<00:22, 80.11it/s]retrival evaluation:  49%|████▊     | 1719/3541 [00:21<00:22, 80.03it/s]retrival evaluation:  49%|████▉     | 1728/3541 [00:21<00:22, 79.71it/s]retrival evaluation:  49%|████▉     | 1736/3541 [00:21<00:22, 79.68it/s]retrival evaluation:  49%|████▉     | 1745/3541 [00:22<00:22, 80.50it/s]retrival evaluation:  50%|████▉     | 1754/3541 [00:22<00:22, 80.68it/s]retrival evaluation:  50%|████▉     | 1763/3541 [00:22<00:22, 80.57it/s]retrival evaluation:  50%|█████     | 1772/3541 [00:22<00:21, 80.94it/s]retrival evaluation:  50%|█████     | 1781/3541 [00:22<00:21, 80.57it/s]retrival evaluation:  51%|█████     | 1790/3541 [00:22<00:21, 80.26it/s]retrival evaluation:  51%|█████     | 1799/3541 [00:22<00:21, 80.13it/s]retrival evaluation:  51%|█████     | 1808/3541 [00:22<00:21, 80.25it/s]retrival evaluation:  51%|█████▏    | 1817/3541 [00:22<00:21, 80.24it/s]retrival evaluation:  52%|█████▏    | 1826/3541 [00:23<00:22, 77.58it/s]retrival evaluation:  52%|█████▏    | 1834/3541 [00:23<00:21, 78.05it/s]retrival evaluation:  52%|█████▏    | 1842/3541 [00:23<00:22, 75.27it/s]retrival evaluation:  52%|█████▏    | 1850/3541 [00:23<00:22, 75.44it/s]retrival evaluation:  52%|█████▏    | 1859/3541 [00:23<00:21, 76.90it/s]retrival evaluation:  53%|█████▎    | 1867/3541 [00:23<00:21, 77.64it/s]retrival evaluation:  53%|█████▎    | 1875/3541 [00:23<00:21, 78.10it/s]retrival evaluation:  53%|█████▎    | 1884/3541 [00:23<00:20, 78.91it/s]retrival evaluation:  53%|█████▎    | 1892/3541 [00:23<00:20, 79.03it/s]retrival evaluation:  54%|█████▎    | 1900/3541 [00:23<00:20, 79.28it/s]retrival evaluation:  54%|█████▍    | 1909/3541 [00:24<00:20, 79.79it/s]retrival evaluation:  54%|█████▍    | 1918/3541 [00:24<00:20, 80.35it/s]retrival evaluation:  54%|█████▍    | 1927/3541 [00:24<00:20, 80.51it/s]retrival evaluation:  55%|█████▍    | 1936/3541 [00:24<00:19, 80.33it/s]retrival evaluation:  55%|█████▍    | 1945/3541 [00:24<00:19, 80.02it/s]retrival evaluation:  55%|█████▌    | 1954/3541 [00:24<00:19, 80.14it/s]retrival evaluation:  55%|█████▌    | 1963/3541 [00:24<00:19, 80.39it/s]retrival evaluation:  56%|█████▌    | 1972/3541 [00:24<00:19, 80.20it/s]retrival evaluation:  56%|█████▌    | 1981/3541 [00:25<00:19, 80.57it/s]retrival evaluation:  56%|█████▌    | 1990/3541 [00:25<00:19, 80.14it/s]retrival evaluation:  56%|█████▋    | 1999/3541 [00:25<00:19, 79.93it/s]retrival evaluation:  57%|█████▋    | 2007/3541 [00:25<00:19, 79.79it/s]retrival evaluation:  57%|█████▋    | 2016/3541 [00:25<00:19, 79.99it/s]retrival evaluation:  57%|█████▋    | 2025/3541 [00:25<00:18, 80.00it/s]retrival evaluation:  57%|█████▋    | 2034/3541 [00:25<00:18, 79.82it/s]retrival evaluation:  58%|█████▊    | 2043/3541 [00:25<00:18, 79.89it/s]retrival evaluation:  58%|█████▊    | 2052/3541 [00:25<00:18, 80.06it/s]retrival evaluation:  58%|█████▊    | 2061/3541 [00:26<00:18, 80.02it/s]retrival evaluation:  58%|█████▊    | 2070/3541 [00:26<00:18, 80.97it/s]retrival evaluation:  59%|█████▊    | 2079/3541 [00:26<00:17, 81.46it/s]retrival evaluation:  59%|█████▉    | 2088/3541 [00:26<00:17, 81.17it/s]retrival evaluation:  59%|█████▉    | 2097/3541 [00:26<00:17, 81.07it/s]retrival evaluation:  59%|█████▉    | 2106/3541 [00:26<00:17, 80.76it/s]retrival evaluation:  60%|█████▉    | 2115/3541 [00:26<00:17, 80.57it/s]retrival evaluation:  60%|█████▉    | 2124/3541 [00:26<00:17, 80.54it/s]retrival evaluation:  60%|██████    | 2133/3541 [00:26<00:17, 80.48it/s]retrival evaluation:  60%|██████    | 2142/3541 [00:27<00:17, 80.43it/s]retrival evaluation:  61%|██████    | 2151/3541 [00:27<00:17, 80.41it/s]retrival evaluation:  61%|██████    | 2160/3541 [00:27<00:17, 80.38it/s]retrival evaluation:  61%|██████▏   | 2169/3541 [00:27<00:17, 80.15it/s]retrival evaluation:  62%|██████▏   | 2178/3541 [00:27<00:16, 80.28it/s]retrival evaluation:  62%|██████▏   | 2187/3541 [00:27<00:16, 80.81it/s]retrival evaluation:  62%|██████▏   | 2196/3541 [00:27<00:16, 81.07it/s]retrival evaluation:  62%|██████▏   | 2205/3541 [00:27<00:16, 80.85it/s]retrival evaluation:  63%|██████▎   | 2214/3541 [00:27<00:16, 80.37it/s]retrival evaluation:  63%|██████▎   | 2223/3541 [00:28<00:16, 80.29it/s]retrival evaluation:  63%|██████▎   | 2232/3541 [00:28<00:16, 79.20it/s]retrival evaluation:  63%|██████▎   | 2241/3541 [00:28<00:16, 79.60it/s]retrival evaluation:  64%|██████▎   | 2250/3541 [00:28<00:16, 79.78it/s]retrival evaluation:  64%|██████▍   | 2258/3541 [00:28<00:16, 79.55it/s]retrival evaluation:  64%|██████▍   | 2266/3541 [00:28<00:16, 79.40it/s]retrival evaluation:  64%|██████▍   | 2275/3541 [00:28<00:15, 79.79it/s]retrival evaluation:  65%|██████▍   | 2284/3541 [00:28<00:15, 80.01it/s]retrival evaluation:  65%|██████▍   | 2293/3541 [00:28<00:15, 79.98it/s]retrival evaluation:  65%|██████▍   | 2301/3541 [00:28<00:15, 79.92it/s]retrival evaluation:  65%|██████▌   | 2309/3541 [00:29<00:15, 79.93it/s]retrival evaluation:  65%|██████▌   | 2317/3541 [00:29<00:15, 79.64it/s]retrival evaluation:  66%|██████▌   | 2326/3541 [00:29<00:15, 79.88it/s]retrival evaluation:  66%|██████▌   | 2335/3541 [00:29<00:14, 80.71it/s]retrival evaluation:  66%|██████▌   | 2344/3541 [00:29<00:14, 81.07it/s]retrival evaluation:  66%|██████▋   | 2353/3541 [00:29<00:14, 80.68it/s]retrival evaluation:  67%|██████▋   | 2362/3541 [00:29<00:14, 80.68it/s]retrival evaluation:  67%|██████▋   | 2371/3541 [00:29<00:14, 80.54it/s]retrival evaluation:  67%|██████▋   | 2380/3541 [00:29<00:14, 80.17it/s]retrival evaluation:  67%|██████▋   | 2389/3541 [00:30<00:14, 79.76it/s]retrival evaluation:  68%|██████▊   | 2397/3541 [00:30<00:14, 79.70it/s]retrival evaluation:  68%|██████▊   | 2405/3541 [00:30<00:14, 79.14it/s]retrival evaluation:  68%|██████▊   | 2413/3541 [00:30<00:14, 79.23it/s]retrival evaluation:  68%|██████▊   | 2421/3541 [00:30<00:14, 78.88it/s]retrival evaluation:  69%|██████▊   | 2429/3541 [00:30<00:14, 78.99it/s]retrival evaluation:  69%|██████▉   | 2437/3541 [00:30<00:13, 78.98it/s]retrival evaluation:  69%|██████▉   | 2445/3541 [00:30<00:13, 78.72it/s]retrival evaluation:  69%|██████▉   | 2453/3541 [00:30<00:13, 78.76it/s]retrival evaluation:  70%|██████▉   | 2462/3541 [00:31<00:13, 80.03it/s]retrival evaluation:  70%|██████▉   | 2471/3541 [00:31<00:13, 80.52it/s]retrival evaluation:  70%|███████   | 2480/3541 [00:31<00:13, 80.81it/s]retrival evaluation:  70%|███████   | 2489/3541 [00:31<00:13, 80.86it/s]retrival evaluation:  71%|███████   | 2498/3541 [00:31<00:12, 80.74it/s]retrival evaluation:  71%|███████   | 2507/3541 [00:31<00:12, 80.94it/s]retrival evaluation:  71%|███████   | 2516/3541 [00:31<00:12, 80.68it/s]retrival evaluation:  71%|███████▏  | 2525/3541 [00:31<00:12, 80.83it/s]retrival evaluation:  72%|███████▏  | 2534/3541 [00:31<00:12, 80.42it/s]retrival evaluation:  72%|███████▏  | 2543/3541 [00:32<00:12, 80.19it/s]retrival evaluation:  72%|███████▏  | 2552/3541 [00:32<00:12, 80.28it/s]retrival evaluation:  72%|███████▏  | 2561/3541 [00:32<00:12, 80.36it/s]retrival evaluation:  73%|███████▎  | 2570/3541 [00:32<00:12, 80.30it/s]retrival evaluation:  73%|███████▎  | 2579/3541 [00:32<00:11, 80.27it/s]retrival evaluation:  73%|███████▎  | 2588/3541 [00:32<00:11, 79.93it/s]retrival evaluation:  73%|███████▎  | 2597/3541 [00:32<00:11, 80.03it/s]retrival evaluation:  74%|███████▎  | 2606/3541 [00:32<00:11, 80.18it/s]retrival evaluation:  74%|███████▍  | 2615/3541 [00:32<00:11, 80.45it/s]retrival evaluation:  74%|███████▍  | 2624/3541 [00:33<00:11, 80.86it/s]retrival evaluation:  74%|███████▍  | 2633/3541 [00:33<00:11, 79.52it/s]retrival evaluation:  75%|███████▍  | 2642/3541 [00:33<00:11, 79.88it/s]retrival evaluation:  75%|███████▍  | 2650/3541 [00:33<00:11, 79.86it/s]retrival evaluation:  75%|███████▌  | 2659/3541 [00:33<00:11, 80.11it/s]retrival evaluation:  75%|███████▌  | 2668/3541 [00:33<00:10, 80.05it/s]retrival evaluation:  76%|███████▌  | 2677/3541 [00:33<00:10, 80.11it/s]retrival evaluation:  76%|███████▌  | 2686/3541 [00:33<00:10, 79.80it/s]retrival evaluation:  76%|███████▌  | 2695/3541 [00:33<00:10, 79.98it/s]retrival evaluation:  76%|███████▋  | 2703/3541 [00:34<00:10, 79.81it/s]retrival evaluation:  77%|███████▋  | 2711/3541 [00:34<00:10, 79.77it/s]retrival evaluation:  77%|███████▋  | 2719/3541 [00:34<00:10, 79.69it/s]retrival evaluation:  77%|███████▋  | 2727/3541 [00:34<00:10, 79.76it/s]retrival evaluation:  77%|███████▋  | 2735/3541 [00:34<00:10, 79.69it/s]retrival evaluation:  77%|███████▋  | 2744/3541 [00:34<00:09, 80.06it/s]retrival evaluation:  78%|███████▊  | 2753/3541 [00:34<00:09, 80.26it/s]retrival evaluation:  78%|███████▊  | 2762/3541 [00:34<00:09, 80.47it/s]retrival evaluation:  78%|███████▊  | 2771/3541 [00:34<00:09, 80.25it/s]retrival evaluation:  79%|███████▊  | 2780/3541 [00:34<00:09, 80.34it/s]retrival evaluation:  79%|███████▉  | 2789/3541 [00:35<00:09, 80.37it/s]retrival evaluation:  79%|███████▉  | 2798/3541 [00:35<00:09, 80.19it/s]retrival evaluation:  79%|███████▉  | 2807/3541 [00:35<00:09, 79.94it/s]retrival evaluation:  79%|███████▉  | 2815/3541 [00:35<00:09, 79.86it/s]retrival evaluation:  80%|███████▉  | 2823/3541 [00:35<00:09, 79.67it/s]retrival evaluation:  80%|███████▉  | 2831/3541 [00:35<00:08, 79.72it/s]retrival evaluation:  80%|████████  | 2839/3541 [00:35<00:08, 79.58it/s]retrival evaluation:  80%|████████  | 2847/3541 [00:35<00:08, 79.51it/s]retrival evaluation:  81%|████████  | 2855/3541 [00:35<00:08, 79.51it/s]retrival evaluation:  81%|████████  | 2863/3541 [00:36<00:08, 79.43it/s]retrival evaluation:  81%|████████  | 2871/3541 [00:36<00:08, 79.58it/s]retrival evaluation:  81%|████████▏ | 2880/3541 [00:36<00:08, 79.80it/s]retrival evaluation:  82%|████████▏ | 2889/3541 [00:36<00:08, 79.99it/s]retrival evaluation:  82%|████████▏ | 2897/3541 [00:36<00:08, 79.80it/s]retrival evaluation:  82%|████████▏ | 2905/3541 [00:36<00:07, 79.79it/s]retrival evaluation:  82%|████████▏ | 2913/3541 [00:36<00:07, 79.67it/s]retrival evaluation:  82%|████████▏ | 2921/3541 [00:36<00:07, 79.61it/s]retrival evaluation:  83%|████████▎ | 2929/3541 [00:36<00:07, 79.54it/s]retrival evaluation:  83%|████████▎ | 2937/3541 [00:36<00:07, 79.60it/s]retrival evaluation:  83%|████████▎ | 2945/3541 [00:37<00:07, 79.55it/s]retrival evaluation:  83%|████████▎ | 2953/3541 [00:37<00:07, 79.34it/s]retrival evaluation:  84%|████████▎ | 2962/3541 [00:37<00:07, 79.61it/s]retrival evaluation:  84%|████████▍ | 2970/3541 [00:37<00:07, 79.62it/s]retrival evaluation:  84%|████████▍ | 2978/3541 [00:37<00:07, 79.69it/s]retrival evaluation:  84%|████████▍ | 2986/3541 [00:37<00:06, 79.61it/s]retrival evaluation:  85%|████████▍ | 2995/3541 [00:37<00:06, 79.73it/s]retrival evaluation:  85%|████████▍ | 3004/3541 [00:37<00:06, 79.98it/s]retrival evaluation:  85%|████████▌ | 3012/3541 [00:37<00:06, 79.64it/s]retrival evaluation:  85%|████████▌ | 3020/3541 [00:37<00:06, 79.64it/s]retrival evaluation:  86%|████████▌ | 3028/3541 [00:38<00:06, 79.57it/s]retrival evaluation:  86%|████████▌ | 3036/3541 [00:38<00:06, 79.46it/s]retrival evaluation:  86%|████████▌ | 3045/3541 [00:38<00:06, 79.73it/s]retrival evaluation:  86%|████████▌ | 3053/3541 [00:38<00:06, 77.24it/s]retrival evaluation:  86%|████████▋ | 3061/3541 [00:38<00:06, 77.77it/s]retrival evaluation:  87%|████████▋ | 3069/3541 [00:38<00:06, 76.58it/s]retrival evaluation:  87%|████████▋ | 3077/3541 [00:38<00:06, 75.40it/s]retrival evaluation:  87%|████████▋ | 3086/3541 [00:38<00:05, 76.85it/s]retrival evaluation:  87%|████████▋ | 3094/3541 [00:38<00:05, 77.64it/s]retrival evaluation:  88%|████████▊ | 3102/3541 [00:39<00:05, 78.06it/s]retrival evaluation:  88%|████████▊ | 3110/3541 [00:39<00:05, 78.55it/s]retrival evaluation:  88%|████████▊ | 3118/3541 [00:39<00:05, 78.97it/s]retrival evaluation:  88%|████████▊ | 3127/3541 [00:39<00:05, 79.47it/s]retrival evaluation:  89%|████████▊ | 3135/3541 [00:39<00:05, 79.40it/s]retrival evaluation:  89%|████████▉ | 3143/3541 [00:39<00:05, 79.56it/s]retrival evaluation:  89%|████████▉ | 3151/3541 [00:39<00:04, 79.38it/s]retrival evaluation:  89%|████████▉ | 3160/3541 [00:39<00:04, 79.71it/s]retrival evaluation:  89%|████████▉ | 3168/3541 [00:39<00:04, 79.63it/s]retrival evaluation:  90%|████████▉ | 3177/3541 [00:39<00:04, 79.69it/s]retrival evaluation:  90%|████████▉ | 3186/3541 [00:40<00:04, 79.85it/s]retrival evaluation:  90%|█████████ | 3195/3541 [00:40<00:04, 80.09it/s]retrival evaluation:  90%|█████████ | 3204/3541 [00:40<00:04, 80.18it/s]retrival evaluation:  91%|█████████ | 3213/3541 [00:40<00:04, 80.32it/s]retrival evaluation:  91%|█████████ | 3222/3541 [00:40<00:03, 80.17it/s]retrival evaluation:  91%|█████████ | 3231/3541 [00:40<00:03, 79.62it/s]retrival evaluation:  91%|█████████▏| 3240/3541 [00:40<00:03, 79.84it/s]retrival evaluation:  92%|█████████▏| 3248/3541 [00:40<00:03, 79.74it/s]retrival evaluation:  92%|█████████▏| 3256/3541 [00:40<00:03, 79.67it/s]retrival evaluation:  92%|█████████▏| 3264/3541 [00:41<00:03, 79.60it/s]retrival evaluation:  92%|█████████▏| 3272/3541 [00:41<00:03, 79.33it/s]retrival evaluation:  93%|█████████▎| 3280/3541 [00:41<00:03, 79.30it/s]retrival evaluation:  93%|█████████▎| 3288/3541 [00:41<00:03, 79.35it/s]retrival evaluation:  93%|█████████▎| 3296/3541 [00:41<00:03, 79.44it/s]retrival evaluation:  93%|█████████▎| 3304/3541 [00:41<00:02, 79.47it/s]retrival evaluation:  94%|█████████▎| 3313/3541 [00:41<00:02, 79.74it/s]retrival evaluation:  94%|█████████▍| 3321/3541 [00:41<00:02, 79.58it/s]retrival evaluation:  94%|█████████▍| 3330/3541 [00:41<00:02, 79.73it/s]retrival evaluation:  94%|█████████▍| 3338/3541 [00:42<00:02, 79.77it/s]retrival evaluation:  94%|█████████▍| 3346/3541 [00:42<00:02, 79.83it/s]retrival evaluation:  95%|█████████▍| 3354/3541 [00:42<00:02, 79.86it/s]retrival evaluation:  95%|█████████▍| 3362/3541 [00:42<00:02, 79.74it/s]retrival evaluation:  95%|█████████▌| 3370/3541 [00:42<00:02, 79.67it/s]retrival evaluation:  95%|█████████▌| 3379/3541 [00:42<00:02, 79.87it/s]retrival evaluation:  96%|█████████▌| 3387/3541 [00:42<00:01, 79.86it/s]retrival evaluation:  96%|█████████▌| 3395/3541 [00:42<00:01, 79.74it/s]retrival evaluation:  96%|█████████▌| 3403/3541 [00:42<00:01, 79.79it/s]retrival evaluation:  96%|█████████▋| 3412/3541 [00:42<00:01, 79.93it/s]retrival evaluation:  97%|█████████▋| 3420/3541 [00:43<00:01, 79.79it/s]retrival evaluation:  97%|█████████▋| 3428/3541 [00:43<00:01, 79.82it/s]retrival evaluation:  97%|█████████▋| 3437/3541 [00:43<00:01, 79.89it/s]retrival evaluation:  97%|█████████▋| 3445/3541 [00:43<00:01, 79.80it/s]retrival evaluation:  98%|█████████▊| 3453/3541 [00:43<00:01, 79.85it/s]retrival evaluation:  98%|█████████▊| 3462/3541 [00:43<00:00, 80.04it/s]retrival evaluation:  98%|█████████▊| 3471/3541 [00:43<00:00, 80.20it/s]retrival evaluation:  98%|█████████▊| 3480/3541 [00:43<00:00, 80.22it/s]retrival evaluation:  99%|█████████▊| 3489/3541 [00:43<00:00, 80.03it/s]retrival evaluation:  99%|█████████▉| 3498/3541 [00:44<00:00, 79.93it/s]retrival evaluation:  99%|█████████▉| 3507/3541 [00:44<00:00, 80.09it/s]retrival evaluation:  99%|█████████▉| 3516/3541 [00:44<00:00, 79.73it/s]retrival evaluation: 100%|█████████▉| 3524/3541 [00:44<00:00, 79.73it/s]retrival evaluation: 100%|█████████▉| 3533/3541 [00:44<00:00, 79.97it/s]retrival evaluation: 100%|██████████| 3541/3541 [00:44<00:00, 79.52it/s]

pk3=0, pk2=0,pk1=0 best_f1 = 0.338, bets_f2=0.361, MAP=0.464, MRR=0, AP=0.263, exe_time=236.91417694091797

INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:__main__:model loaded
INFO:EMSE.BERTDataReader:Creating examples from dataset file at /afs/crc.nd.edu/user/j/jlin6/data/EMSE/canal/test
update feature:   0%|          | 0/28 [00:00<?, ?it/s]update feature:  54%|█████▎    | 15/28 [00:00<00:00, 147.67it/s]update feature: 100%|██████████| 28/28 [00:00<00:00, 188.72it/s]
update feature:   0%|          | 0/28 [00:00<?, ?it/s]update feature: 100%|██████████| 28/28 [00:00<00:00, 511.30it/s]
update embedding:   0%|          | 0/28 [00:00<?, ?it/s]update embedding:   4%|▎         | 1/28 [00:00<00:21,  1.23it/s]update embedding:   7%|▋         | 2/28 [00:01<00:20,  1.24it/s]update embedding:  11%|█         | 3/28 [00:02<00:19,  1.25it/s]update embedding:  14%|█▍        | 4/28 [00:03<00:19,  1.26it/s]update embedding:  18%|█▊        | 5/28 [00:03<00:18,  1.26it/s]update embedding:  21%|██▏       | 6/28 [00:04<00:17,  1.26it/s]update embedding:  25%|██▌       | 7/28 [00:05<00:16,  1.27it/s]update embedding:  29%|██▊       | 8/28 [00:06<00:15,  1.26it/s]update embedding:  32%|███▏      | 9/28 [00:07<00:14,  1.29it/s]update embedding:  36%|███▌      | 10/28 [00:07<00:13,  1.32it/s]update embedding:  39%|███▉      | 11/28 [00:08<00:12,  1.34it/s]update embedding:  43%|████▎     | 12/28 [00:09<00:12,  1.29it/s]update embedding:  46%|████▋     | 13/28 [00:10<00:11,  1.26it/s]update embedding:  50%|█████     | 14/28 [00:10<00:11,  1.25it/s]update embedding:  54%|█████▎    | 15/28 [00:11<00:10,  1.26it/s]update embedding:  57%|█████▋    | 16/28 [00:12<00:09,  1.26it/s]update embedding:  61%|██████    | 17/28 [00:13<00:08,  1.25it/s]update embedding:  64%|██████▍   | 18/28 [00:14<00:08,  1.23it/s]update embedding:  68%|██████▊   | 19/28 [00:15<00:07,  1.21it/s]update embedding:  71%|███████▏  | 20/28 [00:15<00:06,  1.21it/s]update embedding:  75%|███████▌  | 21/28 [00:16<00:05,  1.22it/s]update embedding:  79%|███████▊  | 22/28 [00:17<00:04,  1.23it/s]update embedding:  82%|████████▏ | 23/28 [00:18<00:04,  1.23it/s]update embedding:  86%|████████▌ | 24/28 [00:19<00:03,  1.24it/s]update embedding:  89%|████████▉ | 25/28 [00:19<00:02,  1.24it/s]update embedding:  93%|█████████▎| 26/28 [00:20<00:01,  1.24it/s]update embedding:  96%|█████████▋| 27/28 [00:21<00:00,  1.25it/s]update embedding: 100%|██████████| 28/28 [00:22<00:00,  1.24it/s]update embedding: 100%|██████████| 28/28 [00:22<00:00,  1.25it/s]
update embedding:   0%|          | 0/28 [00:00<?, ?it/s]update embedding:   4%|▎         | 1/28 [00:00<00:21,  1.27it/s]update embedding:   7%|▋         | 2/28 [00:01<00:20,  1.26it/s]update embedding:  11%|█         | 3/28 [00:02<00:19,  1.26it/s]update embedding:  14%|█▍        | 4/28 [00:03<00:19,  1.26it/s]update embedding:  18%|█▊        | 5/28 [00:03<00:18,  1.26it/s]update embedding:  21%|██▏       | 6/28 [00:04<00:17,  1.26it/s]update embedding:  25%|██▌       | 7/28 [00:05<00:16,  1.26it/s]update embedding:  29%|██▊       | 8/28 [00:06<00:16,  1.25it/s]update embedding:  32%|███▏      | 9/28 [00:07<00:15,  1.25it/s]update embedding:  36%|███▌      | 10/28 [00:07<00:14,  1.25it/s]update embedding:  39%|███▉      | 11/28 [00:08<00:13,  1.25it/s]update embedding:  43%|████▎     | 12/28 [00:09<00:12,  1.25it/s]update embedding:  46%|████▋     | 13/28 [00:10<00:11,  1.25it/s]update embedding:  50%|█████     | 14/28 [00:11<00:11,  1.26it/s]update embedding:  54%|█████▎    | 15/28 [00:11<00:10,  1.26it/s]update embedding:  57%|█████▋    | 16/28 [00:12<00:09,  1.26it/s]update embedding:  61%|██████    | 17/28 [00:13<00:08,  1.26it/s]update embedding:  64%|██████▍   | 18/28 [00:14<00:07,  1.26it/s]update embedding:  68%|██████▊   | 19/28 [00:15<00:07,  1.26it/s]update embedding:  71%|███████▏  | 20/28 [00:15<00:06,  1.25it/s]update embedding:  75%|███████▌  | 21/28 [00:16<00:05,  1.26it/s]update embedding:  79%|███████▊  | 22/28 [00:17<00:04,  1.27it/s]update embedding:  82%|████████▏ | 23/28 [00:18<00:03,  1.27it/s]update embedding:  86%|████████▌ | 24/28 [00:19<00:03,  1.28it/s]update embedding:  89%|████████▉ | 25/28 [00:19<00:02,  1.28it/s]update embedding:  93%|█████████▎| 26/28 [00:20<00:01,  1.27it/s]update embedding:  96%|█████████▋| 27/28 [00:21<00:00,  1.27it/s]update embedding: 100%|██████████| 28/28 [00:22<00:00,  1.27it/s]update embedding: 100%|██████████| 28/28 [00:22<00:00,  1.26it/s]
retrival evaluation:   0%|          | 0/196 [00:00<?, ?it/s]retrival evaluation:   3%|▎         | 5/196 [00:00<00:04, 46.88it/s]retrival evaluation:   7%|▋         | 13/196 [00:00<00:03, 52.91it/s]retrival evaluation:  11%|█         | 22/196 [00:00<00:02, 58.94it/s]retrival evaluation:  16%|█▌        | 31/196 [00:00<00:02, 64.17it/s]retrival evaluation:  20%|█▉        | 39/196 [00:00<00:02, 68.06it/s]retrival evaluation:  24%|██▍       | 48/196 [00:00<00:02, 71.29it/s]retrival evaluation:  29%|██▉       | 57/196 [00:00<00:01, 73.86it/s]retrival evaluation:  34%|███▎      | 66/196 [00:00<00:01, 75.75it/s]retrival evaluation:  38%|███▊      | 74/196 [00:00<00:01, 76.51it/s]retrival evaluation:  42%|████▏     | 83/196 [00:01<00:01, 77.75it/s]retrival evaluation:  46%|████▋     | 91/196 [00:01<00:01, 78.37it/s]retrival evaluation:  51%|█████     | 99/196 [00:01<00:01, 78.60it/s]retrival evaluation:  55%|█████▍    | 107/196 [00:01<00:01, 78.68it/s]retrival evaluation:  59%|█████▊    | 115/196 [00:01<00:01, 78.94it/s]retrival evaluation:  63%|██████▎   | 124/196 [00:01<00:00, 79.49it/s]retrival evaluation:  67%|██████▋   | 132/196 [00:01<00:00, 79.53it/s]retrival evaluation:  71%|███████▏  | 140/196 [00:01<00:00, 79.49it/s]retrival evaluation:  76%|███████▌  | 149/196 [00:01<00:00, 79.90it/s]retrival evaluation:  81%|████████  | 158/196 [00:02<00:00, 80.14it/s]retrival evaluation:  85%|████████▌ | 167/196 [00:02<00:00, 80.38it/s]retrival evaluation:  90%|████████▉ | 176/196 [00:02<00:00, 79.87it/s]retrival evaluation:  94%|█████████▍| 185/196 [00:02<00:00, 80.13it/s]retrival evaluation:  99%|█████████▉| 194/196 [00:02<00:00, 79.58it/s]retrival evaluation: 100%|██████████| 196/196 [00:02<00:00, 78.34it/s]

pk3=0, pk2=0,pk1=0 best_f1 = 0.333, bets_f2=0.377, MAP=0.48, MRR=0, AP=0.295, exe_time=47.38232779502869

INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:__main__:model loaded
INFO:EMSE.BERTDataReader:Creating examples from dataset file at /afs/crc.nd.edu/user/j/jlin6/data/EMSE/druid/test
update feature:   0%|          | 0/118 [00:00<?, ?it/s]update feature:   8%|▊         | 9/118 [00:00<00:01, 71.74it/s]update feature:  14%|█▎        | 16/118 [00:00<00:01, 67.30it/s]update feature:  24%|██▎       | 28/118 [00:00<00:01, 77.10it/s]update feature:  31%|███       | 36/118 [00:00<00:01, 68.42it/s]update feature:  38%|███▊      | 45/118 [00:00<00:01, 70.52it/s]update feature:  45%|████▍     | 53/118 [00:00<00:00, 72.29it/s]update feature:  59%|█████▉    | 70/118 [00:00<00:00, 82.72it/s]update feature:  67%|██████▋   | 79/118 [00:01<00:00, 68.28it/s]update feature:  77%|███████▋  | 91/118 [00:01<00:00, 78.19it/s]update feature:  85%|████████▍ | 100/118 [00:01<00:00, 59.58it/s]update feature:  93%|█████████▎| 110/118 [00:01<00:00, 66.51it/s]update feature: 100%|██████████| 118/118 [00:01<00:00, 61.07it/s]update feature: 100%|██████████| 118/118 [00:01<00:00, 71.87it/s]
update feature:   0%|          | 0/118 [00:00<?, ?it/s]update feature:  66%|██████▌   | 78/118 [00:00<00:00, 776.68it/s]update feature: 100%|██████████| 118/118 [00:00<00:00, 811.95it/s]
update embedding:   0%|          | 0/118 [00:00<?, ?it/s]update embedding:   1%|          | 1/118 [00:00<01:39,  1.17it/s]update embedding:   2%|▏         | 2/118 [00:01<01:37,  1.19it/s]update embedding:   3%|▎         | 3/118 [00:02<01:34,  1.21it/s]update embedding:   3%|▎         | 4/118 [00:03<01:35,  1.19it/s]update embedding:   4%|▍         | 5/118 [00:04<01:34,  1.20it/s]update embedding:   5%|▌         | 6/118 [00:05<01:34,  1.18it/s]update embedding:   6%|▌         | 7/118 [00:05<01:34,  1.17it/s]update embedding:   7%|▋         | 8/118 [00:06<01:36,  1.14it/s]update embedding:   8%|▊         | 9/118 [00:07<01:34,  1.16it/s]update embedding:   8%|▊         | 10/118 [00:08<01:33,  1.15it/s]update embedding:   9%|▉         | 11/118 [00:09<01:38,  1.09it/s]update embedding:  10%|█         | 12/118 [00:10<01:37,  1.09it/s]update embedding:  11%|█         | 13/118 [00:11<01:38,  1.07it/s]update embedding:  12%|█▏        | 14/118 [00:12<01:35,  1.09it/s]update embedding:  13%|█▎        | 15/118 [00:13<01:31,  1.13it/s]update embedding:  14%|█▎        | 16/118 [00:14<01:29,  1.14it/s]update embedding:  14%|█▍        | 17/118 [00:14<01:27,  1.15it/s]update embedding:  15%|█▌        | 18/118 [00:15<01:27,  1.14it/s]update embedding:  16%|█▌        | 19/118 [00:16<01:25,  1.16it/s]update embedding:  17%|█▋        | 20/118 [00:17<01:21,  1.20it/s]update embedding:  18%|█▊        | 21/118 [00:18<01:20,  1.20it/s]update embedding:  19%|█▊        | 22/118 [00:19<01:19,  1.21it/s]update embedding:  19%|█▉        | 23/118 [00:19<01:17,  1.22it/s]update embedding:  20%|██        | 24/118 [00:20<01:17,  1.21it/s]update embedding:  21%|██        | 25/118 [00:21<01:15,  1.23it/s]update embedding:  22%|██▏       | 26/118 [00:22<01:14,  1.24it/s]update embedding:  23%|██▎       | 27/118 [00:23<01:13,  1.23it/s]update embedding:  24%|██▎       | 28/118 [00:23<01:12,  1.24it/s]update embedding:  25%|██▍       | 29/118 [00:24<01:11,  1.24it/s]update embedding:  25%|██▌       | 30/118 [00:25<01:10,  1.25it/s]update embedding:  26%|██▋       | 31/118 [00:26<01:09,  1.26it/s]update embedding:  27%|██▋       | 32/118 [00:27<01:08,  1.25it/s]update embedding:  28%|██▊       | 33/118 [00:27<01:08,  1.24it/s]update embedding:  29%|██▉       | 34/118 [00:28<01:07,  1.25it/s]update embedding:  30%|██▉       | 35/118 [00:29<01:06,  1.25it/s]update embedding:  31%|███       | 36/118 [00:30<01:05,  1.26it/s]update embedding:  31%|███▏      | 37/118 [00:30<01:04,  1.26it/s]update embedding:  32%|███▏      | 38/118 [00:31<01:03,  1.26it/s]update embedding:  33%|███▎      | 39/118 [00:32<01:02,  1.27it/s]update embedding:  34%|███▍      | 40/118 [00:33<01:01,  1.27it/s]update embedding:  35%|███▍      | 41/118 [00:34<01:01,  1.26it/s]update embedding:  36%|███▌      | 42/118 [00:34<01:00,  1.25it/s]update embedding:  36%|███▋      | 43/118 [00:35<00:59,  1.26it/s]update embedding:  37%|███▋      | 44/118 [00:36<00:58,  1.26it/s]update embedding:  38%|███▊      | 45/118 [00:37<00:57,  1.26it/s]update embedding:  39%|███▉      | 46/118 [00:38<00:57,  1.26it/s]update embedding:  40%|███▉      | 47/118 [00:38<00:56,  1.26it/s]update embedding:  41%|████      | 48/118 [00:39<00:55,  1.27it/s]update embedding:  42%|████▏     | 49/118 [00:40<00:54,  1.27it/s]update embedding:  42%|████▏     | 50/118 [00:41<00:53,  1.27it/s]update embedding:  43%|████▎     | 51/118 [00:42<00:52,  1.27it/s]update embedding:  44%|████▍     | 52/118 [00:42<00:51,  1.27it/s]update embedding:  45%|████▍     | 53/118 [00:43<00:50,  1.28it/s]update embedding:  46%|████▌     | 54/118 [00:44<00:50,  1.26it/s]update embedding:  47%|████▋     | 55/118 [00:45<00:49,  1.27it/s]update embedding:  47%|████▋     | 56/118 [00:46<00:49,  1.26it/s]update embedding:  48%|████▊     | 57/118 [00:46<00:48,  1.26it/s]update embedding:  49%|████▉     | 58/118 [00:47<00:47,  1.26it/s]update embedding:  50%|█████     | 59/118 [00:48<00:46,  1.26it/s]update embedding:  51%|█████     | 60/118 [00:49<00:45,  1.27it/s]update embedding:  52%|█████▏    | 61/118 [00:49<00:44,  1.27it/s]update embedding:  53%|█████▎    | 62/118 [00:50<00:44,  1.26it/s]update embedding:  53%|█████▎    | 63/118 [00:51<00:43,  1.27it/s]update embedding:  54%|█████▍    | 64/118 [00:52<00:42,  1.27it/s]update embedding:  55%|█████▌    | 65/118 [00:53<00:41,  1.27it/s]update embedding:  56%|█████▌    | 66/118 [00:53<00:40,  1.28it/s]update embedding:  57%|█████▋    | 67/118 [00:54<00:39,  1.28it/s]update embedding:  58%|█████▊    | 68/118 [00:55<00:39,  1.28it/s]update embedding:  58%|█████▊    | 69/118 [00:56<00:38,  1.28it/s]update embedding:  59%|█████▉    | 70/118 [00:57<00:37,  1.28it/s]update embedding:  60%|██████    | 71/118 [00:57<00:36,  1.28it/s]update embedding:  61%|██████    | 72/118 [00:58<00:35,  1.28it/s]update embedding:  62%|██████▏   | 73/118 [00:59<00:34,  1.29it/s]update embedding:  63%|██████▎   | 74/118 [01:00<00:34,  1.28it/s]update embedding:  64%|██████▎   | 75/118 [01:00<00:33,  1.27it/s]update embedding:  64%|██████▍   | 76/118 [01:01<00:32,  1.28it/s]update embedding:  65%|██████▌   | 77/118 [01:02<00:32,  1.28it/s]update embedding:  66%|██████▌   | 78/118 [01:03<00:31,  1.27it/s]update embedding:  67%|██████▋   | 79/118 [01:04<00:30,  1.26it/s]update embedding:  68%|██████▊   | 80/118 [01:04<00:29,  1.27it/s]update embedding:  69%|██████▊   | 81/118 [01:05<00:29,  1.27it/s]update embedding:  69%|██████▉   | 82/118 [01:06<00:28,  1.27it/s]update embedding:  70%|███████   | 83/118 [01:07<00:27,  1.28it/s]update embedding:  71%|███████   | 84/118 [01:07<00:26,  1.28it/s]update embedding:  72%|███████▏  | 85/118 [01:08<00:25,  1.28it/s]update embedding:  73%|███████▎  | 86/118 [01:09<00:24,  1.28it/s]update embedding:  74%|███████▎  | 87/118 [01:10<00:24,  1.28it/s]update embedding:  75%|███████▍  | 88/118 [01:11<00:23,  1.28it/s]update embedding:  75%|███████▌  | 89/118 [01:11<00:22,  1.28it/s]update embedding:  76%|███████▋  | 90/118 [01:12<00:21,  1.29it/s]update embedding:  77%|███████▋  | 91/118 [01:13<00:21,  1.28it/s]update embedding:  78%|███████▊  | 92/118 [01:14<00:20,  1.28it/s]update embedding:  79%|███████▉  | 93/118 [01:15<00:19,  1.28it/s]update embedding:  80%|███████▉  | 94/118 [01:15<00:18,  1.29it/s]update embedding:  81%|████████  | 95/118 [01:16<00:17,  1.29it/s]update embedding:  81%|████████▏ | 96/118 [01:17<00:17,  1.29it/s]update embedding:  82%|████████▏ | 97/118 [01:18<00:16,  1.28it/s]update embedding:  83%|████████▎ | 98/118 [01:18<00:15,  1.28it/s]update embedding:  84%|████████▍ | 99/118 [01:19<00:14,  1.28it/s]update embedding:  85%|████████▍ | 100/118 [01:20<00:14,  1.28it/s]update embedding:  86%|████████▌ | 101/118 [01:21<00:13,  1.28it/s]update embedding:  86%|████████▋ | 102/118 [01:22<00:12,  1.28it/s]update embedding:  87%|████████▋ | 103/118 [01:22<00:11,  1.29it/s]update embedding:  88%|████████▊ | 104/118 [01:23<00:10,  1.29it/s]update embedding:  89%|████████▉ | 105/118 [01:24<00:10,  1.27it/s]update embedding:  90%|████████▉ | 106/118 [01:25<00:09,  1.27it/s]update embedding:  91%|█████████ | 107/118 [01:25<00:08,  1.27it/s]update embedding:  92%|█████████▏| 108/118 [01:26<00:07,  1.28it/s]update embedding:  92%|█████████▏| 109/118 [01:27<00:07,  1.28it/s]update embedding:  93%|█████████▎| 110/118 [01:28<00:06,  1.27it/s]update embedding:  94%|█████████▍| 111/118 [01:29<00:05,  1.27it/s]update embedding:  95%|█████████▍| 112/118 [01:29<00:04,  1.27it/s]update embedding:  96%|█████████▌| 113/118 [01:30<00:03,  1.28it/s]update embedding:  97%|█████████▋| 114/118 [01:31<00:03,  1.28it/s]update embedding:  97%|█████████▋| 115/118 [01:32<00:02,  1.28it/s]update embedding:  98%|█████████▊| 116/118 [01:33<00:01,  1.28it/s]update embedding:  99%|█████████▉| 117/118 [01:33<00:00,  1.28it/s]update embedding: 100%|██████████| 118/118 [01:34<00:00,  1.28it/s]update embedding: 100%|██████████| 118/118 [01:34<00:00,  1.25it/s]
update embedding:   0%|          | 0/118 [00:00<?, ?it/s]update embedding:   1%|          | 1/118 [00:00<01:31,  1.28it/s]update embedding:   2%|▏         | 2/118 [00:01<01:30,  1.28it/s]update embedding:   3%|▎         | 3/118 [00:02<01:29,  1.29it/s]update embedding:   3%|▎         | 4/118 [00:03<01:28,  1.28it/s]update embedding:   4%|▍         | 5/118 [00:03<01:27,  1.28it/s]update embedding:   5%|▌         | 6/118 [00:04<01:27,  1.28it/s]update embedding:   6%|▌         | 7/118 [00:05<01:26,  1.28it/s]update embedding:   7%|▋         | 8/118 [00:06<01:25,  1.28it/s]update embedding:   8%|▊         | 9/118 [00:07<01:25,  1.28it/s]update embedding:   8%|▊         | 10/118 [00:07<01:24,  1.28it/s]update embedding:   9%|▉         | 11/118 [00:08<01:23,  1.28it/s]update embedding:  10%|█         | 12/118 [00:09<01:22,  1.28it/s]update embedding:  11%|█         | 13/118 [00:10<01:21,  1.29it/s]update embedding:  12%|█▏        | 14/118 [00:10<01:20,  1.29it/s]update embedding:  13%|█▎        | 15/118 [00:11<01:19,  1.29it/s]update embedding:  14%|█▎        | 16/118 [00:12<01:18,  1.29it/s]update embedding:  14%|█▍        | 17/118 [00:13<01:18,  1.29it/s]update embedding:  15%|█▌        | 18/118 [00:13<01:17,  1.29it/s]update embedding:  16%|█▌        | 19/118 [00:14<01:16,  1.30it/s]update embedding:  17%|█▋        | 20/118 [00:15<01:15,  1.30it/s]update embedding:  18%|█▊        | 21/118 [00:16<01:14,  1.30it/s]update embedding:  19%|█▊        | 22/118 [00:17<01:13,  1.30it/s]update embedding:  19%|█▉        | 23/118 [00:17<01:13,  1.29it/s]update embedding:  20%|██        | 24/118 [00:18<01:13,  1.28it/s]update embedding:  21%|██        | 25/118 [00:19<01:12,  1.28it/s]update embedding:  22%|██▏       | 26/118 [00:20<01:11,  1.28it/s]update embedding:  23%|██▎       | 27/118 [00:20<01:10,  1.29it/s]update embedding:  24%|██▎       | 28/118 [00:21<01:09,  1.29it/s]update embedding:  25%|██▍       | 29/118 [00:22<01:10,  1.27it/s]update embedding:  25%|██▌       | 30/118 [00:23<01:09,  1.27it/s]update embedding:  26%|██▋       | 31/118 [00:24<01:08,  1.28it/s]update embedding:  27%|██▋       | 32/118 [00:24<01:07,  1.28it/s]update embedding:  28%|██▊       | 33/118 [00:25<01:06,  1.28it/s]update embedding:  29%|██▉       | 34/118 [00:26<01:05,  1.29it/s]update embedding:  30%|██▉       | 35/118 [00:27<01:04,  1.28it/s]update embedding:  31%|███       | 36/118 [00:28<01:03,  1.29it/s]update embedding:  31%|███▏      | 37/118 [00:28<01:02,  1.29it/s]update embedding:  32%|███▏      | 38/118 [00:29<01:02,  1.29it/s]update embedding:  33%|███▎      | 39/118 [00:30<01:01,  1.29it/s]update embedding:  34%|███▍      | 40/118 [00:31<01:00,  1.29it/s]update embedding:  35%|███▍      | 41/118 [00:31<01:00,  1.28it/s]update embedding:  36%|███▌      | 42/118 [00:32<00:59,  1.28it/s]update embedding:  36%|███▋      | 43/118 [00:33<00:58,  1.28it/s]update embedding:  37%|███▋      | 44/118 [00:34<00:57,  1.28it/s]update embedding:  38%|███▊      | 45/118 [00:35<00:56,  1.28it/s]update embedding:  39%|███▉      | 46/118 [00:35<00:56,  1.28it/s]update embedding:  40%|███▉      | 47/118 [00:36<00:55,  1.28it/s]update embedding:  41%|████      | 48/118 [00:37<00:54,  1.27it/s]update embedding:  42%|████▏     | 49/118 [00:38<00:54,  1.27it/s]update embedding:  42%|████▏     | 50/118 [00:38<00:53,  1.27it/s]update embedding:  43%|████▎     | 51/118 [00:39<00:52,  1.28it/s]update embedding:  44%|████▍     | 52/118 [00:40<00:51,  1.28it/s]update embedding:  45%|████▍     | 53/118 [00:41<00:50,  1.28it/s]update embedding:  46%|████▌     | 54/118 [00:42<00:50,  1.28it/s]update embedding:  47%|████▋     | 55/118 [00:42<00:49,  1.27it/s]update embedding:  47%|████▋     | 56/118 [00:43<00:48,  1.27it/s]update embedding:  48%|████▊     | 57/118 [00:44<00:48,  1.27it/s]update embedding:  49%|████▉     | 58/118 [00:45<00:47,  1.27it/s]update embedding:  50%|█████     | 59/118 [00:45<00:46,  1.28it/s]update embedding:  51%|█████     | 60/118 [00:46<00:44,  1.31it/s]update embedding:  52%|█████▏    | 61/118 [00:47<00:44,  1.28it/s]update embedding:  53%|█████▎    | 62/118 [00:48<00:43,  1.28it/s]update embedding:  53%|█████▎    | 63/118 [00:49<00:43,  1.27it/s]update embedding:  54%|█████▍    | 64/118 [00:49<00:41,  1.30it/s]update embedding:  55%|█████▌    | 65/118 [00:50<00:42,  1.25it/s]update embedding:  56%|█████▌    | 66/118 [00:51<00:41,  1.25it/s]update embedding:  57%|█████▋    | 67/118 [00:52<00:41,  1.23it/s]update embedding:  58%|█████▊    | 68/118 [00:53<00:41,  1.21it/s]update embedding:  58%|█████▊    | 69/118 [00:54<00:40,  1.21it/s]update embedding:  59%|█████▉    | 70/118 [00:54<00:38,  1.23it/s]update embedding:  60%|██████    | 71/118 [00:55<00:38,  1.23it/s]update embedding:  61%|██████    | 72/118 [00:56<00:37,  1.23it/s]update embedding:  62%|██████▏   | 73/118 [00:57<00:35,  1.25it/s]update embedding:  63%|██████▎   | 74/118 [00:57<00:34,  1.26it/s]update embedding:  64%|██████▎   | 75/118 [00:58<00:35,  1.22it/s]update embedding:  64%|██████▍   | 76/118 [00:59<00:34,  1.22it/s]update embedding:  65%|██████▌   | 77/118 [01:00<00:33,  1.23it/s]update embedding:  66%|██████▌   | 78/118 [01:01<00:32,  1.23it/s]update embedding:  67%|██████▋   | 79/118 [01:02<00:32,  1.21it/s]update embedding:  68%|██████▊   | 80/118 [01:02<00:31,  1.23it/s]update embedding:  69%|██████▊   | 81/118 [01:03<00:30,  1.22it/s]update embedding:  69%|██████▉   | 82/118 [01:04<00:29,  1.23it/s]update embedding:  70%|███████   | 83/118 [01:05<00:28,  1.24it/s]update embedding:  71%|███████   | 84/118 [01:06<00:27,  1.25it/s]update embedding:  72%|███████▏  | 85/118 [01:06<00:26,  1.24it/s]update embedding:  73%|███████▎  | 86/118 [01:07<00:25,  1.24it/s]update embedding:  74%|███████▎  | 87/118 [01:08<00:24,  1.26it/s]update embedding:  75%|███████▍  | 88/118 [01:09<00:23,  1.27it/s]update embedding:  75%|███████▌  | 89/118 [01:10<00:23,  1.26it/s]update embedding:  76%|███████▋  | 90/118 [01:10<00:22,  1.25it/s]update embedding:  77%|███████▋  | 91/118 [01:11<00:21,  1.25it/s]update embedding:  78%|███████▊  | 92/118 [01:12<00:20,  1.26it/s]update embedding:  79%|███████▉  | 93/118 [01:13<00:19,  1.27it/s]update embedding:  80%|███████▉  | 94/118 [01:14<00:18,  1.27it/s]update embedding:  81%|████████  | 95/118 [01:14<00:18,  1.28it/s]update embedding:  81%|████████▏ | 96/118 [01:15<00:17,  1.28it/s]update embedding:  82%|████████▏ | 97/118 [01:16<00:16,  1.27it/s]update embedding:  83%|████████▎ | 98/118 [01:17<00:15,  1.26it/s]update embedding:  84%|████████▍ | 99/118 [01:18<00:15,  1.26it/s]update embedding:  85%|████████▍ | 100/118 [01:18<00:14,  1.26it/s]update embedding:  86%|████████▌ | 101/118 [01:19<00:13,  1.26it/s]update embedding:  86%|████████▋ | 102/118 [01:20<00:12,  1.27it/s]update embedding:  87%|████████▋ | 103/118 [01:21<00:11,  1.28it/s]update embedding:  88%|████████▊ | 104/118 [01:21<00:10,  1.28it/s]update embedding:  89%|████████▉ | 105/118 [01:22<00:10,  1.28it/s]update embedding:  90%|████████▉ | 106/118 [01:23<00:09,  1.28it/s]update embedding:  91%|█████████ | 107/118 [01:24<00:08,  1.28it/s]update embedding:  92%|█████████▏| 108/118 [01:25<00:07,  1.28it/s]update embedding:  92%|█████████▏| 109/118 [01:25<00:07,  1.27it/s]update embedding:  93%|█████████▎| 110/118 [01:26<00:06,  1.26it/s]update embedding:  94%|█████████▍| 111/118 [01:27<00:05,  1.26it/s]update embedding:  95%|█████████▍| 112/118 [01:28<00:04,  1.26it/s]update embedding:  96%|█████████▌| 113/118 [01:29<00:03,  1.27it/s]update embedding:  97%|█████████▋| 114/118 [01:29<00:03,  1.27it/s]update embedding:  97%|█████████▋| 115/118 [01:30<00:02,  1.27it/s]update embedding:  98%|█████████▊| 116/118 [01:31<00:01,  1.27it/s]update embedding:  99%|█████████▉| 117/118 [01:32<00:00,  1.27it/s]update embedding: 100%|██████████| 118/118 [01:32<00:00,  1.27it/s]update embedding: 100%|██████████| 118/118 [01:32<00:00,  1.27it/s]
retrival evaluation:   0%|          | 0/3481 [00:00<?, ?it/s]retrival evaluation:   0%|          | 7/3481 [00:00<00:54, 63.95it/s]retrival evaluation:   0%|          | 14/3481 [00:00<00:53, 65.28it/s]retrival evaluation:   1%|          | 21/3481 [00:00<00:52, 66.45it/s]retrival evaluation:   1%|          | 29/3481 [00:00<00:50, 68.21it/s]retrival evaluation:   1%|          | 37/3481 [00:00<00:48, 71.11it/s]retrival evaluation:   1%|▏         | 45/3481 [00:00<00:46, 73.50it/s]retrival evaluation:   2%|▏         | 53/3481 [00:00<00:45, 75.14it/s]retrival evaluation:   2%|▏         | 61/3481 [00:00<00:44, 76.48it/s]retrival evaluation:   2%|▏         | 70/3481 [00:00<00:43, 77.91it/s]retrival evaluation:   2%|▏         | 79/3481 [00:01<00:43, 78.70it/s]retrival evaluation:   3%|▎         | 88/3481 [00:01<00:42, 79.47it/s]retrival evaluation:   3%|▎         | 96/3481 [00:01<00:42, 79.61it/s]retrival evaluation:   3%|▎         | 105/3481 [00:01<00:42, 79.99it/s]retrival evaluation:   3%|▎         | 114/3481 [00:01<00:41, 80.51it/s]retrival evaluation:   4%|▎         | 123/3481 [00:01<00:41, 80.49it/s]retrival evaluation:   4%|▍         | 132/3481 [00:01<00:41, 80.52it/s]retrival evaluation:   4%|▍         | 141/3481 [00:01<00:41, 80.91it/s]retrival evaluation:   4%|▍         | 150/3481 [00:01<00:41, 81.09it/s]retrival evaluation:   5%|▍         | 159/3481 [00:02<00:41, 80.63it/s]retrival evaluation:   5%|▍         | 168/3481 [00:02<00:41, 80.60it/s]retrival evaluation:   5%|▌         | 177/3481 [00:02<00:40, 80.73it/s]retrival evaluation:   5%|▌         | 186/3481 [00:02<00:40, 80.48it/s]retrival evaluation:   6%|▌         | 195/3481 [00:02<00:40, 80.56it/s]retrival evaluation:   6%|▌         | 204/3481 [00:02<00:40, 80.14it/s]retrival evaluation:   6%|▌         | 213/3481 [00:02<00:40, 79.94it/s]retrival evaluation:   6%|▋         | 222/3481 [00:02<00:40, 80.08it/s]retrival evaluation:   7%|▋         | 231/3481 [00:02<00:40, 80.06it/s]retrival evaluation:   7%|▋         | 240/3481 [00:03<00:40, 80.35it/s]retrival evaluation:   7%|▋         | 249/3481 [00:03<00:40, 80.37it/s]retrival evaluation:   7%|▋         | 258/3481 [00:03<00:39, 80.58it/s]retrival evaluation:   8%|▊         | 267/3481 [00:03<00:39, 80.37it/s]retrival evaluation:   8%|▊         | 276/3481 [00:03<00:40, 79.91it/s]retrival evaluation:   8%|▊         | 284/3481 [00:03<00:40, 79.88it/s]retrival evaluation:   8%|▊         | 293/3481 [00:03<00:39, 80.03it/s]retrival evaluation:   9%|▊         | 302/3481 [00:03<00:39, 79.64it/s]retrival evaluation:   9%|▉         | 311/3481 [00:03<00:39, 80.01it/s]retrival evaluation:   9%|▉         | 320/3481 [00:04<00:39, 80.02it/s]retrival evaluation:   9%|▉         | 329/3481 [00:04<00:39, 79.95it/s]retrival evaluation:  10%|▉         | 337/3481 [00:04<00:39, 79.96it/s]retrival evaluation:  10%|▉         | 345/3481 [00:04<00:39, 79.90it/s]retrival evaluation:  10%|█         | 354/3481 [00:04<00:39, 80.08it/s]retrival evaluation:  10%|█         | 363/3481 [00:04<00:38, 80.18it/s]retrival evaluation:  11%|█         | 372/3481 [00:04<00:38, 80.17it/s]retrival evaluation:  11%|█         | 381/3481 [00:04<00:38, 80.33it/s]retrival evaluation:  11%|█         | 390/3481 [00:04<00:38, 80.63it/s]retrival evaluation:  11%|█▏        | 399/3481 [00:05<00:38, 80.56it/s]retrival evaluation:  12%|█▏        | 408/3481 [00:05<00:38, 80.59it/s]retrival evaluation:  12%|█▏        | 417/3481 [00:05<00:38, 80.53it/s]retrival evaluation:  12%|█▏        | 426/3481 [00:05<00:37, 80.52it/s]retrival evaluation:  12%|█▏        | 435/3481 [00:05<00:37, 80.74it/s]retrival evaluation:  13%|█▎        | 444/3481 [00:05<00:37, 80.60it/s]retrival evaluation:  13%|█▎        | 453/3481 [00:05<00:37, 80.83it/s]retrival evaluation:  13%|█▎        | 462/3481 [00:05<00:37, 80.80it/s]retrival evaluation:  14%|█▎        | 471/3481 [00:05<00:37, 80.78it/s]retrival evaluation:  14%|█▍        | 480/3481 [00:06<00:37, 80.61it/s]retrival evaluation:  14%|█▍        | 489/3481 [00:06<00:37, 80.13it/s]retrival evaluation:  14%|█▍        | 498/3481 [00:06<00:37, 79.88it/s]retrival evaluation:  15%|█▍        | 506/3481 [00:06<00:37, 79.70it/s]retrival evaluation:  15%|█▍        | 515/3481 [00:06<00:37, 79.87it/s]retrival evaluation:  15%|█▌        | 523/3481 [00:06<00:37, 79.81it/s]retrival evaluation:  15%|█▌        | 532/3481 [00:06<00:36, 79.75it/s]retrival evaluation:  16%|█▌        | 541/3481 [00:06<00:36, 80.12it/s]retrival evaluation:  16%|█▌        | 550/3481 [00:06<00:36, 80.05it/s]retrival evaluation:  16%|█▌        | 559/3481 [00:07<00:36, 80.21it/s]retrival evaluation:  16%|█▋        | 568/3481 [00:07<00:36, 80.37it/s]retrival evaluation:  17%|█▋        | 577/3481 [00:07<00:36, 80.32it/s]retrival evaluation:  17%|█▋        | 586/3481 [00:07<00:36, 79.54it/s]retrival evaluation:  17%|█▋        | 594/3481 [00:07<00:36, 79.28it/s]retrival evaluation:  17%|█▋        | 603/3481 [00:07<00:35, 80.25it/s]retrival evaluation:  18%|█▊        | 612/3481 [00:07<00:35, 80.85it/s]retrival evaluation:  18%|█▊        | 621/3481 [00:07<00:35, 81.04it/s]retrival evaluation:  18%|█▊        | 630/3481 [00:07<00:35, 81.29it/s]retrival evaluation:  18%|█▊        | 639/3481 [00:08<00:34, 81.62it/s]retrival evaluation:  19%|█▊        | 648/3481 [00:08<00:34, 81.81it/s]retrival evaluation:  19%|█▉        | 657/3481 [00:08<00:36, 77.49it/s]retrival evaluation:  19%|█▉        | 665/3481 [00:08<00:37, 75.96it/s]retrival evaluation:  19%|█▉        | 673/3481 [00:08<00:37, 75.04it/s]retrival evaluation:  20%|█▉        | 682/3481 [00:08<00:36, 76.42it/s]retrival evaluation:  20%|█▉        | 691/3481 [00:08<00:35, 77.80it/s]retrival evaluation:  20%|██        | 700/3481 [00:08<00:35, 78.87it/s]retrival evaluation:  20%|██        | 709/3481 [00:08<00:34, 79.55it/s]retrival evaluation:  21%|██        | 717/3481 [00:09<00:34, 79.15it/s]retrival evaluation:  21%|██        | 726/3481 [00:09<00:34, 79.99it/s]retrival evaluation:  21%|██        | 735/3481 [00:09<00:36, 75.53it/s]retrival evaluation:  21%|██▏       | 743/3481 [00:09<00:36, 75.01it/s]retrival evaluation:  22%|██▏       | 752/3481 [00:09<00:35, 76.52it/s]retrival evaluation:  22%|██▏       | 760/3481 [00:09<00:35, 75.68it/s]retrival evaluation:  22%|██▏       | 769/3481 [00:09<00:35, 77.09it/s]retrival evaluation:  22%|██▏       | 777/3481 [00:09<00:34, 77.32it/s]retrival evaluation:  23%|██▎       | 785/3481 [00:09<00:35, 76.48it/s]retrival evaluation:  23%|██▎       | 794/3481 [00:10<00:34, 77.99it/s]retrival evaluation:  23%|██▎       | 802/3481 [00:10<00:35, 75.24it/s]retrival evaluation:  23%|██▎       | 810/3481 [00:10<00:34, 76.33it/s]retrival evaluation:  23%|██▎       | 818/3481 [00:10<00:34, 77.01it/s]retrival evaluation:  24%|██▎       | 826/3481 [00:10<00:34, 77.40it/s]retrival evaluation:  24%|██▍       | 834/3481 [00:10<00:34, 77.80it/s]retrival evaluation:  24%|██▍       | 842/3481 [00:10<00:34, 77.50it/s]retrival evaluation:  24%|██▍       | 850/3481 [00:10<00:34, 76.89it/s]retrival evaluation:  25%|██▍       | 858/3481 [00:10<00:34, 75.22it/s]retrival evaluation:  25%|██▍       | 867/3481 [00:10<00:33, 77.01it/s]retrival evaluation:  25%|██▌       | 876/3481 [00:11<00:33, 78.20it/s]retrival evaluation:  25%|██▌       | 885/3481 [00:11<00:32, 79.22it/s]retrival evaluation:  26%|██▌       | 893/3481 [00:11<00:33, 76.55it/s]retrival evaluation:  26%|██▌       | 901/3481 [00:11<00:33, 77.37it/s]retrival evaluation:  26%|██▌       | 909/3481 [00:11<00:33, 77.79it/s]retrival evaluation:  26%|██▋       | 918/3481 [00:11<00:32, 78.62it/s]retrival evaluation:  27%|██▋       | 926/3481 [00:11<00:33, 76.42it/s]retrival evaluation:  27%|██▋       | 934/3481 [00:11<00:33, 75.87it/s]retrival evaluation:  27%|██▋       | 943/3481 [00:11<00:32, 77.14it/s]retrival evaluation:  27%|██▋       | 951/3481 [00:12<00:32, 77.17it/s]retrival evaluation:  28%|██▊       | 959/3481 [00:12<00:35, 70.52it/s]retrival evaluation:  28%|██▊       | 967/3481 [00:12<00:35, 71.69it/s]retrival evaluation:  28%|██▊       | 975/3481 [00:12<00:35, 71.48it/s]retrival evaluation:  28%|██▊       | 983/3481 [00:12<00:34, 71.84it/s]retrival evaluation:  28%|██▊       | 991/3481 [00:12<00:33, 73.60it/s]retrival evaluation:  29%|██▊       | 999/3481 [00:12<00:33, 74.87it/s]retrival evaluation:  29%|██▉       | 1007/3481 [00:12<00:33, 73.36it/s]retrival evaluation:  29%|██▉       | 1015/3481 [00:12<00:32, 74.73it/s]retrival evaluation:  29%|██▉       | 1023/3481 [00:13<00:32, 75.61it/s]retrival evaluation:  30%|██▉       | 1031/3481 [00:13<00:32, 76.40it/s]retrival evaluation:  30%|██▉       | 1039/3481 [00:13<00:31, 76.85it/s]retrival evaluation:  30%|███       | 1047/3481 [00:13<00:31, 76.27it/s]retrival evaluation:  30%|███       | 1055/3481 [00:13<00:32, 73.92it/s]retrival evaluation:  31%|███       | 1063/3481 [00:13<00:33, 72.21it/s]retrival evaluation:  31%|███       | 1071/3481 [00:13<00:33, 71.40it/s]retrival evaluation:  31%|███       | 1079/3481 [00:13<00:33, 70.83it/s]retrival evaluation:  31%|███       | 1087/3481 [00:13<00:33, 71.88it/s]retrival evaluation:  31%|███▏      | 1095/3481 [00:14<00:32, 73.89it/s]retrival evaluation:  32%|███▏      | 1103/3481 [00:14<00:31, 75.47it/s]retrival evaluation:  32%|███▏      | 1111/3481 [00:14<00:31, 76.12it/s]retrival evaluation:  32%|███▏      | 1119/3481 [00:14<00:30, 77.04it/s]retrival evaluation:  32%|███▏      | 1127/3481 [00:14<00:31, 75.58it/s]retrival evaluation:  33%|███▎      | 1135/3481 [00:14<00:30, 76.69it/s]retrival evaluation:  33%|███▎      | 1143/3481 [00:14<00:30, 77.00it/s]retrival evaluation:  33%|███▎      | 1151/3481 [00:14<00:31, 73.37it/s]retrival evaluation:  33%|███▎      | 1159/3481 [00:14<00:30, 75.05it/s]retrival evaluation:  34%|███▎      | 1167/3481 [00:14<00:30, 75.81it/s]retrival evaluation:  34%|███▍      | 1175/3481 [00:15<00:30, 74.72it/s]retrival evaluation:  34%|███▍      | 1183/3481 [00:15<00:30, 76.00it/s]retrival evaluation:  34%|███▍      | 1191/3481 [00:15<00:29, 76.59it/s]retrival evaluation:  34%|███▍      | 1199/3481 [00:15<00:29, 77.02it/s]retrival evaluation:  35%|███▍      | 1207/3481 [00:15<00:29, 77.81it/s]retrival evaluation:  35%|███▍      | 1215/3481 [00:15<00:29, 76.50it/s]retrival evaluation:  35%|███▌      | 1223/3481 [00:15<00:29, 75.62it/s]retrival evaluation:  35%|███▌      | 1231/3481 [00:15<00:29, 76.24it/s]retrival evaluation:  36%|███▌      | 1239/3481 [00:15<00:29, 76.90it/s]retrival evaluation:  36%|███▌      | 1247/3481 [00:16<00:29, 76.38it/s]retrival evaluation:  36%|███▌      | 1255/3481 [00:16<00:29, 74.49it/s]retrival evaluation:  36%|███▋      | 1263/3481 [00:16<00:29, 75.46it/s]retrival evaluation:  37%|███▋      | 1271/3481 [00:16<00:28, 76.39it/s]retrival evaluation:  37%|███▋      | 1279/3481 [00:16<00:29, 75.68it/s]retrival evaluation:  37%|███▋      | 1287/3481 [00:16<00:28, 76.53it/s]retrival evaluation:  37%|███▋      | 1295/3481 [00:16<00:28, 76.74it/s]retrival evaluation:  37%|███▋      | 1303/3481 [00:16<00:28, 77.47it/s]retrival evaluation:  38%|███▊      | 1312/3481 [00:16<00:27, 78.37it/s]retrival evaluation:  38%|███▊      | 1320/3481 [00:16<00:27, 78.56it/s]retrival evaluation:  38%|███▊      | 1328/3481 [00:17<00:29, 74.23it/s]retrival evaluation:  38%|███▊      | 1337/3481 [00:17<00:28, 76.07it/s]retrival evaluation:  39%|███▊      | 1346/3481 [00:17<00:27, 77.22it/s]retrival evaluation:  39%|███▉      | 1354/3481 [00:17<00:27, 76.33it/s]retrival evaluation:  39%|███▉      | 1362/3481 [00:17<00:28, 75.19it/s]retrival evaluation:  39%|███▉      | 1371/3481 [00:17<00:27, 76.61it/s]retrival evaluation:  40%|███▉      | 1379/3481 [00:17<00:27, 77.29it/s]retrival evaluation:  40%|███▉      | 1388/3481 [00:17<00:26, 78.19it/s]retrival evaluation:  40%|████      | 1396/3481 [00:17<00:26, 78.67it/s]retrival evaluation:  40%|████      | 1404/3481 [00:18<00:26, 76.98it/s]retrival evaluation:  41%|████      | 1412/3481 [00:18<00:26, 77.39it/s]retrival evaluation:  41%|████      | 1420/3481 [00:18<00:26, 77.88it/s]retrival evaluation:  41%|████      | 1428/3481 [00:18<00:26, 78.29it/s]retrival evaluation:  41%|████▏     | 1436/3481 [00:18<00:26, 78.28it/s]retrival evaluation:  41%|████▏     | 1444/3481 [00:18<00:25, 78.55it/s]retrival evaluation:  42%|████▏     | 1452/3481 [00:18<00:26, 76.73it/s]retrival evaluation:  42%|████▏     | 1460/3481 [00:18<00:26, 76.02it/s]retrival evaluation:  42%|████▏     | 1468/3481 [00:18<00:26, 76.31it/s]retrival evaluation:  42%|████▏     | 1476/3481 [00:18<00:26, 76.75it/s]retrival evaluation:  43%|████▎     | 1484/3481 [00:19<00:26, 76.68it/s]retrival evaluation:  43%|████▎     | 1492/3481 [00:19<00:26, 75.86it/s]retrival evaluation:  43%|████▎     | 1501/3481 [00:19<00:25, 77.06it/s]retrival evaluation:  43%|████▎     | 1509/3481 [00:19<00:25, 77.57it/s]retrival evaluation:  44%|████▎     | 1517/3481 [00:19<00:25, 76.93it/s]retrival evaluation:  44%|████▍     | 1525/3481 [00:19<00:25, 77.23it/s]retrival evaluation:  44%|████▍     | 1533/3481 [00:19<00:25, 77.84it/s]retrival evaluation:  44%|████▍     | 1541/3481 [00:19<00:24, 78.39it/s]retrival evaluation:  44%|████▍     | 1549/3481 [00:19<00:25, 77.21it/s]retrival evaluation:  45%|████▍     | 1557/3481 [00:20<00:24, 77.01it/s]retrival evaluation:  45%|████▍     | 1565/3481 [00:20<00:24, 77.32it/s]retrival evaluation:  45%|████▌     | 1573/3481 [00:20<00:24, 77.96it/s]retrival evaluation:  45%|████▌     | 1581/3481 [00:20<00:24, 78.51it/s]retrival evaluation:  46%|████▌     | 1589/3481 [00:20<00:24, 78.50it/s]retrival evaluation:  46%|████▌     | 1597/3481 [00:20<00:24, 78.39it/s]retrival evaluation:  46%|████▌     | 1605/3481 [00:20<00:23, 78.36it/s]retrival evaluation:  46%|████▋     | 1613/3481 [00:20<00:23, 78.56it/s]retrival evaluation:  47%|████▋     | 1621/3481 [00:20<00:24, 75.14it/s]retrival evaluation:  47%|████▋     | 1629/3481 [00:20<00:24, 75.87it/s]retrival evaluation:  47%|████▋     | 1637/3481 [00:21<00:23, 76.87it/s]retrival evaluation:  47%|████▋     | 1645/3481 [00:21<00:23, 76.69it/s]retrival evaluation:  47%|████▋     | 1653/3481 [00:21<00:23, 77.13it/s]retrival evaluation:  48%|████▊     | 1661/3481 [00:21<00:23, 77.88it/s]retrival evaluation:  48%|████▊     | 1670/3481 [00:21<00:23, 78.57it/s]retrival evaluation:  48%|████▊     | 1678/3481 [00:21<00:23, 78.26it/s]retrival evaluation:  48%|████▊     | 1686/3481 [00:21<00:22, 78.50it/s]retrival evaluation:  49%|████▊     | 1695/3481 [00:21<00:22, 79.55it/s]retrival evaluation:  49%|████▉     | 1704/3481 [00:21<00:22, 80.31it/s]retrival evaluation:  49%|████▉     | 1713/3481 [00:22<00:21, 80.73it/s]retrival evaluation:  49%|████▉     | 1722/3481 [00:22<00:21, 80.82it/s]retrival evaluation:  50%|████▉     | 1731/3481 [00:22<00:21, 80.64it/s]retrival evaluation:  50%|████▉     | 1740/3481 [00:22<00:21, 81.09it/s]retrival evaluation:  50%|█████     | 1749/3481 [00:22<00:21, 79.39it/s]retrival evaluation:  51%|█████     | 1758/3481 [00:22<00:21, 79.68it/s]retrival evaluation:  51%|█████     | 1767/3481 [00:22<00:21, 80.15it/s]retrival evaluation:  51%|█████     | 1776/3481 [00:22<00:21, 79.49it/s]retrival evaluation:  51%|█████▏    | 1785/3481 [00:22<00:21, 80.19it/s]retrival evaluation:  52%|█████▏    | 1794/3481 [00:23<00:20, 80.52it/s]retrival evaluation:  52%|█████▏    | 1803/3481 [00:23<00:20, 80.15it/s]retrival evaluation:  52%|█████▏    | 1812/3481 [00:23<00:20, 80.05it/s]retrival evaluation:  52%|█████▏    | 1821/3481 [00:23<00:20, 79.66it/s]retrival evaluation:  53%|█████▎    | 1830/3481 [00:23<00:20, 79.97it/s]retrival evaluation:  53%|█████▎    | 1838/3481 [00:23<00:21, 77.59it/s]retrival evaluation:  53%|█████▎    | 1847/3481 [00:23<00:20, 78.37it/s]retrival evaluation:  53%|█████▎    | 1855/3481 [00:23<00:20, 78.81it/s]retrival evaluation:  54%|█████▎    | 1864/3481 [00:23<00:20, 79.62it/s]retrival evaluation:  54%|█████▍    | 1872/3481 [00:24<00:20, 79.71it/s]retrival evaluation:  54%|█████▍    | 1880/3481 [00:24<00:20, 79.52it/s]retrival evaluation:  54%|█████▍    | 1889/3481 [00:24<00:19, 79.97it/s]retrival evaluation:  55%|█████▍    | 1898/3481 [00:24<00:19, 80.10it/s]retrival evaluation:  55%|█████▍    | 1907/3481 [00:24<00:20, 77.81it/s]retrival evaluation:  55%|█████▌    | 1916/3481 [00:24<00:19, 78.92it/s]retrival evaluation:  55%|█████▌    | 1925/3481 [00:24<00:19, 79.37it/s]retrival evaluation:  56%|█████▌    | 1934/3481 [00:24<00:19, 79.75it/s]retrival evaluation:  56%|█████▌    | 1943/3481 [00:24<00:19, 80.03it/s]retrival evaluation:  56%|█████▌    | 1952/3481 [00:25<00:19, 80.36it/s]retrival evaluation:  56%|█████▋    | 1961/3481 [00:25<00:18, 80.79it/s]retrival evaluation:  57%|█████▋    | 1970/3481 [00:25<00:18, 81.05it/s]retrival evaluation:  57%|█████▋    | 1979/3481 [00:25<00:18, 79.49it/s]retrival evaluation:  57%|█████▋    | 1988/3481 [00:25<00:18, 79.94it/s]retrival evaluation:  57%|█████▋    | 1997/3481 [00:25<00:18, 79.53it/s]retrival evaluation:  58%|█████▊    | 2006/3481 [00:25<00:18, 79.75it/s]retrival evaluation:  58%|█████▊    | 2015/3481 [00:25<00:18, 79.98it/s]retrival evaluation:  58%|█████▊    | 2024/3481 [00:25<00:18, 79.68it/s]retrival evaluation:  58%|█████▊    | 2033/3481 [00:26<00:18, 79.97it/s]retrival evaluation:  59%|█████▊    | 2041/3481 [00:26<00:18, 79.78it/s]retrival evaluation:  59%|█████▉    | 2049/3481 [00:26<00:17, 79.78it/s]retrival evaluation:  59%|█████▉    | 2057/3481 [00:26<00:17, 79.65it/s]retrival evaluation:  59%|█████▉    | 2066/3481 [00:26<00:17, 79.80it/s]retrival evaluation:  60%|█████▉    | 2074/3481 [00:26<00:17, 79.60it/s]retrival evaluation:  60%|█████▉    | 2082/3481 [00:26<00:17, 78.24it/s]retrival evaluation:  60%|██████    | 2090/3481 [00:26<00:18, 76.87it/s]retrival evaluation:  60%|██████    | 2098/3481 [00:26<00:18, 75.97it/s]retrival evaluation:  60%|██████    | 2106/3481 [00:26<00:17, 76.82it/s]retrival evaluation:  61%|██████    | 2114/3481 [00:27<00:17, 77.49it/s]retrival evaluation:  61%|██████    | 2122/3481 [00:27<00:17, 78.03it/s]retrival evaluation:  61%|██████    | 2130/3481 [00:27<00:17, 78.09it/s]retrival evaluation:  61%|██████▏   | 2138/3481 [00:27<00:17, 78.35it/s]retrival evaluation:  62%|██████▏   | 2146/3481 [00:27<00:16, 78.59it/s]retrival evaluation:  62%|██████▏   | 2154/3481 [00:27<00:16, 78.68it/s]retrival evaluation:  62%|██████▏   | 2162/3481 [00:27<00:16, 78.95it/s]retrival evaluation:  62%|██████▏   | 2171/3481 [00:27<00:16, 79.29it/s]retrival evaluation:  63%|██████▎   | 2179/3481 [00:27<00:16, 77.36it/s]retrival evaluation:  63%|██████▎   | 2188/3481 [00:28<00:16, 78.05it/s]retrival evaluation:  63%|██████▎   | 2197/3481 [00:28<00:16, 78.60it/s]retrival evaluation:  63%|██████▎   | 2205/3481 [00:28<00:16, 78.67it/s]retrival evaluation:  64%|██████▎   | 2214/3481 [00:28<00:16, 79.01it/s]retrival evaluation:  64%|██████▍   | 2223/3481 [00:28<00:15, 79.32it/s]retrival evaluation:  64%|██████▍   | 2231/3481 [00:28<00:15, 79.36it/s]retrival evaluation:  64%|██████▍   | 2240/3481 [00:28<00:15, 79.87it/s]retrival evaluation:  65%|██████▍   | 2248/3481 [00:28<00:15, 79.89it/s]retrival evaluation:  65%|██████▍   | 2257/3481 [00:28<00:15, 80.16it/s]retrival evaluation:  65%|██████▌   | 2266/3481 [00:29<00:15, 79.52it/s]retrival evaluation:  65%|██████▌   | 2274/3481 [00:29<00:15, 77.30it/s]retrival evaluation:  66%|██████▌   | 2282/3481 [00:29<00:15, 77.97it/s]retrival evaluation:  66%|██████▌   | 2290/3481 [00:29<00:15, 78.07it/s]retrival evaluation:  66%|██████▌   | 2298/3481 [00:29<00:15, 78.06it/s]retrival evaluation:  66%|██████▌   | 2306/3481 [00:29<00:15, 78.14it/s]retrival evaluation:  66%|██████▋   | 2314/3481 [00:29<00:14, 78.62it/s]retrival evaluation:  67%|██████▋   | 2322/3481 [00:29<00:14, 78.87it/s]retrival evaluation:  67%|██████▋   | 2330/3481 [00:29<00:14, 79.17it/s]retrival evaluation:  67%|██████▋   | 2338/3481 [00:29<00:14, 79.14it/s]retrival evaluation:  67%|██████▋   | 2346/3481 [00:30<00:14, 79.36it/s]retrival evaluation:  68%|██████▊   | 2355/3481 [00:30<00:14, 79.88it/s]retrival evaluation:  68%|██████▊   | 2363/3481 [00:30<00:14, 79.72it/s]retrival evaluation:  68%|██████▊   | 2372/3481 [00:30<00:13, 80.13it/s]retrival evaluation:  68%|██████▊   | 2381/3481 [00:30<00:13, 79.68it/s]retrival evaluation:  69%|██████▊   | 2390/3481 [00:30<00:13, 79.67it/s]retrival evaluation:  69%|██████▉   | 2398/3481 [00:30<00:14, 77.16it/s]retrival evaluation:  69%|██████▉   | 2406/3481 [00:30<00:13, 77.55it/s]retrival evaluation:  69%|██████▉   | 2414/3481 [00:30<00:13, 77.88it/s]retrival evaluation:  70%|██████▉   | 2423/3481 [00:31<00:13, 78.75it/s]retrival evaluation:  70%|██████▉   | 2432/3481 [00:31<00:13, 79.19it/s]retrival evaluation:  70%|███████   | 2440/3481 [00:31<00:13, 79.00it/s]retrival evaluation:  70%|███████   | 2448/3481 [00:31<00:13, 78.91it/s]retrival evaluation:  71%|███████   | 2456/3481 [00:31<00:13, 78.73it/s]retrival evaluation:  71%|███████   | 2464/3481 [00:31<00:13, 77.91it/s]retrival evaluation:  71%|███████   | 2472/3481 [00:31<00:13, 76.52it/s]retrival evaluation:  71%|███████   | 2480/3481 [00:31<00:13, 71.67it/s]retrival evaluation:  71%|███████▏  | 2488/3481 [00:31<00:13, 73.77it/s]retrival evaluation:  72%|███████▏  | 2496/3481 [00:31<00:13, 72.33it/s]retrival evaluation:  72%|███████▏  | 2504/3481 [00:32<00:13, 73.89it/s]retrival evaluation:  72%|███████▏  | 2512/3481 [00:32<00:12, 75.43it/s]retrival evaluation:  72%|███████▏  | 2521/3481 [00:32<00:12, 76.86it/s]retrival evaluation:  73%|███████▎  | 2530/3481 [00:32<00:12, 77.65it/s]retrival evaluation:  73%|███████▎  | 2538/3481 [00:32<00:12, 78.09it/s]retrival evaluation:  73%|███████▎  | 2546/3481 [00:32<00:11, 78.48it/s]retrival evaluation:  73%|███████▎  | 2554/3481 [00:32<00:11, 78.45it/s]retrival evaluation:  74%|███████▎  | 2562/3481 [00:32<00:11, 78.87it/s]retrival evaluation:  74%|███████▍  | 2571/3481 [00:32<00:11, 79.08it/s]retrival evaluation:  74%|███████▍  | 2580/3481 [00:33<00:11, 79.37it/s]retrival evaluation:  74%|███████▍  | 2588/3481 [00:33<00:11, 79.09it/s]retrival evaluation:  75%|███████▍  | 2597/3481 [00:33<00:11, 79.40it/s]retrival evaluation:  75%|███████▍  | 2606/3481 [00:33<00:10, 79.70it/s]retrival evaluation:  75%|███████▌  | 2615/3481 [00:33<00:10, 80.06it/s]retrival evaluation:  75%|███████▌  | 2624/3481 [00:33<00:10, 78.32it/s]retrival evaluation:  76%|███████▌  | 2632/3481 [00:33<00:10, 78.50it/s]retrival evaluation:  76%|███████▌  | 2641/3481 [00:33<00:10, 79.20it/s]retrival evaluation:  76%|███████▌  | 2649/3481 [00:33<00:10, 78.72it/s]retrival evaluation:  76%|███████▋  | 2658/3481 [00:34<00:10, 79.15it/s]retrival evaluation:  77%|███████▋  | 2666/3481 [00:34<00:10, 79.26it/s]retrival evaluation:  77%|███████▋  | 2675/3481 [00:34<00:10, 79.71it/s]retrival evaluation:  77%|███████▋  | 2684/3481 [00:34<00:09, 79.86it/s]retrival evaluation:  77%|███████▋  | 2692/3481 [00:34<00:09, 79.65it/s]retrival evaluation:  78%|███████▊  | 2700/3481 [00:34<00:09, 79.70it/s]retrival evaluation:  78%|███████▊  | 2709/3481 [00:34<00:09, 79.93it/s]retrival evaluation:  78%|███████▊  | 2717/3481 [00:34<00:09, 79.71it/s]retrival evaluation:  78%|███████▊  | 2726/3481 [00:34<00:09, 79.85it/s]retrival evaluation:  79%|███████▊  | 2734/3481 [00:34<00:09, 79.71it/s]retrival evaluation:  79%|███████▉  | 2742/3481 [00:35<00:09, 79.57it/s]retrival evaluation:  79%|███████▉  | 2750/3481 [00:35<00:09, 79.53it/s]retrival evaluation:  79%|███████▉  | 2759/3481 [00:35<00:09, 79.78it/s]retrival evaluation:  80%|███████▉  | 2768/3481 [00:35<00:08, 80.06it/s]retrival evaluation:  80%|███████▉  | 2777/3481 [00:35<00:08, 79.75it/s]retrival evaluation:  80%|████████  | 2785/3481 [00:35<00:08, 77.90it/s]retrival evaluation:  80%|████████  | 2793/3481 [00:35<00:08, 78.01it/s]retrival evaluation:  80%|████████  | 2801/3481 [00:35<00:08, 75.71it/s]retrival evaluation:  81%|████████  | 2809/3481 [00:35<00:08, 76.06it/s]retrival evaluation:  81%|████████  | 2817/3481 [00:36<00:08, 77.03it/s]retrival evaluation:  81%|████████  | 2825/3481 [00:36<00:08, 77.76it/s]retrival evaluation:  81%|████████▏ | 2833/3481 [00:36<00:08, 78.38it/s]retrival evaluation:  82%|████████▏ | 2841/3481 [00:36<00:08, 78.72it/s]retrival evaluation:  82%|████████▏ | 2850/3481 [00:36<00:07, 79.21it/s]retrival evaluation:  82%|████████▏ | 2858/3481 [00:36<00:07, 78.61it/s]retrival evaluation:  82%|████████▏ | 2867/3481 [00:36<00:07, 79.09it/s]retrival evaluation:  83%|████████▎ | 2876/3481 [00:36<00:07, 79.43it/s]retrival evaluation:  83%|████████▎ | 2885/3481 [00:36<00:07, 79.79it/s]retrival evaluation:  83%|████████▎ | 2893/3481 [00:36<00:07, 79.63it/s]retrival evaluation:  83%|████████▎ | 2902/3481 [00:37<00:07, 79.84it/s]retrival evaluation:  84%|████████▎ | 2911/3481 [00:37<00:07, 80.19it/s]retrival evaluation:  84%|████████▍ | 2920/3481 [00:37<00:06, 80.17it/s]retrival evaluation:  84%|████████▍ | 2929/3481 [00:37<00:07, 72.66it/s]retrival evaluation:  84%|████████▍ | 2937/3481 [00:37<00:07, 68.88it/s]retrival evaluation:  85%|████████▍ | 2945/3481 [00:37<00:07, 71.09it/s]retrival evaluation:  85%|████████▍ | 2953/3481 [00:37<00:07, 73.27it/s]retrival evaluation:  85%|████████▌ | 2961/3481 [00:37<00:07, 73.81it/s]retrival evaluation:  85%|████████▌ | 2969/3481 [00:38<00:06, 74.39it/s]retrival evaluation:  86%|████████▌ | 2977/3481 [00:38<00:06, 75.03it/s]retrival evaluation:  86%|████████▌ | 2985/3481 [00:38<00:06, 72.31it/s]retrival evaluation:  86%|████████▌ | 2993/3481 [00:38<00:06, 71.49it/s]retrival evaluation:  86%|████████▌ | 3001/3481 [00:38<00:06, 71.53it/s]retrival evaluation:  86%|████████▋ | 3009/3481 [00:38<00:06, 71.06it/s]retrival evaluation:  87%|████████▋ | 3018/3481 [00:38<00:06, 73.59it/s]retrival evaluation:  87%|████████▋ | 3026/3481 [00:38<00:06, 73.39it/s]retrival evaluation:  87%|████████▋ | 3034/3481 [00:38<00:06, 73.16it/s]retrival evaluation:  87%|████████▋ | 3042/3481 [00:39<00:06, 72.82it/s]retrival evaluation:  88%|████████▊ | 3050/3481 [00:39<00:05, 74.23it/s]retrival evaluation:  88%|████████▊ | 3058/3481 [00:39<00:05, 75.00it/s]retrival evaluation:  88%|████████▊ | 3066/3481 [00:39<00:05, 75.23it/s]retrival evaluation:  88%|████████▊ | 3074/3481 [00:39<00:05, 73.59it/s]retrival evaluation:  89%|████████▊ | 3082/3481 [00:39<00:05, 72.10it/s]retrival evaluation:  89%|████████▉ | 3090/3481 [00:39<00:05, 72.66it/s]retrival evaluation:  89%|████████▉ | 3098/3481 [00:39<00:05, 72.36it/s]retrival evaluation:  89%|████████▉ | 3106/3481 [00:39<00:05, 74.14it/s]retrival evaluation:  89%|████████▉ | 3114/3481 [00:40<00:04, 75.37it/s]retrival evaluation:  90%|████████▉ | 3122/3481 [00:40<00:04, 75.67it/s]retrival evaluation:  90%|████████▉ | 3130/3481 [00:40<00:04, 75.15it/s]retrival evaluation:  90%|█████████ | 3138/3481 [00:40<00:04, 75.18it/s]retrival evaluation:  90%|█████████ | 3146/3481 [00:40<00:04, 76.37it/s]retrival evaluation:  91%|█████████ | 3154/3481 [00:40<00:04, 74.91it/s]retrival evaluation:  91%|█████████ | 3162/3481 [00:40<00:04, 73.70it/s]retrival evaluation:  91%|█████████ | 3170/3481 [00:40<00:04, 75.09it/s]retrival evaluation:  91%|█████████▏| 3178/3481 [00:40<00:03, 76.33it/s]retrival evaluation:  92%|█████████▏| 3186/3481 [00:40<00:03, 75.50it/s]retrival evaluation:  92%|█████████▏| 3194/3481 [00:41<00:03, 76.31it/s]retrival evaluation:  92%|█████████▏| 3202/3481 [00:41<00:03, 76.54it/s]retrival evaluation:  92%|█████████▏| 3210/3481 [00:41<00:03, 77.13it/s]retrival evaluation:  92%|█████████▏| 3218/3481 [00:41<00:03, 76.88it/s]retrival evaluation:  93%|█████████▎| 3226/3481 [00:41<00:03, 74.95it/s]retrival evaluation:  93%|█████████▎| 3234/3481 [00:41<00:03, 76.07it/s]retrival evaluation:  93%|█████████▎| 3243/3481 [00:41<00:03, 77.38it/s]retrival evaluation:  93%|█████████▎| 3251/3481 [00:41<00:02, 77.15it/s]retrival evaluation:  94%|█████████▎| 3259/3481 [00:41<00:02, 76.37it/s]retrival evaluation:  94%|█████████▍| 3267/3481 [00:42<00:02, 76.64it/s]retrival evaluation:  94%|█████████▍| 3275/3481 [00:42<00:02, 77.24it/s]retrival evaluation:  94%|█████████▍| 3283/3481 [00:42<00:02, 75.95it/s]retrival evaluation:  95%|█████████▍| 3291/3481 [00:42<00:02, 76.53it/s]retrival evaluation:  95%|█████████▍| 3299/3481 [00:42<00:02, 76.27it/s]retrival evaluation:  95%|█████████▌| 3307/3481 [00:42<00:02, 76.90it/s]retrival evaluation:  95%|█████████▌| 3316/3481 [00:42<00:02, 78.09it/s]retrival evaluation:  95%|█████████▌| 3324/3481 [00:42<00:02, 78.49it/s]retrival evaluation:  96%|█████████▌| 3332/3481 [00:42<00:02, 73.98it/s]retrival evaluation:  96%|█████████▌| 3340/3481 [00:42<00:01, 74.64it/s]retrival evaluation:  96%|█████████▌| 3348/3481 [00:43<00:01, 75.55it/s]retrival evaluation:  96%|█████████▋| 3356/3481 [00:43<00:01, 75.83it/s]retrival evaluation:  97%|█████████▋| 3364/3481 [00:43<00:01, 76.45it/s]retrival evaluation:  97%|█████████▋| 3372/3481 [00:43<00:01, 75.35it/s]retrival evaluation:  97%|█████████▋| 3380/3481 [00:43<00:01, 76.20it/s]retrival evaluation:  97%|█████████▋| 3388/3481 [00:43<00:01, 76.88it/s]retrival evaluation:  98%|█████████▊| 3396/3481 [00:43<00:01, 77.40it/s]retrival evaluation:  98%|█████████▊| 3404/3481 [00:43<00:00, 77.85it/s]retrival evaluation:  98%|█████████▊| 3412/3481 [00:43<00:00, 76.26it/s]retrival evaluation:  98%|█████████▊| 3420/3481 [00:44<00:00, 76.60it/s]retrival evaluation:  98%|█████████▊| 3428/3481 [00:44<00:00, 72.92it/s]retrival evaluation:  99%|█████████▊| 3436/3481 [00:44<00:00, 74.76it/s]retrival evaluation:  99%|█████████▉| 3444/3481 [00:44<00:00, 76.13it/s]retrival evaluation:  99%|█████████▉| 3452/3481 [00:44<00:00, 76.94it/s]retrival evaluation:  99%|█████████▉| 3460/3481 [00:44<00:00, 75.01it/s]retrival evaluation: 100%|█████████▉| 3468/3481 [00:44<00:00, 74.43it/s]retrival evaluation: 100%|█████████▉| 3476/3481 [00:44<00:00, 72.33it/s]retrival evaluation: 100%|██████████| 3481/3481 [00:44<00:00, 77.63it/s]

pk3=0, pk2=0,pk1=0 best_f1 = 0.259, bets_f2=0.31, MAP=0.439, MRR=0, AP=0.159, exe_time=234.88452434539795

INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:__main__:model loaded
INFO:EMSE.BERTDataReader:Creating examples from dataset file at /afs/crc.nd.edu/user/j/jlin6/data/EMSE/Emmagee/test
update feature:   0%|          | 0/11 [00:00<?, ?it/s]update feature:  91%|█████████ | 10/11 [00:00<00:00, 83.73it/s]update feature: 100%|██████████| 11/11 [00:00<00:00, 88.77it/s]
update feature:   0%|          | 0/11 [00:00<?, ?it/s]update feature: 100%|██████████| 11/11 [00:00<00:00, 1433.95it/s]
update embedding:   0%|          | 0/11 [00:00<?, ?it/s]update embedding:   9%|▉         | 1/11 [00:00<00:08,  1.22it/s]update embedding:  18%|█▊        | 2/11 [00:01<00:07,  1.22it/s]update embedding:  27%|██▋       | 3/11 [00:02<00:06,  1.24it/s]update embedding:  36%|███▋      | 4/11 [00:03<00:05,  1.26it/s]update embedding:  45%|████▌     | 5/11 [00:03<00:04,  1.26it/s]update embedding:  55%|█████▍    | 6/11 [00:04<00:03,  1.26it/s]update embedding:  64%|██████▎   | 7/11 [00:05<00:03,  1.27it/s]update embedding:  73%|███████▎  | 8/11 [00:06<00:02,  1.26it/s]update embedding:  82%|████████▏ | 9/11 [00:07<00:01,  1.25it/s]update embedding:  91%|█████████ | 10/11 [00:07<00:00,  1.23it/s]update embedding: 100%|██████████| 11/11 [00:08<00:00,  1.27it/s]update embedding: 100%|██████████| 11/11 [00:08<00:00,  1.26it/s]
update embedding:   0%|          | 0/11 [00:00<?, ?it/s]update embedding:   9%|▉         | 1/11 [00:00<00:07,  1.39it/s]update embedding:  18%|█▊        | 2/11 [00:01<00:06,  1.38it/s]update embedding:  27%|██▋       | 3/11 [00:02<00:05,  1.35it/s]update embedding:  36%|███▋      | 4/11 [00:03<00:05,  1.33it/s]update embedding:  45%|████▌     | 5/11 [00:03<00:04,  1.31it/s]update embedding:  55%|█████▍    | 6/11 [00:04<00:03,  1.30it/s]update embedding:  64%|██████▎   | 7/11 [00:05<00:03,  1.29it/s]update embedding:  73%|███████▎  | 8/11 [00:06<00:02,  1.28it/s]update embedding:  82%|████████▏ | 9/11 [00:06<00:01,  1.28it/s]update embedding:  91%|█████████ | 10/11 [00:07<00:00,  1.28it/s]update embedding: 100%|██████████| 11/11 [00:08<00:00,  1.28it/s]update embedding: 100%|██████████| 11/11 [00:08<00:00,  1.29it/s]
retrival evaluation:   0%|          | 0/31 [00:00<?, ?it/s]retrival evaluation:  23%|██▎       | 7/31 [00:00<00:00, 67.62it/s]retrival evaluation:  48%|████▊     | 15/31 [00:00<00:00, 70.89it/s]retrival evaluation:  74%|███████▍  | 23/31 [00:00<00:00, 73.38it/s]retrival evaluation: 100%|██████████| 31/31 [00:00<00:00, 77.82it/s]

pk3=0, pk2=0,pk1=0 best_f1 = 0.279, bets_f2=0.43, MAP=0.369, MRR=0, AP=0.211, exe_time=17.82134246826172

INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:__main__:model loaded
INFO:EMSE.BERTDataReader:Creating examples from dataset file at /afs/crc.nd.edu/user/j/jlin6/data/EMSE/nacos/test
update feature:   0%|          | 0/17 [00:00<?, ?it/s]update feature:  71%|███████   | 12/17 [00:00<00:00, 101.44it/s]update feature: 100%|██████████| 17/17 [00:00<00:00, 100.23it/s]
update feature:   0%|          | 0/17 [00:00<?, ?it/s]update feature: 100%|██████████| 17/17 [00:00<00:00, 628.68it/s]
update embedding:   0%|          | 0/17 [00:00<?, ?it/s]update embedding:   6%|▌         | 1/17 [00:00<00:12,  1.29it/s]update embedding:  12%|█▏        | 2/17 [00:01<00:11,  1.30it/s]update embedding:  18%|█▊        | 3/17 [00:02<00:10,  1.30it/s]update embedding:  24%|██▎       | 4/17 [00:03<00:09,  1.31it/s]update embedding:  29%|██▉       | 5/17 [00:03<00:09,  1.31it/s]update embedding:  35%|███▌      | 6/17 [00:04<00:08,  1.31it/s]update embedding:  41%|████      | 7/17 [00:05<00:07,  1.31it/s]update embedding:  47%|████▋     | 8/17 [00:06<00:06,  1.31it/s]update embedding:  53%|█████▎    | 9/17 [00:06<00:06,  1.32it/s]update embedding:  59%|█████▉    | 10/17 [00:07<00:05,  1.31it/s]update embedding:  65%|██████▍   | 11/17 [00:08<00:04,  1.31it/s]update embedding:  71%|███████   | 12/17 [00:09<00:03,  1.31it/s]update embedding:  76%|███████▋  | 13/17 [00:09<00:03,  1.29it/s]update embedding:  82%|████████▏ | 14/17 [00:10<00:02,  1.31it/s]update embedding:  88%|████████▊ | 15/17 [00:11<00:01,  1.33it/s]update embedding:  94%|█████████▍| 16/17 [00:12<00:00,  1.35it/s]update embedding: 100%|██████████| 17/17 [00:12<00:00,  1.35it/s]update embedding: 100%|██████████| 17/17 [00:12<00:00,  1.32it/s]
update embedding:   0%|          | 0/17 [00:00<?, ?it/s]update embedding:   6%|▌         | 1/17 [00:00<00:11,  1.39it/s]update embedding:  12%|█▏        | 2/17 [00:01<00:11,  1.32it/s]update embedding:  18%|█▊        | 3/17 [00:02<00:10,  1.30it/s]update embedding:  24%|██▎       | 4/17 [00:03<00:10,  1.28it/s]update embedding:  29%|██▉       | 5/17 [00:03<00:09,  1.26it/s]update embedding:  35%|███▌      | 6/17 [00:04<00:08,  1.24it/s]update embedding:  41%|████      | 7/17 [00:05<00:08,  1.22it/s]update embedding:  47%|████▋     | 8/17 [00:06<00:07,  1.20it/s]update embedding:  53%|█████▎    | 9/17 [00:07<00:06,  1.20it/s]update embedding:  59%|█████▉    | 10/17 [00:08<00:05,  1.21it/s]update embedding:  65%|██████▍   | 11/17 [00:09<00:04,  1.20it/s]update embedding:  71%|███████   | 12/17 [00:09<00:04,  1.20it/s]update embedding:  76%|███████▋  | 13/17 [00:10<00:03,  1.21it/s]update embedding:  82%|████████▏ | 14/17 [00:11<00:02,  1.22it/s]update embedding:  88%|████████▊ | 15/17 [00:12<00:01,  1.23it/s]update embedding:  94%|█████████▍| 16/17 [00:13<00:00,  1.23it/s]update embedding: 100%|██████████| 17/17 [00:13<00:00,  1.23it/s]update embedding: 100%|██████████| 17/17 [00:13<00:00,  1.22it/s]
retrival evaluation:   0%|          | 0/73 [00:00<?, ?it/s]retrival evaluation:  10%|▉         | 7/73 [00:00<00:01, 62.22it/s]retrival evaluation:  21%|██        | 15/73 [00:00<00:00, 65.01it/s]retrival evaluation:  32%|███▏      | 23/73 [00:00<00:00, 68.04it/s]retrival evaluation:  42%|████▏     | 31/73 [00:00<00:00, 70.74it/s]retrival evaluation:  53%|█████▎    | 39/73 [00:00<00:00, 72.70it/s]retrival evaluation:  64%|██████▍   | 47/73 [00:00<00:00, 74.04it/s]retrival evaluation:  75%|███████▌  | 55/73 [00:00<00:00, 75.27it/s]retrival evaluation:  86%|████████▋ | 63/73 [00:00<00:00, 76.28it/s]retrival evaluation:  97%|█████████▋| 71/73 [00:00<00:00, 76.80it/s]retrival evaluation: 100%|██████████| 73/73 [00:00<00:00, 76.04it/s]

pk3=0, pk2=0,pk1=0 best_f1 = 0.357, bets_f2=0.469, MAP=0.551, MRR=0, AP=0.297, exe_time=28.45674443244934

INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:__main__:model loaded
INFO:EMSE.BERTDataReader:Creating examples from dataset file at /afs/crc.nd.edu/user/j/jlin6/data/EMSE/ncnn/test
update feature:   0%|          | 0/11 [00:00<?, ?it/s]update feature: 100%|██████████| 11/11 [00:00<00:00, 364.85it/s]
update feature:   0%|          | 0/11 [00:00<?, ?it/s]update feature: 100%|██████████| 11/11 [00:00<00:00, 1180.98it/s]
update embedding:   0%|          | 0/11 [00:00<?, ?it/s]update embedding:   9%|▉         | 1/11 [00:00<00:08,  1.24it/s]update embedding:  18%|█▊        | 2/11 [00:01<00:07,  1.25it/s]update embedding:  27%|██▋       | 3/11 [00:02<00:06,  1.25it/s]update embedding:  36%|███▋      | 4/11 [00:03<00:05,  1.26it/s]update embedding:  45%|████▌     | 5/11 [00:03<00:04,  1.27it/s]update embedding:  55%|█████▍    | 6/11 [00:04<00:03,  1.27it/s]update embedding:  64%|██████▎   | 7/11 [00:05<00:03,  1.28it/s]update embedding:  73%|███████▎  | 8/11 [00:06<00:02,  1.28it/s]update embedding:  82%|████████▏ | 9/11 [00:07<00:01,  1.29it/s]update embedding:  91%|█████████ | 10/11 [00:07<00:00,  1.28it/s]update embedding: 100%|██████████| 11/11 [00:08<00:00,  1.28it/s]update embedding: 100%|██████████| 11/11 [00:08<00:00,  1.28it/s]
update embedding:   0%|          | 0/11 [00:00<?, ?it/s]update embedding:   9%|▉         | 1/11 [00:00<00:07,  1.29it/s]update embedding:  18%|█▊        | 2/11 [00:01<00:06,  1.29it/s]update embedding:  27%|██▋       | 3/11 [00:02<00:06,  1.29it/s]update embedding:  36%|███▋      | 4/11 [00:03<00:05,  1.29it/s]update embedding:  45%|████▌     | 5/11 [00:03<00:04,  1.29it/s]update embedding:  55%|█████▍    | 6/11 [00:04<00:03,  1.28it/s]update embedding:  64%|██████▎   | 7/11 [00:05<00:03,  1.28it/s]update embedding:  73%|███████▎  | 8/11 [00:06<00:02,  1.27it/s]update embedding:  82%|████████▏ | 9/11 [00:07<00:01,  1.28it/s]update embedding:  91%|█████████ | 10/11 [00:07<00:00,  1.28it/s]update embedding: 100%|██████████| 11/11 [00:08<00:00,  1.28it/s]update embedding: 100%|██████████| 11/11 [00:08<00:00,  1.28it/s]
retrival evaluation:   0%|          | 0/31 [00:00<?, ?it/s]retrival evaluation:  23%|██▎       | 7/31 [00:00<00:00, 66.33it/s]retrival evaluation:  48%|████▊     | 15/31 [00:00<00:00, 69.02it/s]retrival evaluation:  74%|███████▍  | 23/31 [00:00<00:00, 71.48it/s]retrival evaluation: 100%|██████████| 31/31 [00:00<00:00, 76.41it/s]

pk3=0, pk2=0,pk1=0 best_f1 = 0.818, bets_f2=0.818, MAP=0.909, MRR=0, AP=0.859, exe_time=17.723408699035645

INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:__main__:model loaded
INFO:EMSE.BERTDataReader:Creating examples from dataset file at /afs/crc.nd.edu/user/j/jlin6/data/EMSE/pegasus/test
update feature:   0%|          | 0/17 [00:00<?, ?it/s]update feature: 100%|██████████| 17/17 [00:00<00:00, 252.96it/s]
update feature:   0%|          | 0/17 [00:00<?, ?it/s]update feature: 100%|██████████| 17/17 [00:00<00:00, 845.89it/s]
update embedding:   0%|          | 0/17 [00:00<?, ?it/s]update embedding:   6%|▌         | 1/17 [00:00<00:13,  1.23it/s]update embedding:  12%|█▏        | 2/17 [00:01<00:12,  1.24it/s]update embedding:  18%|█▊        | 3/17 [00:02<00:11,  1.25it/s]update embedding:  24%|██▎       | 4/17 [00:03<00:10,  1.27it/s]update embedding:  29%|██▉       | 5/17 [00:03<00:09,  1.28it/s]update embedding:  35%|███▌      | 6/17 [00:04<00:08,  1.28it/s]update embedding:  41%|████      | 7/17 [00:05<00:07,  1.29it/s]update embedding:  47%|████▋     | 8/17 [00:06<00:06,  1.29it/s]update embedding:  53%|█████▎    | 9/17 [00:07<00:06,  1.29it/s]update embedding:  59%|█████▉    | 10/17 [00:07<00:05,  1.29it/s]update embedding:  65%|██████▍   | 11/17 [00:08<00:04,  1.30it/s]update embedding:  71%|███████   | 12/17 [00:09<00:03,  1.30it/s]update embedding:  76%|███████▋  | 13/17 [00:10<00:03,  1.31it/s]update embedding:  82%|████████▏ | 14/17 [00:10<00:02,  1.31it/s]update embedding:  88%|████████▊ | 15/17 [00:11<00:01,  1.30it/s]update embedding:  94%|█████████▍| 16/17 [00:12<00:00,  1.30it/s]update embedding: 100%|██████████| 17/17 [00:13<00:00,  1.29it/s]update embedding: 100%|██████████| 17/17 [00:13<00:00,  1.29it/s]
update embedding:   0%|          | 0/17 [00:00<?, ?it/s]update embedding:   6%|▌         | 1/17 [00:00<00:12,  1.28it/s]update embedding:  12%|█▏        | 2/17 [00:01<00:11,  1.30it/s]update embedding:  18%|█▊        | 3/17 [00:02<00:10,  1.30it/s]update embedding:  24%|██▎       | 4/17 [00:03<00:10,  1.29it/s]update embedding:  29%|██▉       | 5/17 [00:03<00:09,  1.30it/s]update embedding:  35%|███▌      | 6/17 [00:04<00:08,  1.30it/s]update embedding:  41%|████      | 7/17 [00:05<00:07,  1.30it/s]update embedding:  47%|████▋     | 8/17 [00:06<00:06,  1.31it/s]update embedding:  53%|█████▎    | 9/17 [00:06<00:06,  1.31it/s]update embedding:  59%|█████▉    | 10/17 [00:07<00:05,  1.31it/s]update embedding:  65%|██████▍   | 11/17 [00:08<00:04,  1.30it/s]update embedding:  71%|███████   | 12/17 [00:09<00:03,  1.31it/s]update embedding:  76%|███████▋  | 13/17 [00:09<00:03,  1.31it/s]update embedding:  82%|████████▏ | 14/17 [00:10<00:02,  1.31it/s]update embedding:  88%|████████▊ | 15/17 [00:11<00:01,  1.32it/s]update embedding:  94%|█████████▍| 16/17 [00:12<00:00,  1.32it/s]update embedding: 100%|██████████| 17/17 [00:12<00:00,  1.31it/s]update embedding: 100%|██████████| 17/17 [00:12<00:00,  1.31it/s]
retrival evaluation:   0%|          | 0/73 [00:00<?, ?it/s]retrival evaluation:  11%|█         | 8/73 [00:00<00:00, 74.87it/s]retrival evaluation:  22%|██▏       | 16/73 [00:00<00:00, 76.29it/s]retrival evaluation:  34%|███▍      | 25/73 [00:00<00:00, 78.59it/s]retrival evaluation:  47%|████▋     | 34/73 [00:00<00:00, 79.96it/s]retrival evaluation:  59%|█████▉    | 43/73 [00:00<00:00, 80.71it/s]retrival evaluation:  71%|███████   | 52/73 [00:00<00:00, 81.61it/s]retrival evaluation:  84%|████████▎ | 61/73 [00:00<00:00, 82.25it/s]retrival evaluation:  96%|█████████▌| 70/73 [00:00<00:00, 82.84it/s]retrival evaluation: 100%|██████████| 73/73 [00:00<00:00, 83.00it/s]

pk3=0, pk2=0,pk1=0 best_f1 = 0.788, bets_f2=0.774, MAP=0.941, MRR=0, AP=0.834, exe_time=27.17910122871399

INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:__main__:model loaded
INFO:EMSE.BERTDataReader:Creating examples from dataset file at /afs/crc.nd.edu/user/j/jlin6/data/EMSE/QMUI_Android/test
update feature:   0%|          | 0/8 [00:00<?, ?it/s]update feature: 100%|██████████| 8/8 [00:00<00:00, 97.07it/s]
update feature:   0%|          | 0/8 [00:00<?, ?it/s]update feature: 100%|██████████| 8/8 [00:00<00:00, 506.68it/s]
update embedding:   0%|          | 0/8 [00:00<?, ?it/s]update embedding:  12%|█▎        | 1/8 [00:00<00:05,  1.24it/s]update embedding:  25%|██▌       | 2/8 [00:01<00:04,  1.26it/s]update embedding:  38%|███▊      | 3/8 [00:02<00:03,  1.26it/s]update embedding:  50%|█████     | 4/8 [00:03<00:03,  1.27it/s]update embedding:  62%|██████▎   | 5/8 [00:03<00:02,  1.28it/s]update embedding:  75%|███████▌  | 6/8 [00:04<00:01,  1.26it/s]update embedding:  88%|████████▊ | 7/8 [00:05<00:00,  1.26it/s]update embedding: 100%|██████████| 8/8 [00:06<00:00,  1.26it/s]update embedding: 100%|██████████| 8/8 [00:06<00:00,  1.27it/s]
update embedding:   0%|          | 0/8 [00:00<?, ?it/s]update embedding:  12%|█▎        | 1/8 [00:00<00:05,  1.27it/s]update embedding:  25%|██▌       | 2/8 [00:01<00:04,  1.27it/s]update embedding:  38%|███▊      | 3/8 [00:02<00:03,  1.27it/s]update embedding:  50%|█████     | 4/8 [00:03<00:03,  1.28it/s]update embedding:  62%|██████▎   | 5/8 [00:03<00:02,  1.28it/s]update embedding:  75%|███████▌  | 6/8 [00:04<00:01,  1.28it/s]update embedding:  88%|████████▊ | 7/8 [00:05<00:00,  1.28it/s]update embedding: 100%|██████████| 8/8 [00:06<00:00,  1.27it/s]update embedding: 100%|██████████| 8/8 [00:06<00:00,  1.28it/s]
retrival evaluation:   0%|          | 0/16 [00:00<?, ?it/s]retrival evaluation:  44%|████▍     | 7/16 [00:00<00:00, 68.63it/s]retrival evaluation:  94%|█████████▍| 15/16 [00:00<00:00, 69.62it/s]retrival evaluation: 100%|██████████| 16/16 [00:00<00:00, 70.76it/s]

pk3=0, pk2=0,pk1=0 best_f1 = 0.375, bets_f2=0.493, MAP=0.456, MRR=0, AP=0.237, exe_time=12.956085920333862

INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:__main__:model loaded
INFO:EMSE.BERTDataReader:Creating examples from dataset file at /afs/crc.nd.edu/user/j/jlin6/data/EMSE/QMUI_iOS/test
update feature:   0%|          | 0/12 [00:00<?, ?it/s]update feature: 100%|██████████| 12/12 [00:00<00:00, 399.63it/s]
update feature:   0%|          | 0/12 [00:00<?, ?it/s]update feature: 100%|██████████| 12/12 [00:00<00:00, 1388.04it/s]
update embedding:   0%|          | 0/12 [00:00<?, ?it/s]update embedding:   8%|▊         | 1/12 [00:00<00:08,  1.35it/s]update embedding:  17%|█▋        | 2/12 [00:01<00:07,  1.36it/s]update embedding:  25%|██▌       | 3/12 [00:02<00:06,  1.37it/s]update embedding:  33%|███▎      | 4/12 [00:02<00:05,  1.36it/s]update embedding:  42%|████▏     | 5/12 [00:03<00:05,  1.32it/s]update embedding:  50%|█████     | 6/12 [00:04<00:04,  1.29it/s]update embedding:  58%|█████▊    | 7/12 [00:05<00:03,  1.28it/s]update embedding:  67%|██████▋   | 8/12 [00:06<00:03,  1.27it/s]update embedding:  75%|███████▌  | 9/12 [00:06<00:02,  1.26it/s]update embedding:  83%|████████▎ | 10/12 [00:07<00:01,  1.30it/s]update embedding:  92%|█████████▏| 11/12 [00:08<00:00,  1.30it/s]update embedding: 100%|██████████| 12/12 [00:09<00:00,  1.29it/s]update embedding: 100%|██████████| 12/12 [00:09<00:00,  1.30it/s]
update embedding:   0%|          | 0/12 [00:00<?, ?it/s]update embedding:   8%|▊         | 1/12 [00:00<00:08,  1.27it/s]update embedding:  17%|█▋        | 2/12 [00:01<00:07,  1.27it/s]update embedding:  25%|██▌       | 3/12 [00:02<00:07,  1.26it/s]update embedding:  33%|███▎      | 4/12 [00:03<00:06,  1.27it/s]update embedding:  42%|████▏     | 5/12 [00:03<00:05,  1.27it/s]update embedding:  50%|█████     | 6/12 [00:04<00:04,  1.27it/s]update embedding:  58%|█████▊    | 7/12 [00:05<00:03,  1.27it/s]update embedding:  67%|██████▋   | 8/12 [00:06<00:03,  1.27it/s]update embedding:  75%|███████▌  | 9/12 [00:07<00:02,  1.27it/s]update embedding:  83%|████████▎ | 10/12 [00:07<00:01,  1.27it/s]update embedding:  92%|█████████▏| 11/12 [00:08<00:00,  1.27it/s]update embedding: 100%|██████████| 12/12 [00:09<00:00,  1.27it/s]update embedding: 100%|██████████| 12/12 [00:09<00:00,  1.27it/s]
retrival evaluation:   0%|          | 0/36 [00:00<?, ?it/s]retrival evaluation:  19%|█▉        | 7/36 [00:00<00:00, 67.42it/s]retrival evaluation:  42%|████▏     | 15/36 [00:00<00:00, 70.61it/s]retrival evaluation:  64%|██████▍   | 23/36 [00:00<00:00, 72.16it/s]retrival evaluation:  86%|████████▌ | 31/36 [00:00<00:00, 73.78it/s]retrival evaluation: 100%|██████████| 36/36 [00:00<00:00, 75.60it/s]

pk3=0, pk2=0,pk1=0 best_f1 = 0.364, bets_f2=0.515, MAP=0.644, MRR=0, AP=0.303, exe_time=19.27182960510254

INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:__main__:model loaded
INFO:EMSE.BERTDataReader:Creating examples from dataset file at /afs/crc.nd.edu/user/j/jlin6/data/EMSE/rax/test
update feature:   0%|          | 0/56 [00:00<?, ?it/s]update feature:  54%|█████▎    | 30/56 [00:00<00:00, 296.15it/s]update feature: 100%|██████████| 56/56 [00:00<00:00, 397.28it/s]
update feature:   0%|          | 0/56 [00:00<?, ?it/s]update feature: 100%|██████████| 56/56 [00:00<00:00, 1872.80it/s]
update embedding:   0%|          | 0/56 [00:00<?, ?it/s]update embedding:   2%|▏         | 1/56 [00:00<00:45,  1.22it/s]update embedding:   4%|▎         | 2/56 [00:01<00:43,  1.23it/s]update embedding:   5%|▌         | 3/56 [00:02<00:42,  1.24it/s]update embedding:   7%|▋         | 4/56 [00:03<00:41,  1.26it/s]update embedding:   9%|▉         | 5/56 [00:03<00:40,  1.27it/s]update embedding:  11%|█         | 6/56 [00:04<00:39,  1.27it/s]update embedding:  12%|█▎        | 7/56 [00:05<00:38,  1.27it/s]update embedding:  14%|█▍        | 8/56 [00:06<00:37,  1.28it/s]update embedding:  16%|█▌        | 9/56 [00:07<00:36,  1.29it/s]update embedding:  18%|█▊        | 10/56 [00:07<00:35,  1.30it/s]update embedding:  20%|█▉        | 11/56 [00:08<00:34,  1.30it/s]update embedding:  21%|██▏       | 12/56 [00:09<00:33,  1.30it/s]update embedding:  23%|██▎       | 13/56 [00:10<00:33,  1.30it/s]update embedding:  25%|██▌       | 14/56 [00:10<00:32,  1.29it/s]update embedding:  27%|██▋       | 15/56 [00:11<00:31,  1.29it/s]update embedding:  29%|██▊       | 16/56 [00:12<00:30,  1.29it/s]update embedding:  30%|███       | 17/56 [00:13<00:30,  1.29it/s]update embedding:  32%|███▏      | 18/56 [00:13<00:29,  1.29it/s]update embedding:  34%|███▍      | 19/56 [00:14<00:28,  1.29it/s]update embedding:  36%|███▌      | 20/56 [00:15<00:27,  1.30it/s]update embedding:  38%|███▊      | 21/56 [00:16<00:26,  1.31it/s]update embedding:  39%|███▉      | 22/56 [00:17<00:25,  1.32it/s]update embedding:  41%|████      | 23/56 [00:17<00:24,  1.33it/s]update embedding:  43%|████▎     | 24/56 [00:18<00:23,  1.34it/s]update embedding:  45%|████▍     | 25/56 [00:19<00:23,  1.34it/s]update embedding:  46%|████▋     | 26/56 [00:19<00:22,  1.34it/s]update embedding:  48%|████▊     | 27/56 [00:20<00:21,  1.34it/s]update embedding:  50%|█████     | 28/56 [00:21<00:21,  1.32it/s]update embedding:  52%|█████▏    | 29/56 [00:22<00:20,  1.33it/s]update embedding:  54%|█████▎    | 30/56 [00:22<00:19,  1.33it/s]update embedding:  55%|█████▌    | 31/56 [00:23<00:18,  1.33it/s]update embedding:  57%|█████▋    | 32/56 [00:24<00:17,  1.34it/s]update embedding:  59%|█████▉    | 33/56 [00:25<00:17,  1.34it/s]update embedding:  61%|██████    | 34/56 [00:25<00:16,  1.33it/s]update embedding:  62%|██████▎   | 35/56 [00:26<00:15,  1.33it/s]update embedding:  64%|██████▍   | 36/56 [00:27<00:14,  1.34it/s]update embedding:  66%|██████▌   | 37/56 [00:28<00:14,  1.34it/s]update embedding:  68%|██████▊   | 38/56 [00:28<00:13,  1.33it/s]update embedding:  70%|██████▉   | 39/56 [00:29<00:12,  1.33it/s]update embedding:  71%|███████▏  | 40/56 [00:30<00:11,  1.33it/s]update embedding:  73%|███████▎  | 41/56 [00:31<00:11,  1.33it/s]update embedding:  75%|███████▌  | 42/56 [00:31<00:10,  1.34it/s]update embedding:  77%|███████▋  | 43/56 [00:32<00:09,  1.35it/s]update embedding:  79%|███████▊  | 44/56 [00:33<00:08,  1.35it/s]update embedding:  80%|████████  | 45/56 [00:34<00:08,  1.35it/s]update embedding:  82%|████████▏ | 46/56 [00:34<00:07,  1.34it/s]update embedding:  84%|████████▍ | 47/56 [00:35<00:06,  1.34it/s]update embedding:  86%|████████▌ | 48/56 [00:36<00:05,  1.35it/s]update embedding:  88%|████████▊ | 49/56 [00:37<00:05,  1.34it/s]update embedding:  89%|████████▉ | 50/56 [00:37<00:04,  1.33it/s]update embedding:  91%|█████████ | 51/56 [00:38<00:03,  1.34it/s]update embedding:  93%|█████████▎| 52/56 [00:39<00:02,  1.35it/s]update embedding:  95%|█████████▍| 53/56 [00:40<00:02,  1.34it/s]update embedding:  96%|█████████▋| 54/56 [00:40<00:01,  1.35it/s]update embedding:  98%|█████████▊| 55/56 [00:41<00:00,  1.34it/s]update embedding: 100%|██████████| 56/56 [00:42<00:00,  1.34it/s]update embedding: 100%|██████████| 56/56 [00:42<00:00,  1.32it/s]
update embedding:   0%|          | 0/56 [00:00<?, ?it/s]update embedding:   2%|▏         | 1/56 [00:00<00:40,  1.36it/s]update embedding:   4%|▎         | 2/56 [00:01<00:39,  1.36it/s]update embedding:   5%|▌         | 3/56 [00:02<00:38,  1.36it/s]update embedding:   7%|▋         | 4/56 [00:02<00:38,  1.36it/s]update embedding:   9%|▉         | 5/56 [00:03<00:37,  1.36it/s]update embedding:  11%|█         | 6/56 [00:04<00:36,  1.36it/s]update embedding:  12%|█▎        | 7/56 [00:05<00:36,  1.35it/s]update embedding:  14%|█▍        | 8/56 [00:05<00:35,  1.34it/s]update embedding:  16%|█▌        | 9/56 [00:06<00:35,  1.34it/s]update embedding:  18%|█▊        | 10/56 [00:07<00:34,  1.34it/s]update embedding:  20%|█▉        | 11/56 [00:08<00:33,  1.34it/s]update embedding:  21%|██▏       | 12/56 [00:08<00:32,  1.34it/s]update embedding:  23%|██▎       | 13/56 [00:09<00:32,  1.34it/s]update embedding:  25%|██▌       | 14/56 [00:10<00:31,  1.34it/s]update embedding:  27%|██▋       | 15/56 [00:11<00:30,  1.32it/s]update embedding:  29%|██▊       | 16/56 [00:11<00:30,  1.33it/s]update embedding:  30%|███       | 17/56 [00:12<00:29,  1.33it/s]update embedding:  32%|███▏      | 18/56 [00:13<00:28,  1.34it/s]update embedding:  34%|███▍      | 19/56 [00:14<00:27,  1.34it/s]update embedding:  36%|███▌      | 20/56 [00:14<00:26,  1.35it/s]update embedding:  38%|███▊      | 21/56 [00:15<00:25,  1.35it/s]update embedding:  39%|███▉      | 22/56 [00:16<00:25,  1.34it/s]update embedding:  41%|████      | 23/56 [00:17<00:24,  1.34it/s]update embedding:  43%|████▎     | 24/56 [00:17<00:23,  1.34it/s]update embedding:  45%|████▍     | 25/56 [00:18<00:23,  1.35it/s]update embedding:  46%|████▋     | 26/56 [00:19<00:22,  1.35it/s]update embedding:  48%|████▊     | 27/56 [00:20<00:21,  1.35it/s]update embedding:  50%|█████     | 28/56 [00:20<00:20,  1.34it/s]update embedding:  52%|█████▏    | 29/56 [00:21<00:20,  1.34it/s]update embedding:  54%|█████▎    | 30/56 [00:22<00:19,  1.34it/s]update embedding:  55%|█████▌    | 31/56 [00:23<00:18,  1.34it/s]update embedding:  57%|█████▋    | 32/56 [00:23<00:17,  1.33it/s]update embedding:  59%|█████▉    | 33/56 [00:24<00:17,  1.33it/s]update embedding:  61%|██████    | 34/56 [00:25<00:16,  1.32it/s]update embedding:  62%|██████▎   | 35/56 [00:26<00:15,  1.32it/s]update embedding:  64%|██████▍   | 36/56 [00:26<00:15,  1.33it/s]update embedding:  66%|██████▌   | 37/56 [00:27<00:14,  1.33it/s]update embedding:  68%|██████▊   | 38/56 [00:28<00:13,  1.33it/s]update embedding:  70%|██████▉   | 39/56 [00:29<00:12,  1.33it/s]update embedding:  71%|███████▏  | 40/56 [00:29<00:12,  1.33it/s]update embedding:  73%|███████▎  | 41/56 [00:30<00:11,  1.31it/s]update embedding:  75%|███████▌  | 42/56 [00:31<00:10,  1.32it/s]update embedding:  77%|███████▋  | 43/56 [00:32<00:09,  1.32it/s]update embedding:  79%|███████▊  | 44/56 [00:32<00:09,  1.32it/s]update embedding:  80%|████████  | 45/56 [00:33<00:08,  1.33it/s]update embedding:  82%|████████▏ | 46/56 [00:34<00:07,  1.33it/s]update embedding:  84%|████████▍ | 47/56 [00:35<00:06,  1.32it/s]update embedding:  86%|████████▌ | 48/56 [00:35<00:06,  1.33it/s]update embedding:  88%|████████▊ | 49/56 [00:36<00:05,  1.34it/s]update embedding:  89%|████████▉ | 50/56 [00:37<00:04,  1.35it/s]update embedding:  91%|█████████ | 51/56 [00:38<00:03,  1.35it/s]update embedding:  93%|█████████▎| 52/56 [00:38<00:02,  1.35it/s]update embedding:  95%|█████████▍| 53/56 [00:39<00:02,  1.35it/s]update embedding:  96%|█████████▋| 54/56 [00:40<00:01,  1.34it/s]update embedding:  98%|█████████▊| 55/56 [00:41<00:00,  1.35it/s]update embedding: 100%|██████████| 56/56 [00:41<00:00,  1.35it/s]update embedding: 100%|██████████| 56/56 [00:41<00:00,  1.34it/s]
retrival evaluation:   0%|          | 0/784 [00:00<?, ?it/s]retrival evaluation:   1%|          | 7/784 [00:00<00:12, 62.36it/s]retrival evaluation:   2%|▏         | 15/784 [00:00<00:11, 65.40it/s]retrival evaluation:   3%|▎         | 24/784 [00:00<00:10, 69.72it/s]retrival evaluation:   4%|▍         | 33/784 [00:00<00:10, 73.90it/s]retrival evaluation:   5%|▌         | 42/784 [00:00<00:09, 76.72it/s]retrival evaluation:   7%|▋         | 51/784 [00:00<00:09, 78.62it/s]retrival evaluation:   8%|▊         | 60/784 [00:00<00:09, 80.28it/s]retrival evaluation:   9%|▉         | 69/784 [00:00<00:08, 80.85it/s]retrival evaluation:  10%|▉         | 78/784 [00:00<00:08, 82.04it/s]retrival evaluation:  11%|█         | 87/784 [00:01<00:08, 82.72it/s]retrival evaluation:  12%|█▏        | 96/784 [00:01<00:08, 83.50it/s]retrival evaluation:  13%|█▎        | 105/784 [00:01<00:08, 83.84it/s]retrival evaluation:  15%|█▍        | 114/784 [00:01<00:08, 83.67it/s]retrival evaluation:  16%|█▌        | 123/784 [00:01<00:07, 84.21it/s]retrival evaluation:  17%|█▋        | 132/784 [00:01<00:07, 83.83it/s]retrival evaluation:  18%|█▊        | 141/784 [00:01<00:07, 83.89it/s]retrival evaluation:  19%|█▉        | 150/784 [00:01<00:07, 83.94it/s]retrival evaluation:  20%|██        | 159/784 [00:01<00:07, 84.21it/s]retrival evaluation:  21%|██▏       | 168/784 [00:02<00:07, 84.08it/s]retrival evaluation:  23%|██▎       | 177/784 [00:02<00:07, 83.83it/s]retrival evaluation:  24%|██▎       | 186/784 [00:02<00:07, 84.17it/s]retrival evaluation:  25%|██▍       | 195/784 [00:02<00:06, 84.44it/s]retrival evaluation:  26%|██▌       | 204/784 [00:02<00:06, 84.84it/s]retrival evaluation:  27%|██▋       | 213/784 [00:02<00:06, 84.19it/s]retrival evaluation:  28%|██▊       | 222/784 [00:02<00:06, 84.26it/s]retrival evaluation:  29%|██▉       | 231/784 [00:02<00:06, 84.57it/s]retrival evaluation:  31%|███       | 240/784 [00:02<00:06, 84.51it/s]retrival evaluation:  32%|███▏      | 249/784 [00:03<00:06, 83.65it/s]retrival evaluation:  33%|███▎      | 258/784 [00:03<00:06, 83.79it/s]retrival evaluation:  34%|███▍      | 267/784 [00:03<00:06, 84.01it/s]retrival evaluation:  35%|███▌      | 276/784 [00:03<00:06, 84.32it/s]retrival evaluation:  36%|███▋      | 285/784 [00:03<00:05, 83.99it/s]retrival evaluation:  38%|███▊      | 294/784 [00:03<00:05, 84.18it/s]retrival evaluation:  39%|███▊      | 303/784 [00:03<00:05, 84.25it/s]retrival evaluation:  40%|███▉      | 312/784 [00:03<00:05, 84.16it/s]retrival evaluation:  41%|████      | 321/784 [00:03<00:05, 83.86it/s]retrival evaluation:  42%|████▏     | 330/784 [00:03<00:05, 83.15it/s]retrival evaluation:  43%|████▎     | 339/784 [00:04<00:05, 82.96it/s]retrival evaluation:  44%|████▍     | 348/784 [00:04<00:05, 82.85it/s]retrival evaluation:  46%|████▌     | 357/784 [00:04<00:05, 83.07it/s]retrival evaluation:  47%|████▋     | 366/784 [00:04<00:05, 82.58it/s]retrival evaluation:  48%|████▊     | 375/784 [00:04<00:04, 82.21it/s]retrival evaluation:  49%|████▉     | 384/784 [00:04<00:04, 82.40it/s]retrival evaluation:  50%|█████     | 393/784 [00:04<00:04, 82.05it/s]retrival evaluation:  51%|█████▏    | 402/784 [00:04<00:04, 81.96it/s]retrival evaluation:  52%|█████▏    | 411/784 [00:04<00:04, 82.12it/s]retrival evaluation:  54%|█████▎    | 420/784 [00:05<00:04, 82.50it/s]retrival evaluation:  55%|█████▍    | 429/784 [00:05<00:04, 82.29it/s]retrival evaluation:  56%|█████▌    | 438/784 [00:05<00:04, 82.66it/s]retrival evaluation:  57%|█████▋    | 447/784 [00:05<00:04, 83.15it/s]retrival evaluation:  58%|█████▊    | 456/784 [00:05<00:03, 83.57it/s]retrival evaluation:  59%|█████▉    | 465/784 [00:05<00:03, 83.11it/s]retrival evaluation:  60%|██████    | 474/784 [00:05<00:03, 83.38it/s]retrival evaluation:  62%|██████▏   | 483/784 [00:05<00:03, 84.13it/s]retrival evaluation:  63%|██████▎   | 492/784 [00:05<00:03, 84.13it/s]retrival evaluation:  64%|██████▍   | 501/784 [00:06<00:03, 84.76it/s]retrival evaluation:  65%|██████▌   | 510/784 [00:06<00:03, 84.91it/s]retrival evaluation:  66%|██████▌   | 519/784 [00:06<00:03, 85.14it/s]retrival evaluation:  67%|██████▋   | 528/784 [00:06<00:03, 85.11it/s]retrival evaluation:  68%|██████▊   | 537/784 [00:06<00:02, 85.06it/s]retrival evaluation:  70%|██████▉   | 546/784 [00:06<00:02, 85.22it/s]retrival evaluation:  71%|███████   | 555/784 [00:06<00:02, 84.18it/s]retrival evaluation:  72%|███████▏  | 564/784 [00:06<00:02, 83.49it/s]retrival evaluation:  73%|███████▎  | 573/784 [00:06<00:02, 82.62it/s]retrival evaluation:  74%|███████▍  | 582/784 [00:06<00:02, 82.72it/s]retrival evaluation:  75%|███████▌  | 591/784 [00:07<00:02, 83.64it/s]retrival evaluation:  77%|███████▋  | 600/784 [00:07<00:02, 83.86it/s]retrival evaluation:  78%|███████▊  | 609/784 [00:07<00:02, 84.24it/s]retrival evaluation:  79%|███████▉  | 618/784 [00:07<00:01, 83.79it/s]retrival evaluation:  80%|███████▉  | 627/784 [00:07<00:01, 83.70it/s]retrival evaluation:  81%|████████  | 636/784 [00:07<00:01, 84.01it/s]retrival evaluation:  82%|████████▏ | 645/784 [00:07<00:01, 84.36it/s]retrival evaluation:  83%|████████▎ | 654/784 [00:07<00:01, 84.60it/s]retrival evaluation:  85%|████████▍ | 663/784 [00:07<00:01, 84.79it/s]retrival evaluation:  86%|████████▌ | 672/784 [00:08<00:01, 85.05it/s]retrival evaluation:  87%|████████▋ | 681/784 [00:08<00:01, 85.13it/s]retrival evaluation:  88%|████████▊ | 690/784 [00:08<00:01, 84.43it/s]retrival evaluation:  89%|████████▉ | 699/784 [00:08<00:01, 84.88it/s]retrival evaluation:  90%|█████████ | 708/784 [00:08<00:00, 85.09it/s]retrival evaluation:  91%|█████████▏| 717/784 [00:08<00:00, 84.22it/s]retrival evaluation:  93%|█████████▎| 726/784 [00:08<00:00, 84.09it/s]retrival evaluation:  94%|█████████▍| 735/784 [00:08<00:00, 83.55it/s]retrival evaluation:  95%|█████████▍| 744/784 [00:08<00:00, 83.91it/s]retrival evaluation:  96%|█████████▌| 753/784 [00:09<00:00, 84.28it/s]retrival evaluation:  97%|█████████▋| 762/784 [00:09<00:00, 83.97it/s]retrival evaluation:  98%|█████████▊| 771/784 [00:09<00:00, 84.11it/s]retrival evaluation:  99%|█████████▉| 780/784 [00:09<00:00, 84.20it/s]retrival evaluation: 100%|██████████| 784/784 [00:09<00:00, 83.53it/s]

pk3=0, pk2=0,pk1=0 best_f1 = 0.505, bets_f2=0.522, MAP=0.646, MRR=0, AP=0.374, exe_time=93.97036981582642

INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:__main__:model loaded
INFO:EMSE.BERTDataReader:Creating examples from dataset file at /afs/crc.nd.edu/user/j/jlin6/data/EMSE/san/test
update feature:   0%|          | 0/3 [00:00<?, ?it/s]update feature: 100%|██████████| 3/3 [00:00<00:00, 1645.47it/s]
update feature:   0%|          | 0/3 [00:00<?, ?it/s]update feature: 100%|██████████| 3/3 [00:00<00:00, 758.88it/s]
update embedding:   0%|          | 0/3 [00:00<?, ?it/s]update embedding:  33%|███▎      | 1/3 [00:00<00:01,  1.30it/s]update embedding:  67%|██████▋   | 2/3 [00:01<00:00,  1.31it/s]update embedding: 100%|██████████| 3/3 [00:02<00:00,  1.32it/s]update embedding: 100%|██████████| 3/3 [00:02<00:00,  1.33it/s]
update embedding:   0%|          | 0/3 [00:00<?, ?it/s]update embedding:  33%|███▎      | 1/3 [00:00<00:01,  1.34it/s]update embedding:  67%|██████▋   | 2/3 [00:01<00:00,  1.34it/s]update embedding: 100%|██████████| 3/3 [00:02<00:00,  1.34it/s]update embedding: 100%|██████████| 3/3 [00:02<00:00,  1.33it/s]
retrival evaluation:   0%|          | 0/3 [00:00<?, ?it/s]retrival evaluation: 100%|██████████| 3/3 [00:00<00:00, 109.28it/s]

pk3=0, pk2=0,pk1=0 best_f1 = 0.667, bets_f2=0.833, MAP=0.611, MRR=0, AP=0.633, exe_time=4.594802379608154

INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:__main__:model loaded
INFO:EMSE.BERTDataReader:Creating examples from dataset file at /afs/crc.nd.edu/user/j/jlin6/data/EMSE/weui/test
update feature:   0%|          | 0/16 [00:00<?, ?it/s]update feature:   6%|▋         | 1/16 [00:00<00:01,  7.86it/s]update feature:  12%|█▎        | 2/16 [00:00<00:03,  4.17it/s]update feature:  19%|█▉        | 3/16 [00:01<00:03,  3.40it/s]update feature:  38%|███▊      | 6/16 [00:01<00:02,  3.95it/s]update feature:  44%|████▍     | 7/16 [00:01<00:02,  3.80it/s]update feature:  50%|█████     | 8/16 [00:02<00:02,  3.44it/s]update feature:  62%|██████▎   | 10/16 [00:02<00:01,  4.45it/s]update feature:  75%|███████▌  | 12/16 [00:02<00:00,  4.72it/s]update feature:  81%|████████▏ | 13/16 [00:02<00:00,  4.08it/s]update feature:  94%|█████████▍| 15/16 [00:03<00:00,  4.19it/s]update feature: 100%|██████████| 16/16 [00:04<00:00,  1.89it/s]update feature: 100%|██████████| 16/16 [00:04<00:00,  3.44it/s]
update feature:   0%|          | 0/16 [00:00<?, ?it/s]update feature: 100%|██████████| 16/16 [00:00<00:00, 1201.31it/s]
update embedding:   0%|          | 0/16 [00:00<?, ?it/s]update embedding:   6%|▋         | 1/16 [00:00<00:12,  1.24it/s]update embedding:  12%|█▎        | 2/16 [00:01<00:11,  1.25it/s]update embedding:  19%|█▉        | 3/16 [00:02<00:10,  1.29it/s]update embedding:  25%|██▌       | 4/16 [00:03<00:09,  1.31it/s]update embedding:  31%|███▏      | 5/16 [00:03<00:08,  1.33it/s]update embedding:  38%|███▊      | 6/16 [00:04<00:07,  1.35it/s]update embedding:  44%|████▍     | 7/16 [00:05<00:06,  1.35it/s]update embedding:  50%|█████     | 8/16 [00:05<00:05,  1.34it/s]update embedding:  56%|█████▋    | 9/16 [00:06<00:05,  1.35it/s]update embedding:  62%|██████▎   | 10/16 [00:07<00:04,  1.34it/s]update embedding:  69%|██████▉   | 11/16 [00:08<00:03,  1.32it/s]update embedding:  75%|███████▌  | 12/16 [00:08<00:03,  1.33it/s]update embedding:  81%|████████▏ | 13/16 [00:09<00:02,  1.35it/s]update embedding:  88%|████████▊ | 14/16 [00:10<00:01,  1.36it/s]update embedding:  94%|█████████▍| 15/16 [00:11<00:00,  1.37it/s]update embedding: 100%|██████████| 16/16 [00:11<00:00,  1.37it/s]update embedding: 100%|██████████| 16/16 [00:11<00:00,  1.35it/s]
update embedding:   0%|          | 0/16 [00:00<?, ?it/s]update embedding:   6%|▋         | 1/16 [00:00<00:11,  1.33it/s]update embedding:  12%|█▎        | 2/16 [00:01<00:10,  1.34it/s]update embedding:  19%|█▉        | 3/16 [00:02<00:09,  1.36it/s]update embedding:  25%|██▌       | 4/16 [00:02<00:08,  1.37it/s]update embedding:  31%|███▏      | 5/16 [00:03<00:08,  1.37it/s]update embedding:  38%|███▊      | 6/16 [00:04<00:07,  1.38it/s]update embedding:  44%|████▍     | 7/16 [00:05<00:06,  1.38it/s]update embedding:  50%|█████     | 8/16 [00:05<00:05,  1.38it/s]update embedding:  56%|█████▋    | 9/16 [00:06<00:05,  1.38it/s]update embedding:  62%|██████▎   | 10/16 [00:07<00:04,  1.39it/s]update embedding:  69%|██████▉   | 11/16 [00:07<00:03,  1.39it/s]update embedding:  75%|███████▌  | 12/16 [00:08<00:02,  1.39it/s]update embedding:  81%|████████▏ | 13/16 [00:09<00:02,  1.39it/s]update embedding:  88%|████████▊ | 14/16 [00:10<00:01,  1.39it/s]update embedding:  94%|█████████▍| 15/16 [00:10<00:00,  1.39it/s]update embedding: 100%|██████████| 16/16 [00:11<00:00,  1.39it/s]update embedding: 100%|██████████| 16/16 [00:11<00:00,  1.39it/s]
retrival evaluation:   0%|          | 0/64 [00:00<?, ?it/s]retrival evaluation:  12%|█▎        | 8/64 [00:00<00:00, 71.61it/s]retrival evaluation:  27%|██▋       | 17/64 [00:00<00:00, 75.00it/s]retrival evaluation:  41%|████      | 26/64 [00:00<00:00, 77.13it/s]retrival evaluation:  55%|█████▍    | 35/64 [00:00<00:00, 79.09it/s]retrival evaluation:  69%|██████▉   | 44/64 [00:00<00:00, 80.65it/s]retrival evaluation:  83%|████████▎ | 53/64 [00:00<00:00, 81.70it/s]retrival evaluation:  97%|█████████▋| 62/64 [00:00<00:00, 82.52it/s]retrival evaluation: 100%|██████████| 64/64 [00:00<00:00, 82.21it/s]

pk3=0, pk2=0,pk1=0 best_f1 = 0.207, bets_f2=0.318, MAP=0.3, MRR=0, AP=0.118, exe_time=29.265550136566162

INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-multilingual-cased-config.json from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/aee7490b1a48646df683dee12f25d9c63ebbf8dce1b7e1a656ce28830d9a7e86.bc76a47cb1c1c2984e48f23afbd3473a944ac1a2be9a8c8200092f5bf62153c9
INFO:transformers.configuration_utils:Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "output_past": true,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 119547
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilbert-base-multilingual-cased-pytorch_model.bin from cache at /afs/crc.nd.edu/user/j/jlin6/.cache/torch/transformers/72a6c787412704a6fa6f5d9e5ef7d33c5b80c787e2bbc7d9ad82d7f88fb8f802.89fad86febf14521569023d312560283a922c0884a52f412eef4e96f91513ab2
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing DistilBertModel.

INFO:transformers.modeling_utils:All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.
INFO:__main__:model loaded
INFO:EMSE.BERTDataReader:Creating examples from dataset file at /afs/crc.nd.edu/user/j/jlin6/data/EMSE/xLua/test
update feature:   0%|          | 0/19 [00:00<?, ?it/s]update feature: 100%|██████████| 19/19 [00:00<00:00, 364.21it/s]
update feature:   0%|          | 0/19 [00:00<?, ?it/s]update feature: 100%|██████████| 19/19 [00:00<00:00, 1668.48it/s]
update embedding:   0%|          | 0/19 [00:00<?, ?it/s]update embedding:   5%|▌         | 1/19 [00:00<00:13,  1.32it/s]update embedding:  11%|█         | 2/19 [00:01<00:12,  1.34it/s]update embedding:  16%|█▌        | 3/19 [00:02<00:11,  1.35it/s]update embedding:  21%|██        | 4/19 [00:02<00:11,  1.35it/s]update embedding:  26%|██▋       | 5/19 [00:03<00:10,  1.35it/s]update embedding:  32%|███▏      | 6/19 [00:04<00:09,  1.35it/s]update embedding:  37%|███▋      | 7/19 [00:05<00:08,  1.35it/s]update embedding:  42%|████▏     | 8/19 [00:05<00:08,  1.35it/s]update embedding:  47%|████▋     | 9/19 [00:06<00:07,  1.36it/s]update embedding:  53%|█████▎    | 10/19 [00:07<00:06,  1.36it/s]update embedding:  58%|█████▊    | 11/19 [00:08<00:05,  1.35it/s]update embedding:  63%|██████▎   | 12/19 [00:08<00:05,  1.35it/s]update embedding:  68%|██████▊   | 13/19 [00:09<00:04,  1.36it/s]update embedding:  74%|███████▎  | 14/19 [00:10<00:03,  1.36it/s]update embedding:  79%|███████▉  | 15/19 [00:11<00:02,  1.35it/s]update embedding:  84%|████████▍ | 16/19 [00:11<00:02,  1.36it/s]update embedding:  89%|████████▉ | 17/19 [00:12<00:01,  1.36it/s]update embedding:  95%|█████████▍| 18/19 [00:13<00:00,  1.37it/s]update embedding: 100%|██████████| 19/19 [00:13<00:00,  1.36it/s]update embedding: 100%|██████████| 19/19 [00:13<00:00,  1.36it/s]
update embedding:   0%|          | 0/19 [00:00<?, ?it/s]update embedding:   5%|▌         | 1/19 [00:00<00:12,  1.39it/s]update embedding:  11%|█         | 2/19 [00:01<00:12,  1.39it/s]update embedding:  16%|█▌        | 3/19 [00:02<00:11,  1.39it/s]update embedding:  21%|██        | 4/19 [00:02<00:10,  1.38it/s]update embedding:  26%|██▋       | 5/19 [00:03<00:10,  1.38it/s]update embedding:  32%|███▏      | 6/19 [00:04<00:09,  1.38it/s]update embedding:  37%|███▋      | 7/19 [00:05<00:08,  1.38it/s]update embedding:  42%|████▏     | 8/19 [00:05<00:07,  1.38it/s]update embedding:  47%|████▋     | 9/19 [00:06<00:07,  1.38it/s]update embedding:  53%|█████▎    | 10/19 [00:07<00:06,  1.38it/s]update embedding:  58%|█████▊    | 11/19 [00:07<00:05,  1.37it/s]update embedding:  63%|██████▎   | 12/19 [00:08<00:05,  1.37it/s]update embedding:  68%|██████▊   | 13/19 [00:09<00:04,  1.37it/s]update embedding:  74%|███████▎  | 14/19 [00:10<00:03,  1.38it/s]update embedding:  79%|███████▉  | 15/19 [00:10<00:02,  1.38it/s]update embedding:  84%|████████▍ | 16/19 [00:11<00:02,  1.38it/s]update embedding:  89%|████████▉ | 17/19 [00:12<00:01,  1.38it/s]update embedding:  95%|█████████▍| 18/19 [00:13<00:00,  1.37it/s]update embedding: 100%|██████████| 19/19 [00:13<00:00,  1.36it/s]update embedding: 100%|██████████| 19/19 [00:13<00:00,  1.37it/s]
retrival evaluation:   0%|          | 0/91 [00:00<?, ?it/s]retrival evaluation:   8%|▊         | 7/91 [00:00<00:01, 68.11it/s]retrival evaluation:  18%|█▊        | 16/91 [00:00<00:01, 72.36it/s]retrival evaluation:  27%|██▋       | 25/91 [00:00<00:00, 76.38it/s]retrival evaluation:  37%|███▋      | 34/91 [00:00<00:00, 79.37it/s]retrival evaluation:  47%|████▋     | 43/91 [00:00<00:00, 81.54it/s]retrival evaluation:  57%|█████▋    | 52/91 [00:00<00:00, 83.36it/s]retrival evaluation:  67%|██████▋   | 61/91 [00:00<00:00, 84.53it/s]retrival evaluation:  77%|███████▋  | 70/91 [00:00<00:00, 85.37it/s]retrival evaluation:  87%|████████▋ | 79/91 [00:00<00:00, 85.76it/s]retrival evaluation:  97%|█████████▋| 88/91 [00:01<00:00, 86.09it/s]retrival evaluation: 100%|██████████| 91/91 [00:01<00:00, 85.81it/s]

pk3=0, pk2=0,pk1=0 best_f1 = 0.581, bets_f2=0.526, MAP=0.64, MRR=0, AP=0.488, exe_time=29.04593324661255

